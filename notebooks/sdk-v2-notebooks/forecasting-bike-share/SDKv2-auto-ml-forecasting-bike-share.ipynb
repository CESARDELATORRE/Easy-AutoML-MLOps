{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/automated-machine-learning/forecasting-bike-share/auto-ml-forecasting-bike-share.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Machine Learning\n",
    "**BikeShare Demand Forecasting**\n",
    "\n",
    "## Contents\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Compute](#Compute)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Featurization](#Featurization)\n",
    "1. [Evaluate](#Evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook demonstrates demand forecasting for a bike-sharing service using AutoML.\n",
    "\n",
    "AutoML highlights here include built-in holiday featurization, accessing engineered feature names, and working with the `forecast` function. Please also look at the additional forecasting notebooks, which document lagging, rolling windows, forecast quantiles, other ways to use the forecast function, and forecaster deployment.\n",
    "\n",
    "Make sure you have executed the [configuration notebook](../../../configuration.ipynb) before running this notebook.\n",
    "\n",
    "Notebook synopsis:\n",
    "1. Creating an Experiment in an existing Workspace\n",
    "2. Configuration and local run of AutoML for a time-series model with lag and holiday features \n",
    "3. Viewing the engineered names for featurized data and featurization summary for all raw features\n",
    "4. Evaluating the fitted model using a rolling test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AZURE_EXTENSION_DIR=\"E:/Src/git/sdk-cli-v2/src/cli/src\"\n",
      "env: AZURE_ML_CLI_PRIVATE_FEATURES_ENABLED=true\n"
     ]
    }
   ],
   "source": [
    "%env AZURE_EXTENSION_DIR=\"E:/Src/git/sdk-cli-v2/src/cli/src\"\n",
    "%env AZURE_ML_CLI_PRIVATE_FEATURES_ENABLED=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import azure.ml\n",
    "from azure.ml import MLClient\n",
    "\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "\n",
    "from azure.ml.entities import Workspace\n",
    "from azure.ml.entities import AmlCompute\n",
    "from azure.ml.entities import Data\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample notebook may use features that are not available in previous versions of the Azure ML SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was created using version 1.31.0 of the Azure ML SDK\n",
      "You are currently using SDK version 0.0.88 of the Azure ML SDK\n"
     ]
    }
   ],
   "source": [
    "# TODO: Versions need to change\n",
    "print(\"This notebook was created using version 1.31.0 of the Azure ML SDK\")\n",
    "print(\"You are currently using SDK version\", azure.ml.version.VERSION, \"of the Azure ML SDK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Equivalents for the following may be missing.\n",
    "\n",
    "Accessing the Azure ML workspace requires authentication with Azure.\n",
    "\n",
    "The default authentication is interactive authentication using the default tenant.  Executing the `ws = Workspace.from_config()` line in the cell below will prompt for authentication the first time that it is run.\n",
    "\n",
    "If you have multiple Azure tenants, you can specify the tenant by replacing the `ws = Workspace.from_config()` line in the cell below with the following:\n",
    "\n",
    "```\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "auth = InteractiveLoginAuthentication(tenant_id = 'mytenantid')\n",
    "ws = Workspace.from_config(auth = auth)\n",
    "```\n",
    "\n",
    "If you need to run in an environment where interactive login is not possible, you can use Service Principal authentication by replacing the `ws = Workspace.from_config()` line in the cell below with the following:\n",
    "\n",
    "```\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "auth = auth = ServicePrincipalAuthentication('mytenantid', 'myappid', 'mypassword')\n",
    "ws = Workspace.from_config(auth = auth)\n",
    "```\n",
    "For more details, see [aka.ms/aml-notebook-auth](http://aka.ms/aml-notebook-auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize MLClient\n",
    "\n",
    "Create an MLClient object, to interact with Azure ML resources, such as computes, jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.ml._ml_client.MLClient at 0x2c215b7ed68>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subscription_id = '381b38e9-9840-4719-a5a0-61d9585e1e91'\n",
    "resource_group_name = 'yunba_test_rg'\n",
    "workspace_name = \"yunba-test-ws-eastus2\" #\"gasi_ws_centraleuap\"\n",
    "experiment_name = \"sdkv2-auto-ml-forecasting-bike-share\"\n",
    "\n",
    "client = MLClient(subscription_id, resource_group_name, default_workspace_name=workspace_name)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize MLFlowClient\n",
    "\n",
    "Create an MLFlowClient to interact with the resources that the AutoML job creates, such as models, metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azureml-core azureml-mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'sdkv2-auto-ml-forecasting-bike-share' does not exist. Creating a new experiment\n",
      "\n",
      "Current tracking uri: azureml://eastus2.experiments.azureml.net/mlflow/v1.0/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/yunba_test_rg/providers/Microsoft.MachineLearningServices/workspaces/yunba-test-ws-eastus2?\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "########\n",
    "# TODO: The API to get tracking URI is not yet available on Worksapce object.\n",
    "from azureml.core import Workspace as WorkspaceV1\n",
    "ws = WorkspaceV1(workspace_name=workspace_name, resource_group=resource_group_name, subscription_id=subscription_id)\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "del ws\n",
    "########\n",
    "\n",
    "# Not sure why this doesn't work w/o the double + single quotes\n",
    "# mlflow.set_tracking_uri(\"azureml://northeurope.experiments.azureml.net/mlflow/v1.0/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_neu/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_neu?\")\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Attach existing AmlCompute\n",
    "You will need to create a compute target for your AutoML run. In this tutorial, you create AmlCompute as your training compute resource.\n",
    "\n",
    "> Note that if you have an AzureML Data Scientist role, you will not have permission to create compute resources. Talk to your workspace or IT admin to create the compute targets described in this section, if they do not already exist.\n",
    "\n",
    "#### Creation of AmlCompute takes approximately 5 minutes. \n",
    "If the AmlCompute with that name is already in your workspace this code will skip the creation process.\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AzureCliCredential.get_token failed: Please run 'az login' to set up an account\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not create compute. Cannot deserialize duration object., ISO8601Error: Unable to parse duration string ''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AmlCompute({'type': 'amlcompute', 'created_on': None, 'provisioning_state': 'Succeeded', 'provisioning_errors': None, 'name': 'cpu-cluster', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/yunba_test_rg/providers/Microsoft.MachineLearningServices/workspaces/yunba-test-ws-eastus2/computes/cpu-cluster', 'base_path': './', 'creation_context': None, 'location': 'eastus2', 'enable_public_ip': False, 'resource_id': None, 'size': 'STANDARD_D2_V2', 'min_instances': 0, 'max_instances': 6, 'idle_time_before_scale_down': 120.0, 'identity_type': None, 'user_assigned_identities': None, 'admin_username': 'azureuser', 'admin_password': None, 'ssh_key_value': None, 'vnet_name': None, 'subnet': None, 'priority': 'Dedicated'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set or create compute\n",
    "\n",
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "compute = AmlCompute(\n",
    "    name=cpu_cluster_name, size=\"STANDARD_D11_V2\",\n",
    "    min_instances=0, max_instances=3,\n",
    "    idle_time_before_scale_down=120\n",
    ")\n",
    "\n",
    "# Load directly from YAML file\n",
    "# compute = Compute.load(\"./compute.yaml\")\n",
    "\n",
    "try:\n",
    "    # TODO: This currently results in an exception in Azure ML, please create compute manually.\n",
    "    client.compute.create(compute)\n",
    "except ResourceExistsError as re:\n",
    "    print(re)\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    \n",
    "    print(\"Could not create compute.\", str(e))\n",
    "#     traceback.print_exc()\n",
    "    # Reload an existing compute target\n",
    "    compute = client.compute.get(cpu_cluster_name)\n",
    "\n",
    "compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The [Machine Learning service workspace](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-workspace) is paired with the storage account, which contains the default data store. We will use it to upload the bike share data and create [tabular dataset](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.tabulardataset?view=azure-ml-py) for training. A tabular dataset defines a series of lazily-evaluated, immutable operations to load data from the data source into tabular representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: This doesnt' work, ensure dataset is created via. the UI.\n",
    "#### Below ws_tmp setup should be changed: uploading data to init a dataset, and then split data with time points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ws object to upload data to datastore.\n",
    "from azureml.core import Workspace\n",
    "ws_tmp = Workspace(subscription_id=subscription_id, resource_group=resource_group_name, workspace_name=workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./bike-no.csv\n",
      "Uploaded ./bike-no.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_02b53e73aaf94fbfb63f5b870e4e6683"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore = ws_tmp.get_default_datastore()\n",
    "datastore.upload_files(files = ['./bike-no.csv'], target_path = 'dataset/', overwrite = True,show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant       date  season  yr  mnth  weekday  weathersit      temp  \\\n",
       "0        1 2011-01-01       1   0     1        6           2  0.344167   \n",
       "1        2 2011-01-02       1   0     1        0           2  0.363478   \n",
       "2        3 2011-01-03       1   0     1        1           1  0.196364   \n",
       "3        4 2011-01-04       1   0     1        2           1  0.200000   \n",
       "4        5 2011-01-05       1   0     1        3           1  0.226957   \n",
       "\n",
       "      atemp       hum  windspeed   cnt  \n",
       "0  0.363625  0.805833   0.160446   985  \n",
       "1  0.353739  0.696087   0.248539   801  \n",
       "2  0.189405  0.437273   0.248309  1349  \n",
       "3  0.212122  0.590435   0.160296  1562  \n",
       "4  0.229270  0.436957   0.186900  1600  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'dataset/bike-no.csv')]).with_timestamp_columns(fine_grain_timestamp=time_column_name) \n",
    "\n",
    "# Drop the columns 'casual' and 'registered' as these columns are a breakdown of the total and therefore a leak.\n",
    "dataset = dataset.drop_columns(columns=['casual', 'registered'])\n",
    "\n",
    "dataset.take(5).to_pandas_dataframe().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "The first split we make is into train and test sets. Note we are splitting on time. Data before 9/1 will be used for training, and data after and including 9/1 will be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>2012-08-27</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>0.654688</td>\n",
       "      <td>0.730417</td>\n",
       "      <td>0.128733</td>\n",
       "      <td>6917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>606</td>\n",
       "      <td>2012-08-28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.728333</td>\n",
       "      <td>0.666050</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.190925</td>\n",
       "      <td>7040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>607</td>\n",
       "      <td>2012-08-29</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.635733</td>\n",
       "      <td>0.552083</td>\n",
       "      <td>0.112562</td>\n",
       "      <td>7697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>608</td>\n",
       "      <td>2012-08-30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.652779</td>\n",
       "      <td>0.590417</td>\n",
       "      <td>0.077117</td>\n",
       "      <td>7713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>609</td>\n",
       "      <td>2012-08-31</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.764167</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.168533</td>\n",
       "      <td>7350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant       date  season  yr  mnth  weekday  weathersit      temp  \\\n",
       "0      605 2012-08-27       3   1     8        1           1  0.703333   \n",
       "1      606 2012-08-28       3   1     8        2           1  0.728333   \n",
       "2      607 2012-08-29       3   1     8        3           1  0.685000   \n",
       "3      608 2012-08-30       3   1     8        4           1  0.706667   \n",
       "4      609 2012-08-31       3   1     8        5           1  0.764167   \n",
       "\n",
       "      atemp       hum  windspeed   cnt  \n",
       "0  0.654688  0.730417   0.128733  6917  \n",
       "1  0.666050  0.620000   0.190925  7040  \n",
       "2  0.635733  0.552083   0.112562  7697  \n",
       "3  0.652779  0.590417   0.077117  7713  \n",
       "4  0.689400  0.587500   0.168533  7350  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select data that occurs before a specified date\n",
    "train = dataset.time_before(datetime(2012, 8, 31), include_boundary=True)\n",
    "train.to_pandas_dataframe().tail(5).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>610</td>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>0.702654</td>\n",
       "      <td>0.638333</td>\n",
       "      <td>0.113187</td>\n",
       "      <td>6140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>611</td>\n",
       "      <td>2012-09-02</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.649000</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.064071</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>612</td>\n",
       "      <td>2012-09-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.661629</td>\n",
       "      <td>0.790833</td>\n",
       "      <td>0.151121</td>\n",
       "      <td>6034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>613</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.725833</td>\n",
       "      <td>0.686888</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.236321</td>\n",
       "      <td>6864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>614</td>\n",
       "      <td>2012-09-05</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.708983</td>\n",
       "      <td>0.741250</td>\n",
       "      <td>0.187808</td>\n",
       "      <td>7112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant       date  season  yr  mnth  weekday  weathersit      temp  \\\n",
       "0      610 2012-09-01       3   1     9        6           2  0.753333   \n",
       "1      611 2012-09-02       3   1     9        0           2  0.696667   \n",
       "2      612 2012-09-03       3   1     9        1           1  0.707500   \n",
       "3      613 2012-09-04       3   1     9        2           1  0.725833   \n",
       "4      614 2012-09-05       3   1     9        3           1  0.736667   \n",
       "\n",
       "      atemp       hum  windspeed   cnt  \n",
       "0  0.702654  0.638333   0.113187  6140  \n",
       "1  0.649000  0.815000   0.064071  5810  \n",
       "2  0.661629  0.790833   0.151121  6034  \n",
       "3  0.686888  0.755000   0.236321  6864  \n",
       "4  0.708983  0.741250   0.187808  7112  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = dataset.time_after(datetime(2012, 9, 1), include_boundary=True)\n",
    "test.to_pandas_dataframe().head(5).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CSV file locally, so that it can be uploaded to create a \n",
    "# tabular dataset\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "    \n",
    "# Save the train-test-valid data to a csv to be uploaded to the datastore\n",
    "train.to_pandas_dataframe().to_csv(\"data/train_data.csv\", index=False)\n",
    "test.to_pandas_dataframe().to_csv(\"data/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init the training and test data for the MLClient object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data({'is_anonymous': False, 'name': 'bike_share_train', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/yunba_test_rg/providers/Microsoft.MachineLearningServices/workspaces/yunba-test-ws-eastus2/data/bike_share_train/versions/1', 'base_path': './', 'creation_context': <azure.ml._restclient.v2021_03_01_preview.models._models_py3.SystemData object at 0x000002C215BA4F98>, 'version': 1, 'datastore': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/yunba_test_rg/providers/Microsoft.MachineLearningServices/workspaces/yunba-test-ws-eastus2/datastores/workspaceblobstore', 'path': 'UI/08-04-2021_114520_UTC/train_data.csv', 'local_path': None})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: This doesnt' work, ensure dataset is created via. the UI\n",
    "# Create dataset\n",
    "\n",
    "dataset_name = \"bike_share_train\"\n",
    "dataset_version = 1\n",
    "\n",
    "try:\n",
    "    training_data = client.data.get(dataset_name, dataset_version)\n",
    "#     training_data = Data(name=dataset_name, version=dataset_version, local_path=\"./data/train\")\n",
    "#     training_data = client.data.create_or_update(training_data)\n",
    "#     print(\"Uploaded to path  : \", training_data.path)\n",
    "#     print(\"Datastore location: \", training_data.datastore)\n",
    "except Exception as e:\n",
    "    print(\"Could not create dataset. \", str(e))\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data({'is_anonymous': False, 'name': 'bike_share_test', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/yunba_test_rg/providers/Microsoft.MachineLearningServices/workspaces/yunba-test-ws-eastus2/data/bike_share_test/versions/1', 'base_path': './', 'creation_context': <azure.ml._restclient.v2021_03_01_preview.models._models_py3.SystemData object at 0x000002C215BA4D30>, 'version': 1, 'datastore': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/yunba_test_rg/providers/Microsoft.MachineLearningServices/workspaces/yunba-test-ws-eastus2/datastores/workspaceblobstore', 'path': 'UI/08-04-2021_114650_UTC/test_data.csv', 'local_path': None})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_name = \"bike_share_test\"\n",
    "test_data = client.data.get(test_dataset_name, dataset_version)\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting Parameters\n",
    "To define forecasting parameters for your experiment training, you can leverage the ForecastingParameters class. The table below details the forecasting parameter we will be passing into our experiment.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**time_column_name**|The name of your time column.|\n",
    "|**forecast_horizon**|The forecast horizon is how many periods forward you would like to forecast. This integer horizon is in units of the timeseries frequency (e.g. daily, weekly).|\n",
    "|**country_or_region_for_holidays**|The country/region used to generate holiday features. These should be ISO 3166 two-letter country/region codes (i.e. 'US', 'GB').|\n",
    "|**target_lags**|The target_lags specifies how far back we will construct the lags of the target variable.|\n",
    "|**freq**|Forecast frequency. This optional parameter represents the period with which the forecast is desired, for example, daily, weekly, yearly, etc. Use this parameter for the correction of time series containing irregular data points or for padding of short time series. The frequency needs to be a pandas offset alias. Please refer to [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Instantiate a AutoMLConfig object. This defines the settings and data used to run the experiment.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|forecasting|\n",
    "|**primary_metric**|This is the metric that you want to optimize.<br> Forecasting supports the following primary metrics <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>\n",
    "|**blocked_models**|Models in blocked_models won't be used by AutoML. All supported models can be found at [here](https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.constants.supportedmodels.forecasting?view=azure-ml-py).|\n",
    "|**experiment_timeout_hours**|Experimentation timeout in hours.|\n",
    "|**training_data**|Input dataset, containing both features and label column.|\n",
    "|**label_column_name**|The name of the label column.|\n",
    "|**compute_target**|The remote compute for training.|\n",
    "|**n_cross_validations**|Number of cross validation splits.|\n",
    "|**enable_early_stopping**|If early stopping is on, training will stop when the primary metric is no longer improving.|\n",
    "|**forecasting_parameters**|A class that holds all the forecasting related parameters.|\n",
    "\n",
    "This notebook uses the blocked_models parameter to exclude some models that take a longer time to train on this dataset. You can choose to remove models from the blocked_models list but you may need to increase the experiment_timeout_hours parameter value to get results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's set up what we know about the dataset. \n",
    "\n",
    "**Target column** is what we want to forecast.\n",
    "\n",
    "**Time column** is the time axis along which to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name = 'cnt'\n",
    "time_column_name = 'date'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting forecaster maximum horizon \n",
    "\n",
    "The forecast horizon is the number of periods into the future that the model should predict. Here, we set the horizon to 14 periods (i.e. 14 days). Notice that this is much shorter than the number of days in the test set; we will need to use a rolling test to evaluate the performance on the whole test set. For more discussion of forecast horizons and guiding principles for setting them, please see the [energy demand notebook](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/automated-machine-learning/forecasting-energy-demand).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_horizon = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoMLJob({'type': 'automl_job', 'status': None, 'output': None, 'log_files': None, 'name': '293be5e6-49d2-4a08-bf33-63a8de599be3', 'description': None, 'tags': {}, 'properties': {'save_mlflow': True}, 'id': None, 'base_path': './', 'creation_context': None, 'experiment_name': 'forecasting-bike-share', 'interaction_endpoints': None, 'general_settings': <azure.ml._restclient.v2020_09_01_preview.models._models_py3.GeneralSettings object at 0x000002C215BC7240>, 'data_settings': <azure.ml._restclient.v2020_09_01_preview.models._models_py3.DataSettings object at 0x000002C215BC7358>, 'limit_settings': <azure.ml._restclient.v2020_09_01_preview.models._models_py3.LimitSettings object at 0x000002C215BC72B0>, 'forecasting_settings': <azure.ml.entities._job.automl.forecasting.ForecastingSettings object at 0x000002C215BC73C8>, 'training_settings': <azure.ml.entities._job.automl.training_settings.TrainingSettings object at 0x000002C215BC7390>, 'featurization_settings': <azure.ml.entities._job.automl.featurization.FeaturizationSettings object at 0x000002C215BC7320>, 'compute': {'instance_count': None, 'target': 'cpu-cluster', 'is_local': False, 'instance_type': None, 'location': None, 'properties': None}})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ml._restclient.v2020_09_01_preview.models import (\n",
    "    GeneralSettings,\n",
    "    DataSettings,\n",
    "    LimitSettings,\n",
    "    TrainingDataSettings,\n",
    "    ValidationDataSettings,\n",
    "    TestDataSettings,\n",
    "    FeaturizationSettings,\n",
    "\n",
    ")\n",
    "\n",
    "from azure.ml.entities._job.automl.training_settings import TrainingSettings\n",
    "from azure.ml.entities._job.automl.featurization import FeaturizationSettings\n",
    "from azure.ml.entities._job.automl.forecasting import ForecastingSettings\n",
    "\n",
    "from azure.ml.entities import AutoMLJob, ComputeConfiguration\n",
    "\n",
    "\n",
    "compute_settings = ComputeConfiguration(target=cpu_cluster_name)\n",
    "\n",
    "general_settings = GeneralSettings(\n",
    "    task_type=\"forecasting\",\n",
    "    primary_metric= \"normalized_root_mean_squared_error\",\n",
    "    log_verbosity=\"Info\")\n",
    "\n",
    "limit_settings = LimitSettings(\n",
    "    timeout=60,\n",
    "    trial_timeout=5,\n",
    "    max_concurrent_trials=4,\n",
    "    enable_early_termination=True)\n",
    "\n",
    "training_data_settings = TrainingDataSettings(\n",
    "    dataset_arm_id=\"{}:{}\".format(training_data.name, training_data.version)\n",
    ")\n",
    "validation_data_settings = ValidationDataSettings(\n",
    "    n_cross_validations=3\n",
    ")\n",
    "\n",
    "data_settings = DataSettings(\n",
    "    training_data=training_data_settings,\n",
    "    target_column_name=target_column_name,\n",
    "    validation_data=validation_data_settings\n",
    ")\n",
    "\n",
    "featurization_settings = FeaturizationSettings(\n",
    "    featurization_config=\"auto\"\n",
    ")\n",
    "\n",
    "training_settings = TrainingSettings(\n",
    "    block_list_models=['ExtremeRandomTrees']    \n",
    ")\n",
    "\n",
    "# Forecasting setting.\n",
    "forecasting_settings = ForecastingSettings(\n",
    "    time_column_name=time_column_name,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    country_or_region_for_holidays='US', # set country_or_region will trigger holiday featurizer\n",
    "    target_lags='auto', # use heuristic based lag setting\n",
    "    frequency='D' # Set the forecast frequency to be daily\n",
    ")\n",
    "\n",
    "extra_automl_settings = {\"save_mlflow\": True}\n",
    "\n",
    "automl_job = AutoMLJob(\n",
    "    compute=compute_settings,\n",
    "    general_settings=general_settings,\n",
    "    limit_settings=limit_settings,\n",
    "    data_settings=data_settings,\n",
    "    training_settings=training_settings,\n",
    "    featurization_settings=featurization_settings,\n",
    "    forecasting_settings=forecasting_settings,\n",
    "    properties=extra_automl_settings,\n",
    ")\n",
    "\n",
    "automl_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AzureCliCredential.get_token failed: Please run 'az login' to set up an account\n",
      "AzureCliCredential.get_token failed: Please run 'az login' to set up an account\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoMLJob({'type': 'automl_job', 'status': 'NotStarted', 'output': None, 'log_files': None, 'name': '293be5e6-49d2-4a08-bf33-63a8de599be3', 'description': None, 'tags': {}, 'properties': {'save_mlflow': 'True'}, 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/yunba_test_rg/providers/Microsoft.MachineLearningServices/workspaces/yunba-test-ws-eastus2/jobs/293be5e6-49d2-4a08-bf33-63a8de599be3', 'base_path': './', 'creation_context': <azure.ml._restclient.v2020_09_01_preview.models._models_py3.SystemData object at 0x000002C215B9E8D0>, 'experiment_name': 'forecasting-bike-share', 'interaction_endpoints': {'Tracking': <azure.ml._restclient.v2020_09_01_preview.models._models_py3.JobEndpoint object at 0x000002C215B9E748>, 'Studio': <azure.ml._restclient.v2020_09_01_preview.models._models_py3.JobEndpoint object at 0x000002C215B9EE80>}, 'general_settings': <azure.ml._restclient.v2020_09_01_preview.models._models_py3.GeneralSettings object at 0x000002C215B9EEB8>, 'data_settings': <azure.ml._restclient.v2020_09_01_preview.models._models_py3.DataSettings object at 0x000002C215B9EDA0>, 'limit_settings': <azure.ml._restclient.v2020_09_01_preview.models._models_py3.LimitSettings object at 0x000002C215BC7048>, 'forecasting_settings': <azure.ml.entities._job.automl.forecasting.ForecastingSettings object at 0x000002C215BC70B8>, 'training_settings': <azure.ml.entities._job.automl.training_settings.TrainingSettings object at 0x000002C215BC7198>, 'featurization_settings': <azure.ml.entities._job.automl.featurization.FeaturizationSettings object at 0x000002C215BC7160>, 'compute': {'instance_count': None, 'target': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/yunba_test_rg/providers/Microsoft.MachineLearningServices/workspaces/yunba-test-ws-eastus2/computes/', 'is_local': False, 'instance_type': None, 'location': None, 'properties': None}})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_job = client.jobs.create_or_update(automl_job)\n",
    "created_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studio URL:  https://ml.azure.com/runs/293be5e6-49d2-4a08-bf33-63a8de599be3?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/yunba_test_rg/workspaces/yunba-test-ws-eastus2&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "print(\"Studio URL: \", created_job.interaction_endpoints[\"Studio\"].endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Wait for the remote run to complete\n",
    "# remote_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Best Model\n",
    "Below we select the best model from all the training iterations using get_output method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best child run id:  5e759c10-d73a-46fb-8b3f-3c0616c05fbf_104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={'explained_variance': 0.7620329414961295,\n",
       " 'mean_absolute_error': 427.4545191833113,\n",
       " 'mean_absolute_percentage_error': 6.727707830057546,\n",
       " 'median_absolute_error': 373.9487443518653,\n",
       " 'normalized_mean_absolute_error': 0.053896673708651026,\n",
       " 'normalized_median_absolute_error': 0.047150264071600716,\n",
       " 'normalized_root_mean_squared_error': 0.06778592385824482,\n",
       " 'normalized_root_mean_squared_log_error': 0.029927443382009773,\n",
       " 'r2_score': 0.6823643627231287,\n",
       " 'root_mean_squared_error': 537.6101621197396,\n",
       " 'root_mean_squared_log_error': 0.08867941123607752,\n",
       " 'spearman_correlation': 0.8681318681318682}, params={}, tags={'_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":4,\"CurrentNodeCount\":6}',\n",
       " '_aml_system_azureml.automlComponent': 'AutoML',\n",
       " 'mlflow.parentRunId': '5e759c10-d73a-46fb-8b3f-3c0616c05fbf',\n",
       " 'mlflow.source.name': 'automl_driver.py',\n",
       " 'mlflow.source.type': 'JOB'}>, info=<RunInfo: artifact_uri='azureml://experiments/forecasting-bike-share/runs/5e759c10-d73a-46fb-8b3f-3c0616c05fbf_104/artifacts', end_time=1628200058560, experiment_id='afd268df-56a7-46be-a91c-7116423de155', lifecycle_stage='active', run_id='5e759c10-d73a-46fb-8b3f-3c0616c05fbf_104', run_uuid='5e759c10-d73a-46fb-8b3f-3c0616c05fbf_104', start_time=1628199975698, status='FINISHED', user_id='3863f00b-8ad4-4a84-ac86-75fbe7210440'>>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# TODO: Use this run, as it has MLFlow model stored on the run\n",
    "job_name = \"5e759c10-d73a-46fb-8b3f-3c0616c05fbf\"\n",
    "# job_name = created_job.name\n",
    "\n",
    "mlflow_client = MlflowClient()\n",
    "mlflow_parent_run = mlflow_client.get_run(job_name)\n",
    "\n",
    "best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\n",
    "print(\"Found best child run id: \", best_child_run_id)\n",
    "\n",
    "best_run_customized = mlflow_client.get_run(best_child_run_id)\n",
    "best_run_customized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurization\n",
    "\n",
    "You can access the engineered feature names generated in time-series featurization. Note that a number of named holiday periods are represented. We recommend that you have at least one year of data when using this feature to ensure that all yearly holidays are captured in the training featurization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step requires AutoML runtime libraries to be installed\n",
    "# !pip install azureml-train-automl-runtime\n",
    "import mlflow.sklearn\n",
    "\n",
    "fitted_model_customized = mlflow.sklearn.load_model(\"runs:/{}/outputs\".format(best_run_customized.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_automl_target_col_WASNULL',\n",
       " 'atemp',\n",
       " 'atemp_WASNULL',\n",
       " 'horizon_origin',\n",
       " 'hum',\n",
       " 'hum_WASNULL',\n",
       " 'instant',\n",
       " 'instant_WASNULL',\n",
       " 'mnth',\n",
       " 'mnth_WASNULL',\n",
       " 'season',\n",
       " 'season_WASNULL',\n",
       " 'temp',\n",
       " 'temp_WASNULL',\n",
       " 'weathersit',\n",
       " 'weathersit_WASNULL',\n",
       " 'weekday',\n",
       " 'weekday_WASNULL',\n",
       " 'windspeed',\n",
       " 'windspeed_WASNULL',\n",
       " 'yr',\n",
       " 'yr_WASNULL',\n",
       " '_automl_target_col_lag1D',\n",
       " '_automl_year',\n",
       " '_automl_year_iso',\n",
       " '_automl_half',\n",
       " '_automl_quarter',\n",
       " '_automl_month',\n",
       " '_automl_day',\n",
       " '_automl_wday',\n",
       " '_automl_qday',\n",
       " '_automl_week',\n",
       " '_automl_IsPaidTimeOff',\n",
       " '_automl_Holiday_1 day after Christmas Day',\n",
       " '_automl_Holiday_1 day after Columbus Day',\n",
       " '_automl_Holiday_1 day after Independence Day',\n",
       " '_automl_Holiday_1 day after Labor Day',\n",
       " '_automl_Holiday_1 day after Martin Luther King, Jr. Day',\n",
       " '_automl_Holiday_1 day after Memorial Day',\n",
       " \"_automl_Holiday_1 day after New Year's Day\",\n",
       " '_automl_Holiday_1 day after Thanksgiving',\n",
       " '_automl_Holiday_1 day after Veterans Day',\n",
       " \"_automl_Holiday_1 day after Washington's Birthday\",\n",
       " '_automl_Holiday_1 day before Christmas Day',\n",
       " '_automl_Holiday_1 day before Columbus Day',\n",
       " '_automl_Holiday_1 day before Independence Day',\n",
       " '_automl_Holiday_1 day before Labor Day',\n",
       " '_automl_Holiday_1 day before Martin Luther King, Jr. Day',\n",
       " '_automl_Holiday_1 day before Memorial Day',\n",
       " '_automl_Holiday_1 day before Thanksgiving',\n",
       " '_automl_Holiday_1 day before Veterans Day',\n",
       " \"_automl_Holiday_1 day before Washington's Birthday\",\n",
       " '_automl_Holiday_10 days after Thanksgiving',\n",
       " '_automl_Holiday_10 days before Christmas Day',\n",
       " '_automl_Holiday_2 days after Christmas Day',\n",
       " '_automl_Holiday_2 days after Columbus Day',\n",
       " '_automl_Holiday_2 days after Independence Day',\n",
       " '_automl_Holiday_2 days after Labor Day',\n",
       " '_automl_Holiday_2 days after Martin Luther King, Jr. Day',\n",
       " '_automl_Holiday_2 days after Memorial Day',\n",
       " \"_automl_Holiday_2 days after New Year's Day\",\n",
       " '_automl_Holiday_2 days after Thanksgiving',\n",
       " '_automl_Holiday_2 days after Veterans Day',\n",
       " \"_automl_Holiday_2 days after Washington's Birthday\",\n",
       " '_automl_Holiday_2 days before Christmas Day',\n",
       " '_automl_Holiday_2 days before Columbus Day',\n",
       " '_automl_Holiday_2 days before Independence Day',\n",
       " '_automl_Holiday_2 days before Labor Day',\n",
       " '_automl_Holiday_2 days before Martin Luther King, Jr. Day',\n",
       " '_automl_Holiday_2 days before Memorial Day',\n",
       " '_automl_Holiday_2 days before Thanksgiving',\n",
       " '_automl_Holiday_2 days before Veterans Day',\n",
       " \"_automl_Holiday_2 days before Washington's Birthday\",\n",
       " '_automl_Holiday_3 days after Christmas Day',\n",
       " '_automl_Holiday_3 days after Columbus Day',\n",
       " '_automl_Holiday_3 days after Independence Day',\n",
       " \"_automl_Holiday_3 days after New Year's Day\",\n",
       " '_automl_Holiday_3 days after Thanksgiving',\n",
       " '_automl_Holiday_3 days after Veterans Day',\n",
       " '_automl_Holiday_3 days before Christmas Day',\n",
       " '_automl_Holiday_3 days before Columbus Day',\n",
       " '_automl_Holiday_3 days before Independence Day',\n",
       " '_automl_Holiday_3 days before Thanksgiving',\n",
       " '_automl_Holiday_3 days before Veterans Day',\n",
       " '_automl_Holiday_4 days after Christmas Day',\n",
       " '_automl_Holiday_4 days after Columbus Day',\n",
       " '_automl_Holiday_4 days after Independence Day',\n",
       " \"_automl_Holiday_4 days after New Year's Day\",\n",
       " '_automl_Holiday_4 days after Thanksgiving',\n",
       " '_automl_Holiday_4 days after Veterans Day',\n",
       " '_automl_Holiday_4 days before Christmas Day',\n",
       " '_automl_Holiday_4 days before Columbus Day',\n",
       " '_automl_Holiday_4 days before Independence Day',\n",
       " '_automl_Holiday_4 days before Thanksgiving',\n",
       " '_automl_Holiday_4 days before Veterans Day',\n",
       " '_automl_Holiday_5 days after Christmas Day',\n",
       " '_automl_Holiday_5 days after Columbus Day',\n",
       " '_automl_Holiday_5 days after Independence Day',\n",
       " \"_automl_Holiday_5 days after New Year's Day\",\n",
       " '_automl_Holiday_5 days after Thanksgiving',\n",
       " '_automl_Holiday_5 days after Veterans Day',\n",
       " '_automl_Holiday_5 days before Christmas Day',\n",
       " '_automl_Holiday_5 days before Columbus Day',\n",
       " '_automl_Holiday_5 days before Independence Day',\n",
       " '_automl_Holiday_5 days before Thanksgiving',\n",
       " '_automl_Holiday_5 days before Veterans Day',\n",
       " '_automl_Holiday_6 days after Christmas Day',\n",
       " '_automl_Holiday_6 days after Thanksgiving',\n",
       " '_automl_Holiday_6 days before Christmas Day',\n",
       " '_automl_Holiday_6 days before Thanksgiving',\n",
       " '_automl_Holiday_7 days after Thanksgiving',\n",
       " '_automl_Holiday_7 days before Christmas Day',\n",
       " '_automl_Holiday_7 days before Thanksgiving',\n",
       " '_automl_Holiday_8 days after Thanksgiving',\n",
       " '_automl_Holiday_8 days before Christmas Day',\n",
       " '_automl_Holiday_9 days after Thanksgiving',\n",
       " '_automl_Holiday_9 days before Christmas Day',\n",
       " '_automl_Holiday_Christmas Day',\n",
       " '_automl_Holiday_Columbus Day',\n",
       " '_automl_Holiday_Independence Day',\n",
       " '_automl_Holiday_Labor Day',\n",
       " '_automl_Holiday_Martin Luther King, Jr. Day',\n",
       " '_automl_Holiday_Memorial Day',\n",
       " \"_automl_Holiday_New Year's Day\",\n",
       " '_automl_Holiday_Thanksgiving',\n",
       " '_automl_Holiday_Veterans Day',\n",
       " \"_automl_Holiday_Washington's Birthday\"]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_transformer = fitted_model_customized.named_steps['timeseriestransformer']\n",
    "timeseries_transformer.get_engineered_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the featurization summary\n",
    "\n",
    "You can also see what featurization steps were performed on different raw features in the user data. For each raw feature in the user data, the following information is displayed:\n",
    "\n",
    "- Raw feature name\n",
    "- Number of engineered features formed out of this raw feature\n",
    "- Type detected\n",
    "- If feature was dropped\n",
    "- List of feature transformations for the raw feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RawFeatureName</th>\n",
       "      <th>TypeDetected</th>\n",
       "      <th>Dropped</th>\n",
       "      <th>EngineeredFeatureCount</th>\n",
       "      <th>Transformations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_automl_target_col</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[ImputationMarker, Lag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atemp</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>date</td>\n",
       "      <td>DateTime</td>\n",
       "      <td>No</td>\n",
       "      <td>105</td>\n",
       "      <td>[MaxHorizonFeaturizer, DateTimeTransformer, Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hum</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>instant</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mnth</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>season</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>temp</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weathersit</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>weekday</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>windspeed</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yr</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[MedianImputer, ImputationMarker]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RawFeatureName TypeDetected Dropped  EngineeredFeatureCount  \\\n",
       "0   _automl_target_col      Numeric      No                       2   \n",
       "1                atemp      Numeric      No                       2   \n",
       "2                 date     DateTime      No                     105   \n",
       "3                  hum      Numeric      No                       2   \n",
       "4              instant      Numeric      No                       2   \n",
       "5                 mnth      Numeric      No                       2   \n",
       "6               season      Numeric      No                       2   \n",
       "7                 temp      Numeric      No                       2   \n",
       "8           weathersit      Numeric      No                       2   \n",
       "9              weekday      Numeric      No                       2   \n",
       "10           windspeed      Numeric      No                       2   \n",
       "11                  yr      Numeric      No                       2   \n",
       "\n",
       "                                      Transformations  \n",
       "0                             [ImputationMarker, Lag]  \n",
       "1                   [MedianImputer, ImputationMarker]  \n",
       "2   [MaxHorizonFeaturizer, DateTimeTransformer, Da...  \n",
       "3                   [MedianImputer, ImputationMarker]  \n",
       "4                   [MedianImputer, ImputationMarker]  \n",
       "5                   [MedianImputer, ImputationMarker]  \n",
       "6                   [MedianImputer, ImputationMarker]  \n",
       "7                   [MedianImputer, ImputationMarker]  \n",
       "8                   [MedianImputer, ImputationMarker]  \n",
       "9                   [MedianImputer, ImputationMarker]  \n",
       "10                  [MedianImputer, ImputationMarker]  \n",
       "11                  [MedianImputer, ImputationMarker]  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the featurization summary as a list of JSON\n",
    "featurization_summary = timeseries_transformer.get_featurization_summary()\n",
    "# View the featurization summary as a pandas dataframe\n",
    "pd.DataFrame.from_records(featurization_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the best fitted model from the AutoML Run to make forecasts for the test set. We will do batch scoring on the test dataset which should have the same schema as training dataset.\n",
    "\n",
    "The scoring will run on a remote compute. In this example, it will reuse the training compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving forecasts from the model\n",
    "To run the forecast on the remote compute we will use a helper script: forecasting_script. This script contains the utility methods which will be used by the remote estimator. We copy the script to the project folder to upload it to remote compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from azureml.core.experiment import Experiment\n",
      "from azureml.core import Dataset, Run\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "from azureml.automl.core.shared.constants import MODEL_PATH\n",
      "\n",
      "train_experiment_name = '<<train_experiment_name>>'\n",
      "train_run_id = '<<train_run_id>>'\n",
      "target_column_name = '<<target_column_name>>'\n",
      "test_dataset_name = '<<test_dataset_name>>'\n",
      "\n",
      "run = Run.get_context()\n",
      "ws = run.experiment.workspace\n",
      "\n",
      "# Get the AutoML run object from the experiment name and the workspace\n",
      "train_experiment = Experiment(ws, train_experiment_name)\n",
      "automl_run = Run(experiment=train_experiment, run_id=train_run_id)\n",
      "\n",
      "# Download the trained model from the artifact store\n",
      "automl_run.download_file(name=MODEL_PATH, output_file_path='model.pkl')\n",
      "\n",
      "# get the input dataset by name\n",
      "test_dataset = Dataset.get_by_name(ws, name=test_dataset_name)\n",
      "\n",
      "X_test_df = test_dataset.drop_columns(columns=[target_column_name]).to_pandas_dataframe().reset_index(drop=True)\n",
      "y_test_df = test_dataset.with_timestamp_columns(None).keep_columns(columns=[target_column_name]).to_pandas_dataframe()\n",
      "\n",
      "fitted_model = joblib.load('model.pkl')\n",
      "\n",
      "y_pred, X_trans = fitted_model.rolling_evaluation(X_test_df, y_test_df.values)\n",
      "\n",
      "# Add predictions, actuals, and horizon relative to rolling origin to the test feature data\n",
      "assign_dict = {'horizon_origin': X_trans['horizon_origin'].values, 'predicted': y_pred,\n",
      "               target_column_name: y_test_df[target_column_name].values}\n",
      "df_all = X_test_df.assign(**assign_dict)\n",
      "\n",
      "file_name = 'outputs/predictions.csv'\n",
      "export_csv = df_all.to_csv(file_name, header=True)\n",
      "\n",
      "# Upload the predictions into artifacts\n",
      "run.upload_file(name=file_name, path_or_stream=file_name)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('forecasting_script.py', 'r') as cefr:\n",
    "    print(cefr.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "script_folder = os.path.join(os.getcwd(), 'forecast')\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "shutil.copy('forecasting_script.py', script_folder)\n",
    "\n",
    "# Create the explainer script that will run on the remote compute.\n",
    "script_file_name = script_folder + '/forecasting_script.py'\n",
    "\n",
    "# Open the sample script for modification\n",
    "with open(script_file_name, 'r') as cefr:\n",
    "    content = cefr.read()\n",
    "\n",
    "# Replace the values in train_explainer.py file with the appropriate values\n",
    "content = content.replace('<<train_experiment_name>>', experiment_name) # your training experiment name.\n",
    "content = content.replace('<<train_run_id>>', best_child_run_id) # Training Run-id.\n",
    "content = content.replace('<<target_column_name>>', target_column_name) # Your target column name\n",
    "# Name of your test dataset register with your workspace\n",
    "content = content.replace('<<test_dataset_name>>', test_dataset_name)\n",
    "\n",
    "# Write sample file into your script folder.\n",
    "with open(script_file_name, 'w') as cefw:\n",
    "    cefw.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For brevity, we have created a function called run_forecast that submits the test data to the best model determined during the training run and retrieves forecasts. The test set is longer than the forecast horizon specified at train time, so the forecasting script uses a so-called rolling evaluation to generate predictions over the whole test set. A rolling evaluation iterates the forecaster over the test set, using the actuals in the test set to make lag features as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_experiment_name = experiment_name + \"_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a 'CommandJob' to submit the custom script to run the explainer\n",
    "from azure.ml.entities import CommandJob, Code\n",
    "from azureml.core import Run\n",
    "mlflow.set_experiment(test_experiment_name)\n",
    "\n",
    "#TODO: Here we create an environment object by loading a downloaded conda env from the training run.\n",
    "train_experiment = Experiment(ws_tmp, experiment_name)\n",
    "best_child_run = Run(experiment=train_experiment, run_id=best_child_run_id)\n",
    "\n",
    "best_child_run.download_file('outputs/conda_env_v_1_0_0.yml', 'condafile.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Environment({'is_anonymous': False, 'name': 'test-env-1', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/yunba_test_rg/providers/Microsoft.MachineLearningServices/workspaces/yunba-test-ws-eastus2/environments/test-env-1/versions/1', 'base_path': './', 'creation_context': <azure.ml._restclient.v2021_03_01_preview.models._models_py3.SystemData object at 0x000002C21598AE80>, 'version': 1, 'conda_file': OrderedDict([('channels', ['anaconda', 'conda-forge']), ('dependencies', ['python=3.6.2', OrderedDict([('pip', ['azureml-train-automl-runtime==1.32.0', 'inference-schema', 'azureml-interpret==1.32.0', 'azureml-defaults==1.32.0'])]), 'numpy>=1.16.0,<1.19.0', 'pandas==0.25.1', 'scikit-learn==0.22.1', 'py-xgboost<=0.90', 'fbprophet==0.5', 'holidays==0.9.11', 'psutil>=5.2.2,<6.0.0']), ('name', 'azureml_c199a2d8511501c9bde5dfe3639e54c9')]), 'path': None, 'docker': <azure.ml.entities._assets.environment._DockerConfiguration object at 0x000002C215BDF860>, 'inference_config': None, 'os_type': 'Linux'})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ml.entities._assets.environment import Environment\n",
    "\n",
    "# environment = client.environments.get(\"AutoML-env\")\n",
    "environment = Environment(name=\"test-env-1\", version=1, conda_file='condafile.yml',\n",
    "                          docker_image='mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.2-cudnn8-ubuntu18.04:20210507.v1')\n",
    "environment\n",
    "client.environments.create_or_update(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AzureCliCredential.get_token failed: Please run 'az login' to set up an account\n",
      "AzureCliCredential.get_token failed: Please run 'az login' to set up an account\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommandJob({'parameters': {}, 'type': 'command_job', 'status': 'Starting', 'output': None, 'log_files': None, 'name': 'e3866325-dc1e-4215-a332-9a706c24fdcf', 'description': None, 'tags': {'training_run_id': '5e759c10-d73a-46fb-8b3f-3c0616c05fbf_104'}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/CESARDELATORRE/Easy-AutoML-MLOps.git', 'mlflow.source.git.branch': 'master', 'mlflow.source.git.commit': '1ae739f365b9f7679a9b55c03fb2c4b2223bddf5', 'azureml.git.dirty': 'True', '_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'e22ce1c1-43a9-461f-8b27-5f0536f5decb'}, 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/yunba_test_rg/providers/Microsoft.MachineLearningServices/workspaces/yunba-test-ws-eastus2/jobs/e3866325-dc1e-4215-a332-9a706c24fdcf', 'base_path': './', 'creation_context': <azure.ml._restclient.v2020_09_01_preview.models._models_py3.SystemData object at 0x000002C215A60F28>, 'inputs': {}, 'command': 'python forecasting_script.py', 'input_ports': {}, 'data_bindings': {}, 'code': '98f439f0-3172-4093-abdf-fafa484f1ed2:1', 'environment': 'test-env-1:1', 'distribution': None, 'compute': {'instance_count': 1, 'target': 'cpu-cluster', 'is_local': False, 'instance_type': None, 'location': None, 'properties': None}, 'experiment_name': 'forecasting-bike-share', 'interaction_endpoints': {'Tracking': <azure.ml._restclient.v2020_09_01_preview.models._models_py3.JobEndpoint object at 0x000002C215A602E8>, 'Studio': <azure.ml._restclient.v2020_09_01_preview.models._models_py3.JobEndpoint object at 0x000002C215A60048>}, 'timeout': None, 'identity': None, 'environment_variables': {}})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute = compute_settings\n",
    "\n",
    "command_job = CommandJob(\n",
    "    command=\"python forecasting_script.py\",\n",
    "    code=Code(local_path=script_folder),\n",
    "    environment=environment,\n",
    "    compute=compute,\n",
    "    tags={'training_run_id':\n",
    "           best_child_run_id,\n",
    "#            'run_algorithm':\n",
    "#            train_run.properties['run_algorithm'],\n",
    "#            'valid_score':\n",
    "#            train_run.properties['score'],\n",
    "#            'primary_metric':\n",
    "#            train_run.properties['primary_metric']\n",
    "         }\n",
    ")\n",
    "\n",
    "created_command_job = client.jobs.create_or_update(command_job)\n",
    "created_command_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studio URL:  https://ml.azure.com/runs/e3866325-dc1e-4215-a332-9a706c24fdcf?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/yunba_test_rg/workspaces/yunba-test-ws-eastus2&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "print(\"Studio URL: \", created_command_job.interaction_endpoints[\"Studio\"].endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the prediction result for metrics calcuation\n",
    "The test data with predictions are saved in artifact outputs/predictions.csv. You can download it and calculation some error metrics for the forecasts and vizualize the predictions vs. the actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote_run.download_file('outputs/predictions.csv', 'predictions.csv')\n",
    "# df_all = pd.read_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.automl.core.shared import constants\n",
    "# from azureml.automl.runtime.shared.score import scoring\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# # use automl metrics module\n",
    "# scores = scoring.score_regression(\n",
    "#     y_test=df_all[target_column_name],\n",
    "#     y_pred=df_all['predicted'],\n",
    "#     metrics=list(constants.Metric.SCALAR_REGRESSION_SET))\n",
    "\n",
    "# print(\"[Test data scores]\\n\")\n",
    "# for key, value in scores.items():    \n",
    "#     print('{}:   {:.3f}'.format(key, value))\n",
    "    \n",
    "# # Plot outputs\n",
    "# %matplotlib inline\n",
    "# test_pred = plt.scatter(df_all[target_column_name], df_all['predicted'], color='b')\n",
    "# test_test = plt.scatter(df_all[target_column_name], df_all[target_column_name], color='g')\n",
    "# plt.legend((test_pred, test_test), ('prediction', 'truth'), loc='upper left', fontsize=8)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details on what metrics are included and how they are calculated, please refer to [supported metrics](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml#regressionforecasting-metrics). You could also calculate residuals, like described [here](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml#residuals).\n",
    "\n",
    "\n",
    "Since we did a rolling evaluation on the test set, we can analyze the predictions by their forecast horizon relative to the rolling origin. The model was initially trained at a forecast horizon of 14, so each prediction from the model is associated with a horizon value from 1 to 14. The horizon values are in a column named, \"horizon_origin,\" in the prediction set. For example, we can calculate some of the error metrics grouped by the horizon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from metrics_helper import MAPE, APE\n",
    "# df_all.groupby('horizon_origin').apply(\n",
    "#     lambda df: pd.Series({'MAPE': MAPE(df[target_column_name], df['predicted']),\n",
    "#                           'RMSE': np.sqrt(mean_squared_error(df[target_column_name], df['predicted'])),\n",
    "#                           'MAE': mean_absolute_error(df[target_column_name], df['predicted'])}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To drill down more, we can look at the distributions of APE (absolute percentage error) by horizon. From the chart, it is clear that the overall MAPE is being skewed by one particular point where the actual value is of small absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_APE = df_all.assign(APE=APE(df_all[target_column_name], df_all['predicted']))\n",
    "# APEs = [df_all_APE[df_all['horizon_origin'] == h].APE.values for h in range(1, forecast_horizon + 1)]\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.boxplot(APEs)\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel('horizon')\n",
    "# plt.ylabel('APE (%)')\n",
    "# plt.title('Absolute Percentage Errors by Forecast Horizon')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "jialiu"
   }
  ],
  "category": "tutorial",
  "compute": [
   "Remote"
  ],
  "datasets": [
   "BikeShare"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "file_extension": ".py",
  "framework": [
   "Azure ML AutoML"
  ],
  "friendly_name": "Forecasting BikeShare Demand",
  "index_order": 1,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "tags": [
   "Forecasting"
  ],
  "task": "Forecasting",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
