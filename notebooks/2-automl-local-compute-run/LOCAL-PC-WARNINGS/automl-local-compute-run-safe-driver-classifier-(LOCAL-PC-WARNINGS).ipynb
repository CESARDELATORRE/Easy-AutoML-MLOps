{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AutoML Local Compute Run \n",
    "## (Porto Seguro's Safe Driving Prediction)\n",
    "\n",
    "Now let's use Azure Automated ML!\n",
    "\n",
    "In this notebook you are going to use a **'Local Compute Run'** which is a better approach when getting started and trying small datasets because it needs less overhead on infrastructure preparation since it'll use your read-to-run Jupyter environment and compute from your machine (versus Azure ML remote runs which require to sping up VMs in the cloud for remote compute).\n",
    "\n",
    "However, when targeting larger datasets and production trainings, it'll be better to use Azure ML Remote Compute since you will be able to parallelize runs/trainings and scale out on multiple VMs in the Azure ML training cluster. You can see that other approach in the 'automl-remote-compute-run-safe-driver-classifier.ipynb' notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed Packages\n",
    "\n",
    "Import the packages needed for this solution notebook. The most widely used package for machine learning is [scikit-learn](https://scikit-learn.org/stable/), [pandas](https://pandas.pydata.org/docs/getting_started/index.html#getting-started), and [numpy](https://numpy.org/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Azure ML SDK version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was tested using version 1.6.0 of the Azure ML SDK\n",
      "You are currently using version 1.6.0 of the Azure ML SDK\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"This notebook was tested using version 1.6.0 of the Azure ML SDK\")\n",
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get Azure ML Workspace to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "# Get Workspace defined in by default config.json file\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from file into regular Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
       "0              0              0              1              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              0              1              0              0       ...         \n",
       "4              0              1              0              0       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directly load from file into Pandas DataFrame\n",
    "DATA_DIR = \"../../data/\"\n",
    "data_df = pd.read_csv(os.path.join(DATA_DIR, 'porto_seguro_safe_driver_prediction_train.csv'))\n",
    "\n",
    "print(data_df.shape)\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Test Sets\n",
    "\n",
    "Partitioning data into training, validation, and holdout/test sets allows you to develop highly accurate models that are relevant to data that you collect in the future, not just the data the model was trained on. \n",
    "\n",
    "In this notebook we holdout a test dataset to calculate the metrics with that set \"not seen\" by AutoML, after the AutoML process is finished.\n",
    "Not taking into account the test dataset, AutoML will by default internally either use a validation dataset split from the train dataset or use cross-validation, depending on the size of the data (larger than 20k rows will use validation split), or as explicitely specified in the AutoMLConfig class (Validation-split vs. Cross-Validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(535690, 59)\n",
      "(59522, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.356900e+05</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.00000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "      <td>535690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.437339e+05</td>\n",
       "      <td>0.036433</td>\n",
       "      <td>1.900314</td>\n",
       "      <td>1.359226</td>\n",
       "      <td>4.422926</td>\n",
       "      <td>0.416888</td>\n",
       "      <td>0.404969</td>\n",
       "      <td>0.393683</td>\n",
       "      <td>0.256675</td>\n",
       "      <td>0.164130</td>\n",
       "      <td>...</td>\n",
       "      <td>5.441373</td>\n",
       "      <td>1.441154</td>\n",
       "      <td>2.871545</td>\n",
       "      <td>7.53850</td>\n",
       "      <td>0.122323</td>\n",
       "      <td>0.627996</td>\n",
       "      <td>0.553869</td>\n",
       "      <td>0.287334</td>\n",
       "      <td>0.349058</td>\n",
       "      <td>0.153298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.295112e+05</td>\n",
       "      <td>0.187366</td>\n",
       "      <td>1.983858</td>\n",
       "      <td>0.665157</td>\n",
       "      <td>2.699572</td>\n",
       "      <td>0.493313</td>\n",
       "      <td>1.350742</td>\n",
       "      <td>0.488566</td>\n",
       "      <td>0.436799</td>\n",
       "      <td>0.370394</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333417</td>\n",
       "      <td>1.202829</td>\n",
       "      <td>1.694241</td>\n",
       "      <td>2.74664</td>\n",
       "      <td>0.327658</td>\n",
       "      <td>0.483340</td>\n",
       "      <td>0.497090</td>\n",
       "      <td>0.452519</td>\n",
       "      <td>0.476673</td>\n",
       "      <td>0.360274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.717152e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.433270e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.115636e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.488027e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         target      ps_ind_01  ps_ind_02_cat  \\\n",
       "count  5.356900e+05  535690.000000  535690.000000  535690.000000   \n",
       "mean   7.437339e+05       0.036433       1.900314       1.359226   \n",
       "std    4.295112e+05       0.187366       1.983858       0.665157   \n",
       "min    7.000000e+00       0.000000       0.000000      -1.000000   \n",
       "25%    3.717152e+05       0.000000       0.000000       1.000000   \n",
       "50%    7.433270e+05       0.000000       1.000000       1.000000   \n",
       "75%    1.115636e+06       0.000000       3.000000       2.000000   \n",
       "max    1.488027e+06       1.000000       7.000000       4.000000   \n",
       "\n",
       "           ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  ps_ind_06_bin  \\\n",
       "count  535690.000000  535690.000000  535690.000000  535690.000000   \n",
       "mean        4.422926       0.416888       0.404969       0.393683   \n",
       "std         2.699572       0.493313       1.350742       0.488566   \n",
       "min         0.000000      -1.000000      -1.000000       0.000000   \n",
       "25%         2.000000       0.000000       0.000000       0.000000   \n",
       "50%         4.000000       0.000000       0.000000       0.000000   \n",
       "75%         6.000000       1.000000       0.000000       1.000000   \n",
       "max        11.000000       1.000000       6.000000       1.000000   \n",
       "\n",
       "       ps_ind_07_bin  ps_ind_08_bin       ...           ps_calc_11  \\\n",
       "count  535690.000000  535690.000000       ...        535690.000000   \n",
       "mean        0.256675       0.164130       ...             5.441373   \n",
       "std         0.436799       0.370394       ...             2.333417   \n",
       "min         0.000000       0.000000       ...             0.000000   \n",
       "25%         0.000000       0.000000       ...             4.000000   \n",
       "50%         0.000000       0.000000       ...             5.000000   \n",
       "75%         1.000000       0.000000       ...             7.000000   \n",
       "max         1.000000       1.000000       ...            19.000000   \n",
       "\n",
       "          ps_calc_12     ps_calc_13    ps_calc_14  ps_calc_15_bin  \\\n",
       "count  535690.000000  535690.000000  535690.00000   535690.000000   \n",
       "mean        1.441154       2.871545       7.53850        0.122323   \n",
       "std         1.202829       1.694241       2.74664        0.327658   \n",
       "min         0.000000       0.000000       0.00000        0.000000   \n",
       "25%         1.000000       2.000000       6.00000        0.000000   \n",
       "50%         1.000000       3.000000       7.00000        0.000000   \n",
       "75%         2.000000       4.000000       9.00000        0.000000   \n",
       "max        10.000000      13.000000      23.00000        1.000000   \n",
       "\n",
       "       ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "count   535690.000000   535690.000000   535690.000000   535690.000000   \n",
       "mean         0.627996        0.553869        0.287334        0.349058   \n",
       "std          0.483340        0.497090        0.452519        0.476673   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        0.000000        0.000000   \n",
       "50%          1.000000        1.000000        0.000000        0.000000   \n",
       "75%          1.000000        1.000000        1.000000        1.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_20_bin  \n",
       "count   535690.000000  \n",
       "mean         0.153298  \n",
       "std          0.360274  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split in train/test datasets (Test=10%, Train=90%)\n",
    "\n",
    "# Split in full sets, if not stratifying\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.1, random_state=0)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Azure AutoML automatically searching for the 'best model' (Best algorithms and best hyper-parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List and select primary metric to drive the AutoML classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['norm_macro_recall',\n",
       " 'accuracy',\n",
       " 'precision_score_weighted',\n",
       " 'AUC_weighted',\n",
       " 'average_precision_score_weighted']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train import automl\n",
    "    \n",
    "# Get a list of valid metrics for your given task\n",
    "automl.utilities.get_primary_metrics('classification')\n",
    "\n",
    "# List of possible primary metrics is here:\n",
    "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#primary-metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AutoML Experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# You can provide additional settings as a **kwargs parameter for the AutoMLConfig object\n",
    "automl_settings = {\n",
    "      \"blacklist_models\":['LogisticRegression', 'ExtremeRandomTrees', 'RandomForest'], \n",
    "      # \"whitelist_models\": ['LightGBM'],\n",
    "      \"validation_size\": 0.1\n",
    "      # \"validation_data\": validation_df,  # If you have an explicit validation set\n",
    "      # \"n_cross_validations\": 5,\n",
    "      # \"experiment_exit_score\": 0.7,\n",
    "      # \"max_cores_per_iteration\": -1,\n",
    "      \"enable_voting_ensemble\": 'False',\n",
    "      \"enable_stack_ensemble\": 'False'\n",
    "}\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_config = AutoMLConfig(task='classification',\n",
    "                             primary_metric='AUC_weighted',                           \n",
    "                             training_data= train_df,  # Pandas DataFrame\n",
    "                             label_column_name=\"target\",                                                    \n",
    "                             enable_early_stopping= True,\n",
    "                             iterations=15,                    \n",
    "                             experiment_timeout_hours=1,\n",
    "                             featurization=\"auto\",\n",
    "                             model_explainability=True,\n",
    "                             **automl_settings\n",
    "                             )\n",
    "\n",
    "# Explanation of Settings: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings\n",
    "\n",
    "# AutoMLConfig info on: \n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment with multiple child runs under the covers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK_local_porto_seguro_driver_pred\n",
      "Running on local machine\n",
      "Parent Run ID: AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4\n",
      "\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       ALERTED\n",
      "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
      "+=================================+=================================+======================================+\n",
      "|17552                            |1                                |482121                                |\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:02:14       0.6369    0.6369\n",
      "         1   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml/ExperimentRun/dcid.AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4_1/outputs/conda_env_v_1_0_0.yml?sv=2019-02-02&sr=b&sig=bHim8LHjQtmRL8RRIC9Xgl%2BC0wvPVS3nG8sX7no7C3g%3D&st=2020-06-06T19%3A19%3A44Z&se=2020-06-07T19%3A29%3A44Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxAbsScaler XGBoostClassifier                 0:03:31       0.6382    0.6382\n",
      "         2   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml/ExperimentRun/dcid.AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4_2/outputs/model.pkl?sv=2019-02-02&sr=b&sig=sF%2F8ev9Rgy%2BFhcm9D5NQlW%2Bu%2FGJbzGuHmhTyKhO7HX0%3D&st=2020-06-06T19%3A21%3A45Z&se=2020-06-07T19%3A31%3A45Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNRFF4T1RRek1EUSUzRA%3D%3D&timeout=30\n",
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml/ExperimentRun/dcid.AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4_2/outputs/model.pkl?sv=2019-02-02&sr=b&sig=sF%2F8ev9Rgy%2BFhcm9D5NQlW%2Bu%2FGJbzGuHmhTyKhO7HX0%3D&st=2020-06-06T19%3A21%3A45Z&se=2020-06-07T19%3A31%3A45Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXlNVE01TURrMU1EUSUzRA%3D%3D&timeout=30\n",
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml/ExperimentRun/dcid.AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4_2/outputs/model.pkl?sv=2019-02-02&sr=b&sig=sF%2F8ev9Rgy%2BFhcm9D5NQlW%2Bu%2FGJbzGuHmhTyKhO7HX0%3D&st=2020-06-06T19%3A21%3A45Z&se=2020-06-07T19%3A31%3A45Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXlNelE0T0RFd01qUSUzRA%3D%3D&timeout=30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxAbsScaler LightGBM                          0:02:20       0.6262    0.6382\n",
      "         3   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml/ExperimentRun/dcid.AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4_3/outputs/model.pkl?sv=2019-02-02&sr=b&sig=Fb5e%2BAzPfjNfMeSj1o7W7rWDRC4jc7EbrUocEHspL7o%3D&st=2020-06-06T19%3A24%3A35Z&se=2020-06-07T19%3A34%3A35Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30\n",
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml/ExperimentRun/dcid.AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4_3/outputs/pipeline_graph.json?sv=2019-02-02&sr=b&sig=UFyG9EmQilZYMqOLhN3s1Jm7pZPlLig0PXGXuhibs50%3D&st=2020-06-06T19%3A24%3A35Z&se=2020-06-07T19%3A34%3A35Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30\n",
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml/ExperimentRun/dcid.AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4_3/outputs/model.pkl?sv=2019-02-02&sr=b&sig=Fb5e%2BAzPfjNfMeSj1o7W7rWDRC4jc7EbrUocEHspL7o%3D&st=2020-06-06T19%3A24%3A35Z&se=2020-06-07T19%3A34%3A35Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQTFNRE16TVRZME9EQSUzRA%3D%3D&timeout=30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScalerWrapper XGBoostClassifier        0:02:26       0.6212    0.6382\n",
      "         4   MaxAbsScaler SGD                               0:01:55       0.5709    0.6382\n",
      "         5   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml/ExperimentRun/dcid.AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4_5/outputs/model.pkl?sv=2019-02-02&sr=b&sig=BT9Inwqjyi9wR8Cefsey5TjCOv7LidTLh6Bkju9Dpro%3D&st=2020-06-06T19%3A28%3A42Z&se=2020-06-07T19%3A38%3A42Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNRFF4T1RRek1EUSUzRA%3D%3D&timeout=30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScalerWrapper LightGBM                 0:01:58       0.6313    0.6382\n",
      "         6   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml/ExperimentRun/dcid.AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4_6/outputs/scoring_file_v_1_0_0.py?sv=2019-02-02&sr=b&sig=KC6ybvcS%2B%2Fu4%2B%2B%2FE3rcpyoCES4CPMuxfnfA%2BD0ix6k8%3D&st=2020-06-06T19%3A31%3A11Z&se=2020-06-07T19%3A41%3A11Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30\n",
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml/ExperimentRun/dcid.AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4_6/outputs/model.pkl?sv=2019-02-02&sr=b&sig=14dOx8F8UNk87QdysfB%2FSSm3O%2F8nKLy%2FDAm957sNaDE%3D&st=2020-06-06T19%3A31%3A11Z&se=2020-06-07T19%3A41%3A11Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXpPRFU0TnpVNU5qZyUzRA%3D%3D&timeout=30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseNormalizer XGBoostClassifier             0:02:21       0.6126    0.6382\n",
      "         7   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml/ExperimentRun/dcid.AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4_7/outputs/model.pkl?sv=2019-02-02&sr=b&sig=HxTyYNTTtEwTe79%2BvIURTUQZ9Mx%2BlbwlPpbrK0kMPhU%3D&st=2020-06-06T19%3A33%3A13Z&se=2020-06-07T19%3A43%3A13Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNRFF4T1RRek1EUSUzRA%3D%3D&timeout=30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxAbsScaler SGD                               0:01:57       0.5646    0.6382\n",
      "         8   MaxAbsScaler SGD                               0:01:56       0.5682    0.6382\n",
      "         9   StandardScalerWrapper XGBoostClassifier        0:02:21       0.6281    0.6382\n",
      "        10   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\",))': /azureml/ExperimentRun/dcid.AutoML_2c4e24f7-aa40-40e0-afb2-8b5f9fb9d6a4_10/outputs/model.pkl?sv=2019-02-02&sr=b&sig=8wK6RSDTbYKoQ8ChinV1hN1A%2F8Mj7I0X843bje5R4OM%3D&st=2020-06-06T19%3A39%3A40Z&se=2020-06-07T19%3A49%3A40Z&sp=rcw&comp=block&blockid=TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQXdNREF3TURBd01EQSUzRA%3D%3D&timeout=30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxAbsScaler LightGBM                          0:01:55       0.6232    0.6382\n",
      "        11   MaxAbsScaler MultinomialNaiveBayes             0:02:14       0.6234    0.6382\n",
      "        12   MaxAbsScaler SGD                               0:02:07       0.6210    0.6382\n",
      "        13   "
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = \"SDK_local_porto_seguro_driver_pred\"\n",
    "print(experiment_name)\n",
    "\n",
    "experiment = Experiment(workspace=ws, \n",
    "                        name=experiment_name)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "run = experiment.submit(automl_config, show_output=True)\n",
    "\n",
    "print('Manual run timing: --- %s minutes needed for running the whole Remote AutoML Experiment ---' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore results with Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the results of automatic training with a Jupyter widget: https://docs.microsoft.com/en-us/python/api/azureml-widgets/azureml.widgets?view=azure-ml-py\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the 'Best' Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = run.get_output()\n",
    "print(best_run)\n",
    "print('--------')\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions and calculate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Test Data: Separate x_test set (feature columns) from y_test (label column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_test_df = test_df.copy()\n",
    "\n",
    "if 'target' in x_test_df.columns:\n",
    "    y_test_df = x_test_df.pop('target')\n",
    "\n",
    "print(test_df.shape)\n",
    "print(x_test_df.shape)\n",
    "print(y_test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions in bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the best model making predictions with the test dataset\n",
    "y_predictions = fitted_model.predict(x_test_df)\n",
    "\n",
    "print('30 predictions: ')\n",
    "print(y_predictions[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the predictions' probabilities needed to calculate ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probabilities = fitted_model.predict_proba(x_test_df)\n",
    "\n",
    "print(class_probabilities.shape)\n",
    "\n",
    "print('Some class probabilities...: ')\n",
    "print(class_probabilities[:3])\n",
    "print('')\n",
    "print('Probabilities for class 1:')\n",
    "print(class_probabilities[:,1])\n",
    "print('')\n",
    "print('Probabilities for class 0:')\n",
    "print(class_probabilities[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "Evaluating performance is an essential task in machine learning. In this case, because this is a classification problem, the data scientist elected to use an AUC - ROC Curve. When we need to check or visualize the performance of the multi - class classification problem, we use AUC (Area Under The Curve) ROC (Receiver Operating Characteristics) curve. It is one of the most important evaluation metrics for checking any classification model’s performance.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Oxana_Trifonova/publication/276079439/figure/fig2/AS:614187332034565@1523445079168/An-example-of-ROC-curves-with-good-AUC-09-and-satisfactory-AUC-065-parameters.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 12px; width: 320px; height: 239px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the ROC AUC with probabilities vs. the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ROC AUC *method 1*:')\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test_df, class_probabilities[:,1])\n",
    "metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('ROC AUC *method 2*:')\n",
    "print(roc_auc_score(y_test_df, class_probabilities[:,1]))\n",
    "\n",
    "print('ROC AUC Weighted:')\n",
    "print(roc_auc_score(y_test_df, class_probabilities[:,1], average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Accuracy with predictions vs. the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test_df, y_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model pickle file from the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model .pkl file to local (Using the 'run' object)\n",
    "best_run.download_file('outputs/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model in memory from .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model into memory\n",
    "import joblib\n",
    "fitted_model = joblib.load('model.pkl')\n",
    "print(fitted_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 (aml-conda-env)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
