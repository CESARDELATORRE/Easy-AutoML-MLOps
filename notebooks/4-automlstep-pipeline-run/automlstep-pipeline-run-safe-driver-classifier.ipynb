{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning Pipeline with AutoMLStep (AutoML training in pipeline)\n",
    "This notebook demonstrates the use of **AutoMLStep** for training in Azure Machine Learning Pipeline.\n",
    "As secondary pipeline step, it also uses a **PythonScriptStep** for registering the trained model into AML Workspace model registry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this example we showcase AML Pipelines, how you can train a model with AutoML as one pipeline step with AutoMLStep while using AML Datasets as input data. \n",
    "\n",
    "If you are using an Azure Machine Learning Compute Instance (aka. Notebook VM), you are all set. Otherwise, make sure you have executed the [configuration](https://aka.ms/pl-config) and [Azure Automated ML setup](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/automated-machine-learning#setup-using-a-local-conda-environment) before running this notebook.\n",
    "\n",
    "In this notebook you will learn how to:\n",
    "\n",
    "1. Create an `Experiment` in an existing `Workspace`.\n",
    "2. Create or Attach existing AmlCompute to a workspace.\n",
    "3. Define data loading in a **TabularDataset**.\n",
    "4. Configure AutoML using **AutoMLConfig**.\n",
    "5. Configure **AutoMLStep** step for training\n",
    "6. Configure **PythonScriptStep** for registering the model in the Workspace\n",
    "7. Run the AML pipeline using AmlCompute\n",
    "8. Explore the results.\n",
    "9. Test the best fitted model.\n",
    "10. Publish the Pipeline in the Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Machine Learning and Pipeline SDK-specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import pkg_resources\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from azureml.pipeline.steps import AutoMLStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Azure ML SDK version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "print(\"This notebook was created and tested using version 1.2.0 of the Azure ML SDK\")\n",
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "Initialize a workspace object from persisted configuration. Make sure the config file is present at .\\config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML experiment\n",
    "Let's create an experiment named \"automlstep-classif-porto\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a name for the run history container in the workspace.\n",
    "experiment_name = 'automlstep-classif-porto'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or Attach an AmlCompute cluster\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for your AutoML run. In this tutorial, you get the default `AmlCompute` as your training compute resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "# Define remote compute target to use\n",
    "# Further docs on Remote Compute Target: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-remote\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "amlcompute_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "cts = ws.compute_targets\n",
    "\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
    "     found = True\n",
    "     print('Found existing training cluster.')\n",
    "     # Get existing cluster\n",
    "     # Method 1:\n",
    "     aml_remote_compute = cts[amlcompute_cluster_name]\n",
    "     # Method 2:\n",
    "     # aml_remote_compute = ComputeTarget(ws, amlcompute_cluster_name)\n",
    "    \n",
    "if not found:\n",
    "     print('Creating a new training cluster...')\n",
    "     provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D13_V2\", # for GPU, use \"STANDARD_NC12\"\n",
    "                                                                 #vm_priority = 'lowpriority', # optional\n",
    "                                                                 max_nodes = 5)\n",
    "     # Create the cluster.\n",
    "     aml_remote_compute = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
    "    \n",
    "print('Checking cluster status...')\n",
    "# Can poll for a minimum number of nodes and for a specific timeout.\n",
    "# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "aml_remote_compute.wait_for_completion(show_output = True, min_node_count = 0, timeout_in_minutes = 20)\n",
    "\n",
    "# For a more detailed view of current AmlCompute status, use get_status()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (***Optional***) Submit dataset file into DataStore (Azure Blob under the covers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload(src_dir='../../data/', \n",
    "                 target_path='Datasets/porto_seguro_safe_driver_prediction', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into Azure ML Dataset and Register into Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load the dataset from the Workspace. Otherwise, create it from the file in the HTTP URL\n",
    "found = False\n",
    "aml_dataset_name = \"porto_seguro_safe_driver_prediction_train\"\n",
    "\n",
    "if aml_dataset_name in ws.datasets.keys(): \n",
    "       found = True\n",
    "       dataset = ws.datasets[aml_dataset_name] \n",
    "       print(\"Dataset found and loaded from the Workspace\")\n",
    "       \n",
    "if not found:\n",
    "        # Create AML Dataset and register it into Workspace\n",
    "        print(\"Dataset does not exist in the current Workspace. It will be imported and registered.\")\n",
    "        \n",
    "        # Option A: Create AML Dataset from file in AML DataStore\n",
    "        datastore = ws.get_default_datastore()\n",
    "        dataset = Dataset.Tabular.from_delimited_files(path=datastore.path('Datasets/porto_seguro_safe_driver_prediction/porto_seguro_safe_driver_prediction_train.csv'))\n",
    "        data_origin_type = 'AMLDataStore'\n",
    "        \n",
    "        # Option B: Create AML Dataset from file in HTTP URL\n",
    "        # data_url = 'https://azmlworkshopdata.blob.core.windows.net/safedriverdata/porto_seguro_safe_driver_prediction_train.csv'\n",
    "        # aml_dataset = Dataset.Tabular.from_delimited_files(data_url)  \n",
    "        # data_origin_type = 'HttpUrl'\n",
    "        \n",
    "        print(aml_dataset)\n",
    "                \n",
    "        #Register Dataset in Workspace\n",
    "        registration_method = 'SDK'  # or 'UI'\n",
    "        dataset = aml_dataset.register(workspace=ws,\n",
    "                                           name=aml_dataset_name,\n",
    "                                           description='Porto Seguro Safe Driver Prediction Train dataset file',\n",
    "                                           tags={'Registration-Method': registration_method, 'Data-Origin-Type': data_origin_type},\n",
    "                                           create_new_version=True)\n",
    "        \n",
    "        print(\"Dataset created from file and registered in the Workspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.take(5).to_pandas_dataframe().head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segregate a Test dataset for later testing and creating a confusion matrix\n",
    "Split original AML Tabular Dataset in two test/train AML Tabular Datasets (using AML DS function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name and target column of the Dataset to create \n",
    "train_dataset_name = \"porto_seguro_safe_driver_prediction_train90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split using Azure Tabular Datasets (Better for Remote Compute)\n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.tabulardataset?view=azure-ml-py#random-split-percentage--seed-none-\n",
    "\n",
    "train_dataset, test_dataset = dataset.random_split(0.9, seed=1)\n",
    "\n",
    "#Register Train Dataset (90%) after Split in Workspace\n",
    "registration_method = 'SDK'  # or 'UI'\n",
    "data_origin_type = 'SPLIT'\n",
    "train_dataset = train_dataset.register(workspace=ws,\n",
    "                                       name=train_dataset_name,\n",
    "                                       description='Porto Seguro Safe Driver Prediction Train dataset file (90%)',\n",
    "                                       tags={'Registration-Method': registration_method, 'Data-Origin-Type': data_origin_type},\n",
    "                                       create_new_version=True)\n",
    "\n",
    "# Load from Workspace\n",
    "train_dataset = ws.datasets[train_dataset_name] \n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas DF only to check the data\n",
    "train_df = train_dataset.to_pandas_dataframe()\n",
    "test_df = test_dataset.to_pandas_dataframe()\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List possible metrics to optimize for (primary metric) in Classification using AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train import automl\n",
    "\n",
    "# List of possible primary metrics is here:\n",
    "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#primary-metric\n",
    "    \n",
    "# Get a list of valid metrics for your given task\n",
    "automl.utilities.get_primary_metrics('classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train configuration in AutoMLConfig\n",
    "This creates a general AutoML settings object.\n",
    "\n",
    "Note that we're using a single algorithm (LightGBM as the only whitelisted algo) and a single iteration (iterations=1) just for the sake of time when trying the notebook so the end-to-end run needs less time.\n",
    "\n",
    "In a real training run you would let AutoML to try many iterations in order to find the \"best model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Path to the Azure ML project folder\n",
    "project_folder = './project'\n",
    "\n",
    "# You can provide additional settings as a **kwargs parameter for the AutoMLConfig object\n",
    "automl_settings = {\n",
    "      \"blacklist_models\":['LogisticRegression', 'ExtremeRandomTrees', 'RandomForest'], \n",
    "      # \"whitelist_models\": ['LightGBM'],\n",
    "      # \"n_cross_validations\": 5,\n",
    "      # \"validation_data\": test_dataset,   # Better to holdout the Test Dataset\n",
    "      \"experiment_exit_score\": 0.7\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(compute_target=aml_remote_compute,\n",
    "                             task='classification',\n",
    "                             primary_metric='AUC_weighted',                           \n",
    "                             training_data=train_dataset, # AML Dataset\n",
    "                             label_column_name=\"target\",\n",
    "                             path = project_folder,\n",
    "                             enable_early_stopping= True,\n",
    "                             iterations=20,\n",
    "                             max_concurrent_iterations=5,\n",
    "                             experiment_timeout_hours=1,                           \n",
    "                             featurization= 'auto',   # (auto/off) All feature columns in this dataset are numbers, no need to featurize with AML Dataset. \n",
    "                             debug_log='automated_ml_errors.log',\n",
    "                             verbosity= logging.INFO,\n",
    "                             model_explainability=True,\n",
    "                             enable_onnx_compatible_models=False,\n",
    "                             **automl_settings\n",
    "                             )\n",
    "\n",
    "# Explanation of Settings: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#configure-your-experiment-settings\n",
    "\n",
    "# AutoMLConfig info on: \n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.automlconfig.automlconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The AML Pipeline\n",
    "\n",
    "### PipelineData objects\n",
    "\n",
    "Let's first define the data (metrics and model) to be produced by the pipeline.\n",
    "\n",
    "The **PipelineData** object is a special kind of data reference that is used for interim storage locations that can be passed between pipeline steps.\n",
    "\n",
    "Note that we also need to pass it as a script argument so our code can access the datastore location referenced by the data reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "metrics_output_name = 'metrics_output'\n",
    "best_model_output_name = 'best_model_output'\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                            datastore=ds,\n",
    "                            pipeline_output_name=metrics_output_name,\n",
    "                            training_output=TrainingOutput(type='Metrics'))\n",
    "\n",
    "model_data = PipelineData(name='model_data',\n",
    "                          datastore=ds,\n",
    "                          pipeline_output_name=best_model_output_name,\n",
    "                          training_output=TrainingOutput(type='Model'))\n",
    "\n",
    "print(model_data.get_env_variable_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an AutoMLStep for training.\n",
    "Pipelines consist of one or more *steps*, which can be specialized steps like an AutoMLStep (like this step) for training a model, or Python scripts, or a data transfer step that copies data from one location to another. \n",
    "\n",
    "Each step can run in its own compute context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_step = AutoMLStep(\n",
    "    name='automl_module',\n",
    "    automl_config=automl_config,\n",
    "    outputs=[metrics_data, model_data],\n",
    "    allow_reuse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a PythonScriptStep to register the model in the Workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Environment and Conda dependencies needed to run the PythonScriptStep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment, Conda-Dependencies and RunConfiguration for PythonScriptStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import CondaDependencies, DEFAULT_CPU_IMAGE, RunConfiguration\n",
    "from azureml.core import Environment\n",
    "\n",
    "# Create an Environment for future usage\n",
    "custom_env = Environment(\"python-script-step-env\")\n",
    "custom_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "custom_env.docker.enabled = True \n",
    "custom_env.docker.base_image = azureml.core.runconfig.DEFAULT_CPU_IMAGE \n",
    "\n",
    "conda_dependencies = CondaDependencies.create(pip_packages=['azureml-sdk[automl]', 'applicationinsights'], #'azureml-explain-model'\n",
    "                                              conda_packages=['numpy==1.16.2'], \n",
    "                                              pin_sdk_version=False)\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "custom_env.python.conda_dependencies = conda_dependencies\n",
    "\n",
    "# Register the environment (To use it again)\n",
    "custom_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'python-script-step-env')\n",
    "\n",
    "# create a new RunConfig object\n",
    "conda_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Set compute target to AmlCompute\n",
    "conda_run_config.target = aml_remote_compute\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "conda_run_config.environment\n",
    "conda_run_config.environment = registered_env\n",
    "\n",
    "print('Run config is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model Step (Python Script Step)\n",
    "Script to register the model to the workspace.\n",
    "\n",
    "First, let's create a folder where the script will be placed.\n",
    "\n",
    "The best practice is to use separate folders for scripts and its dependent files for each step and specify that folder as the `source_directory` for the step. This helps reduce the size of the snapshot created for the step (only the specific folder is snapshotted). Since changes in any files in the `source_directory` would trigger a re-upload of the snapshot, this helps keep the reuse of the step when there are no changes in the `source_directory` of the step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "scripts_folder=\"Scripts\"\n",
    "os.makedirs(scripts_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the register_model.py script file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $scripts_folder/register_model.py\n",
    "from azureml.core.model import Model, Dataset\n",
    "from azureml.core.run import Run, _OfflineRun\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_name\")\n",
    "parser.add_argument(\"--model_path\")\n",
    "parser.add_argument(\"--ds_name\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(\"Argument 1(model_name): %s\" % args.model_name)\n",
    "print(\"Argument 2(model_path): %s\" % args.model_path)\n",
    "print(\"Argument 3(ds_name): %s\" % args.ds_name)\n",
    "\n",
    "run = Run.get_context()\n",
    "ws = None\n",
    "if type(run) == _OfflineRun:\n",
    "    ws = Workspace.from_config()\n",
    "else:\n",
    "    ws = run.experiment.workspace\n",
    "\n",
    "train_ds = Dataset.get_by_name(ws, args.ds_name)\n",
    "datasets = [(Dataset.Scenario.TRAINING, train_ds)]\n",
    "\n",
    "# Register model with training dataset\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_path=args.model_path,                  # File to upload and register as a model.\n",
    "                       model_name=args.model_name,                  # Name of the registered model in your workspace.\n",
    "                       datasets=datasets,\n",
    "                       description='Porto Seguro Safe Driving Prediction.',\n",
    "                       tags={'area': 'insurance', 'type': 'classification'}\n",
    "                      )\n",
    "\n",
    "print(\"Registered version {0} of model {1}\".format(model.version, model.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PythonScriptStep to run register_model.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineParameter\n",
    "\n",
    "# The model name with which to register the trained model in the workspace.\n",
    "model_name = \"porto-model-from-automlstep\"\n",
    "model_name_param = PipelineParameter(\"model_name\", default_value=model_name)\n",
    "\n",
    "# The Dataset name to relate with the model to register in the workspace.\n",
    "dataset_name_param = PipelineParameter(name=\"ds_name\", default_value=train_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PythonScriptStep for Model registration\n",
    "\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "register_model_step = PythonScriptStep(name=\"register_model\",                                      \n",
    "                                       source_directory = scripts_folder,            # Local folder with .py script\n",
    "                                       script_name=\"register_model.py\",\n",
    "                                       allow_reuse=False,\n",
    "                                       arguments=[\"--model_name\", model_name_param, \"--model_path\", model_data, \"--ds_name\", dataset_name_param],\n",
    "                                       inputs=[model_data],\n",
    "                                       compute_target=aml_remote_compute,\n",
    "                                       runconfig=conda_run_config)\n",
    "\n",
    "register_model_step.run_after(automl_step)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example, designed to demonstrate the principle. In reality, you could build more sophisticated logic into the pipeline steps - for example, evaluating the model against some test data to calculate a performance metric like AUC or accuracy, comparing the metric to that of any previously registered versions of the model, and only registering the new model if it performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline and add the multiple steps into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "pipeline = Pipeline(\n",
    "    description=\"pipeline_with_automlstep\",\n",
    "    workspace=ws,    \n",
    "    steps=[automl_step, register_model_step]) \n",
    "\n",
    "print(\"Pipeline is built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run = experiment.submit(pipeline, pipeline_parameters={\n",
    "        \"ds_name\": train_dataset_name, \"model_name\": model_name})\n",
    "\n",
    "print(\"Pipeline submitted for execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Results from Pipeline\n",
    "\n",
    "### Retrieve the metrics of all child runs\n",
    "Outputs of above run can be used as inputs of other steps in pipeline. In this tutorial, we will examine the outputs by retrieve output data and running some tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output = pipeline_run.get_pipeline_output(metrics_output_name)\n",
    "num_file_downloaded = metrics_output.download('.', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(metrics_output._path_on_datastore) as f:  \n",
    "   metrics_output_result = f.read()\n",
    "    \n",
    "deserialized_metrics_output = json.loads(metrics_output_result)\n",
    "df = pd.DataFrame(deserialized_metrics_output)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve info about the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_output = pipeline_run.get_pipeline_output(best_model_output_name)\n",
    "best_model_output\n",
    "# num_file_downloaded = best_model_output.download('.', show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_output = pipeline_run.get_pipeline_output(best_model_output_name)\n",
    "num_file_downloaded = best_model_output.download('.', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(best_model_output._path_on_datastore, \"rb\" ) as f:\n",
    "    best_model = pickle.load(f)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model (Make predictions, get probabilities and calculate metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep Test Data: Extract X values (feature columns) from test dataset and convert to NumPi array for predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_test_df = test_df.copy()\n",
    "\n",
    "if 'target' in x_test_df.columns:\n",
    "    y_test_df = x_test_df.pop('target')\n",
    "\n",
    "print(test_df.shape)\n",
    "print(x_test_df.shape)\n",
    "print(y_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Our Best Fitted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the best model making predictions with the test dataset\n",
    "y_predictions = best_model.predict(x_test_df)\n",
    "\n",
    "print('10 predictions: ')\n",
    "print(y_predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy with Scikit-Learn model:')\n",
    "print(accuracy_score(y_test_df, y_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate AUC with Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Probabilities/scores per class\n",
    "\n",
    "class_probabilities = best_model.predict_proba(x_test_df)\n",
    "print(class_probabilities.shape)\n",
    "\n",
    "print('Some class probabilities...: ')\n",
    "print(class_probabilities[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('ROC AUC:')\n",
    "print(roc_auc_score(y_test_df, class_probabilities[:,1]))\n",
    "\n",
    "print('ROC AUC Weighted:')\n",
    "print(roc_auc_score(y_test_df, class_probabilities[:,1], average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Confusion Matrix\n",
    "We will use confusion matrix to see how our model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to have installed: \n",
    "!pip install pandas_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "cm = ConfusionMatrix(y_test_df, y_predictions)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "cm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the Pipeline\n",
    "Now that you've created a pipeline and verified it works, you can publish it as a REST service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline.publish(name=\"Training_Pipeline_AutoMLStep_Porto\",\n",
    "                                      description=\"Pipeline with AutoMLStep for Training model for Porto Seguro Safe Driver\")\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigger the AML Pipeline by using the Pipeline REST Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. A real application would require a service principal with which to be authenticated, but to test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print(auth_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to call the REST interface. The pipeline runs asynchronously, so you'll get an identifier back, which you can use to track the pipeline experiment as it runs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The REST Endpoint\n",
    "Note that the published pipeline has an endpoint, which you can see in the Endpoints page (on the Pipeline Endpoints tab) in Azure Machine Learning studio. You can also find its URI as a property of the published pipeline object.\n",
    "So, you could also copy that REST Endpoint from the AML portal and paste it like here:\n",
    "\n",
    "rest_endpoint = \"Your opied REST Endpoint here\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have the run ID, you can use the RunDetails widget to view the experiment as it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "RunDetails(published_pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps!\n",
    "You can use the Azure Machine Learning extension for Azure DevOps to combine Azure ML pipelines with Azure DevOps pipelines (yes, it is confusing that they have the same name!) and integrate model retraining into a continuous integration/continuous deployment (CI/CD) process. For example you could use an Azure DevOps build pipeline to trigger an Azure ML pipeline that trains and registers a model, and when the model is registered it could trigger an Azure Devops release pipeline that deploys the model as a web service, along with the application or service that consumes the model."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "sanpil"
   }
  ],
  "category": "tutorial",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Custom"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "Automated Machine Learning"
  ],
  "friendly_name": "How to use AutoMLStep with AML Pipelines",
  "kernelspec": {
   "display_name": "Python 3.6.5 (aml-conda-env)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "order_index": 11,
  "star_tag": [
   "featured"
  ],
  "tags": [
   "None"
  ],
  "task": "Demonstrates the use of AutoMLStep"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
