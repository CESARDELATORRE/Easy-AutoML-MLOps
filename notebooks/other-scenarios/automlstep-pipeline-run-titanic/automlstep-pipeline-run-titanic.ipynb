{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Azure ML SDK version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ComputeTarget, Dataset, Datastore, Experiment, Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.pipeline.steps import AutoMLStep, PythonScriptStep\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was created and tested using version 1.3.0 of the Azure ML SDK\n",
      "You are currently using version 1.3.0 of the Azure ML SDK\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"This notebook was created and tested using version 1.3.0 of the Azure ML SDK\")\n",
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "if not 'titanic_ds' in ws.datasets.keys() :\n",
    "    # create a TabularDataset from Titanic training data\n",
    "    web_paths = ['https://dprepdata.blob.core.windows.net/demo/Titanic.csv',\n",
    "                 'https://dprepdata.blob.core.windows.net/demo/Titanic2.csv']\n",
    "    titanic_ds = Dataset.Tabular.from_delimited_files(path=web_paths)\n",
    "\n",
    "    titanic_ds.register(workspace = ws,\n",
    "                                     name = 'titanic_ds',\n",
    "                                     description = 'Titanic baseline data',\n",
    "                                     create_new_version = True)\n",
    "\n",
    "titanic_ds = Dataset.get_by_name(ws, 'titanic_ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure your storage and compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core import Datastore\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "compute_name = 'cpu-compute'\n",
    "if not compute_name in ws.compute_targets :\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                                min_nodes=0,\n",
    "                                                                max_nodes=1)\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # Show the result\n",
    "    print(compute_target.get_status().serialize())\n",
    "\n",
    "compute_target = ws.compute_targets[compute_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intermediate data between the data preparation and the automated ML step can be stored in the workspace's default datastore (object 'datastore' in the notebook), so we don't need to do more than call get_default_datastore() on the Workspace object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the training run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is making sure that the remote training run has all the dependencies that are required by the training steps. Dependencies and the runtime context are set by creating and configuring a RunConfiguration object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration, CondaDependencies\n",
    "\n",
    "aml_run_config = RunConfiguration()\n",
    "# Use just-specified compute target (\"cpu-compute\")\n",
    "aml_run_config.target = compute_target\n",
    "aml_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Add some packages relied on by data prep step\n",
    "aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=['pandas','scikit-learn'], \n",
    "    pip_packages=['azureml-sdk', 'azureml-dataprep[fuse,pandas]'], \n",
    "    pin_sdk_version=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for automated machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the data preparation code\n",
    "The baseline Titanic dataset consists of mixed numerical and text data, with some values missing. To prepare it for automated machine learning, the data preparation pipeline step will:\n",
    "\n",
    "Fill missing data with either random data or a category corresponding to \"Unknown\"\n",
    "Transform categorical data to integers\n",
    "Drop columns that we don't intend to use\n",
    "Split the data into training and testing sets\n",
    "Write the transformed data to the PipelineData output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataprep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataprep.py\n",
    "# dataprep.py\n",
    "from azureml.core import Run\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "RANDOM_SEED=42\n",
    "\n",
    "def prepare_age(df):\n",
    "    # Fill in missing Age values from distribution of present Age values \n",
    "    mean = df[\"Age\"].mean()\n",
    "    std = df[\"Age\"].std()\n",
    "    is_null = df[\"Age\"].isnull().sum()\n",
    "    # compute enough (== is_null().sum()) random numbers between the mean, std\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = df[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    df[\"Age\"] = age_slice\n",
    "    df[\"Age\"] = df[\"Age\"].astype(int)\n",
    "    \n",
    "    # Quantize age into 5 classes\n",
    "    df['Age_Group'] = pd.qcut(df['Age'],5, labels=False)\n",
    "    df.drop(['Age'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def prepare_fare(df):\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    df['Fare_Group'] = pd.qcut(df['Fare'],5,labels=False)\n",
    "    df.drop(['Fare'], axis=1, inplace=True)\n",
    "    return df \n",
    "\n",
    "def prepare_genders(df):\n",
    "    genders = {\"male\": 0, \"female\": 1, \"unknown\": 2}\n",
    "    df['Sex'] = df['Sex'].map(genders)\n",
    "    df['Sex'].fillna(2, inplace=True)\n",
    "    df['Sex'] = df['Sex'].astype(int)\n",
    "    return df\n",
    "\n",
    "def prepare_embarked(df):\n",
    "    df['Embarked'].replace('', 'U', inplace=True)\n",
    "    df['Embarked'].fillna('U', inplace=True)\n",
    "    ports = {\"S\": 0, \"C\": 1, \"Q\": 2, \"U\": 3}\n",
    "    df['Embarked'] = df['Embarked'].map(ports)\n",
    "    return df\n",
    "    \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_path', dest='output_path', required=True)\n",
    "args = parser.parse_args()\n",
    "    \n",
    "titanic_ds = Run.get_context().input_datasets['titanic_ds']\n",
    "df = titanic_ds.to_pandas_dataframe().drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df = prepare_embarked(prepare_genders(prepare_fare(prepare_age(df))))\n",
    "\n",
    "os.makedirs(os.path.dirname(args.output_path), exist_ok=True)\n",
    "pq.write_table(pa.Table.from_pandas(df), args.output_path)\n",
    "\n",
    "print(f\"Wrote test to {args.output_path} and train to {args.output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code parses the input argument, which is the path to which we want to write our data. (These values will be determined by PipelineData objects that will be discussed in the next step.) The code retrieves the registered 'titanic_cs' Dataset and calls the various data preparation functions.\n",
    "\n",
    "The code uses mkdirs to create the directory for the output data file (args.output_path) and then writes the datasets as a Parquet file at that destination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the data preparation pipeline step (PythonScriptStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data preparation code described above must be associated with a PythonScripStep object in order to be used with a pipeline. The path to which the Parquet data-preparation output is written is generated by a PipelineData object. The resources prepared earlier, such as the ComputeTarget, the RunConfig, and the 'titanic_ds' Dataset are used to complete the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "prepped_data_path = PipelineData(\"titanic_train\", datastore).as_dataset()\n",
    "\n",
    "dataprep_step = PythonScriptStep(\n",
    "    name=\"dataprep\", \n",
    "    script_name=\"dataprep.py\", \n",
    "    compute_target=compute_target, \n",
    "    runconfig=aml_run_config,\n",
    "    arguments=[\"--output_path\", prepped_data_path],\n",
    "    inputs=[titanic_ds.as_named_input(\"titanic_ds\")],\n",
    "    outputs=[prepped_data_path],\n",
    "    allow_reuse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prepped_data_path object is of type PipelineOutputFileDataset. Notice that it is specified in both the arguments and outputs arguments. If you review the previous step, you'll see that within the data preparation code, the value of the argument '--output_path' is the file path to which the Parquet file was written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with AutoMLStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring an automated ML pipeline step is done with the AutoMLConfig class. This flexible class is described in Configure automated ML experiments in Python. Data input and output are the only aspects of configuration that require special attention in an ML pipeline. Input and output for AutoMLConfig in pipelines is discussed in detail below. Beyond data, an advantage of ML pipelines is the ability to use different compute targets for different steps. You might choose to use a more powerful ComputeTarget only for the automated ML process. Doing so is as straightforward as assigning a more powerful RunConfiguration to the AutoMLConfig object's run_configuration parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send data to AutoMLStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed above, configuring input to your automated ML step requires the use of certain configurations. In an ML pipeline, you must provide your data using an `X,y` technique and cannot use the `training_data` technique. You may provide all your data in `X` and `y` and use `n_cross_validations` or you may provide your own validation data in `X_valid` and `y_valid` and leave `n_cross_validations` to the default `None` value.\n",
    "\n",
    "In an ML pipeline, the input data must be a Dataset object. The highest-performing way is to provide the input data in the form of `PipelineOutputTabularDataset` objects. You create an object of that type with the `parse_parquet_files()` or `parse_delimited_files()` on a `PipelineOutputFileDataset`, such as the `prepped_data_path` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(prepped_data_path) == PipelineOutputFileDataset\n",
    "# type(prepped_data_potds) == PipelineOutputTabularDataset\n",
    "prepped_data_potds = prepped_data_path.parse_parquet_files(file_extension=None)\n",
    "\n",
    "X = prepped_data_potds.drop_columns('Survived')\n",
    "y = prepped_data_potds.keep_columns('Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify automated ML outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of the `AutoMLStep` are the final metric scores of the higher-performing model and that model itself. To use these outputs in further pipeline steps, prepare `PipelineData` objects to receive them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** What's the difference between this line:\n",
    "\n",
    "dstor = Datastore.get_default(ws)\n",
    "\n",
    "and the initial one that we also got a default Datastore?:\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "Can't we use the same DataStore object? (Confirm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import TrainingOutput\n",
    "\n",
    "dstor = Datastore.get_default(ws)\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                           datastore=dstor,\n",
    "                           pipeline_output_name='metrics_output',\n",
    "                           training_output=TrainingOutput(type='Metrics'))\n",
    "model_data = PipelineData(name='best_model_data',\n",
    "                           datastore=dstor,\n",
    "                           pipeline_output_name='model_output',\n",
    "                           training_output=TrainingOutput(type='Model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snippet above assigns the default datastore of the workspace to `dstor`. Then, it creates the two `PipelineData` objects for the metrics and model output. Each is named, assigned `dstor` as the datastore on which the output will be stored, and associated with the particular `type` of `TrainingOutput` from the `AutoMLStep`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Configure and create the automated ML pipeline step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - The AutoMLConfig inputs you have specified will soon be deprecated. Please use the AutoMLConfig shown in our documentation: https://aka.ms/AutoMLConfig\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "# Change timeouts and increase iterations to a reasonable number (e.g., 50) for better accuracy\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\" : 10,\n",
    "    \"iterations\" : 2,\n",
    "    \"experiment_timeout_hours\" : 0.25,\n",
    "    \"primary_metric\" : 'AUC_weighted',\n",
    "    \"n_cross_validations\" : 3\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             path = '.',\n",
    "                             debug_log = 'automated_ml_errors.log',\n",
    "                             compute_target = compute_target,\n",
    "                             run_configuration = aml_run_config,\n",
    "                             featurization = 'auto',\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             **automl_settings)\n",
    "\n",
    "train_step = AutoMLStep(name='AutoML_Classification',\n",
    "                                 automl_config=automl_config,\n",
    "                                 passthru_automl_config=False,\n",
    "                                 outputs=[metrics_data,model_data],\n",
    "                                 allow_reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model generated by automated ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting register_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile register_model.py\n",
    "\n",
    "# register_model.py\n",
    "from azureml.core.model import Model, Dataset\n",
    "from azureml.core.run import Run, _OfflineRun\n",
    "from azureml.core import Workspace\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_name\", required=True)\n",
    "parser.add_argument(\"--model_path\", required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(f\"model_name : {args.model_name}\")\n",
    "print(f\"model_path: {args.model_path}\")\n",
    "\n",
    "run = Run.get_context()\n",
    "ws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_path=args.model_path,\n",
    "                       model_name=args.model_name)\n",
    "\n",
    "print(\"Registered version {0} of model {1}\".format(model.version, model.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write the PythonScriptStep code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "# The model name with which to register the trained model in the workspace.\n",
    "model_name = PipelineParameter(\"model_name\", default_value=\"TitanicSurvivalInitial\")\n",
    "\n",
    "register_step = PythonScriptStep(script_name=\"register_model.py\",\n",
    "                                       name=\"register_model\",\n",
    "                                       allow_reuse=False,\n",
    "                                       arguments=[\"--model_name\", model_name, \"--model_path\", model_data],\n",
    "                                       inputs=[model_data],\n",
    "                                       compute_target=compute_target,\n",
    "                                       runconfig=aml_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and run your automated ML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(ws, [dataprep_step, train_step, register_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step dataprep [f976bbfb][73f6cd66-6673-40fe-9663-0c22be511500], (This step will run and generate new outputs)\n",
      "Created step AutoML_Classification [33b9d1f1][7e415b64-6545-4001-bd68-3c8ef67bea23], (This step will run and generate new outputs)\n",
      "Created step register_model [e4f1e548][b0e0dea0-1724-4b21-a37f-c456eaad11dd], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun ebeab107-cd1b-4c4a-8fb4-f397fbdc52be\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/ebeab107-cd1b-4c4a-8fb4-f397fbdc52be?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "PipelineRunId: ebeab107-cd1b-4c4a-8fb4-f397fbdc52be\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/ebeab107-cd1b-4c4a-8fb4-f397fbdc52be?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "StepRun( dataprep ) Status: NotStarted\n",
      "StepRun( dataprep ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_e500d72f3653bd93798b2ddbb4794a8c9a5413486dd0711ca01fc9d124136621_d.txt\n",
      "========================================================================================================================\n",
      "2020-04-29T19:08:00Z Starting output-watcher...\n",
      "2020-04-29T19:08:00Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_ba78bf0538a0fee350254eccdf8e0109\n",
      "a1298f4ce990: Pulling fs layer\n",
      "04a3282d9c4b: Pulling fs layer\n",
      "9b0d3db6dc03: Pulling fs layer\n",
      "8269c605f3f1: Pulling fs layer\n",
      "6504d449e70c: Pulling fs layer\n",
      "4e38f320d0d4: Pulling fs layer\n",
      "b0a763e8ee03: Pulling fs layer\n",
      "11917a028ca4: Pulling fs layer\n",
      "a6c378d11cbf: Pulling fs layer\n",
      "6cc007ad9140: Pulling fs layer\n",
      "6c1698a608f3: Pulling fs layer\n",
      "6fda577a4ec7: Pulling fs layer\n",
      "62d96c61a3ed: Pulling fs layer\n",
      "92ef3637e5f0: Pulling fs layer\n",
      "5de3052d5a1c: Pulling fs layer\n",
      "6e577b66bf4f: Pulling fs layer\n",
      "f37617f4641b: Pulling fs layer\n",
      "4e38f320d0d4: Waiting\n",
      "b0a763e8ee03: Waiting\n",
      "11917a028ca4: Waiting\n",
      "a6c378d11cbf: Waiting\n",
      "6cc007ad9140: Waiting\n",
      "6c1698a608f3: Waiting\n",
      "6fda577a4ec7: Waiting\n",
      "62d96c61a3ed: Waiting\n",
      "92ef3637e5f0: Waiting\n",
      "5de3052d5a1c: Waiting\n",
      "6e577b66bf4f: Waiting\n",
      "f37617f4641b: Waiting\n",
      "8269c605f3f1: Waiting\n",
      "6504d449e70c: Waiting\n",
      "04a3282d9c4b: Verifying Checksum\n",
      "04a3282d9c4b: Download complete\n",
      "9b0d3db6dc03: Download complete\n",
      "8269c605f3f1: Verifying Checksum\n",
      "8269c605f3f1: Download complete\n",
      "4e38f320d0d4: Verifying Checksum\n",
      "4e38f320d0d4: Download complete\n",
      "a1298f4ce990: Verifying Checksum\n",
      "a1298f4ce990: Download complete\n",
      "6504d449e70c: Verifying Checksum\n",
      "6504d449e70c: Download complete\n",
      "11917a028ca4: Verifying Checksum\n",
      "11917a028ca4: Download complete\n",
      "6cc007ad9140: Verifying Checksum\n",
      "6cc007ad9140: Download complete\n",
      "a6c378d11cbf: Verifying Checksum\n",
      "a6c378d11cbf: Download complete\n",
      "6c1698a608f3: Verifying Checksum\n",
      "6c1698a608f3: Download complete\n",
      "b0a763e8ee03: Verifying Checksum\n",
      "b0a763e8ee03: Download complete\n",
      "6fda577a4ec7: Verifying Checksum\n",
      "6fda577a4ec7: Download complete\n",
      "62d96c61a3ed: Verifying Checksum\n",
      "62d96c61a3ed: Download complete\n",
      "92ef3637e5f0: Verifying Checksum\n",
      "92ef3637e5f0: Download complete\n",
      "5de3052d5a1c: Verifying Checksum\n",
      "5de3052d5a1c: Download complete\n",
      "f37617f4641b: Verifying Checksum\n",
      "f37617f4641b: Download complete\n",
      "a1298f4ce990: Pull complete\n",
      "04a3282d9c4b: Pull complete\n",
      "9b0d3db6dc03: Pull complete\n",
      "8269c605f3f1: Pull complete\n",
      "6e577b66bf4f: Verifying Checksum\n",
      "6e577b66bf4f: Download complete\n",
      "6504d449e70c: Pull complete\n",
      "4e38f320d0d4: Pull complete\n",
      "b0a763e8ee03: Pull complete\n",
      "11917a028ca4: Pull complete\n",
      "a6c378d11cbf: Pull complete\n",
      "6cc007ad9140: Pull complete\n",
      "6c1698a608f3: Pull complete\n",
      "6fda577a4ec7: Pull complete\n",
      "62d96c61a3ed: Pull complete\n",
      "92ef3637e5f0: Pull complete\n",
      "5de3052d5a1c: Pull complete\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_e500d72f3653bd93798b2ddbb4794a8c9a5413486dd0711ca01fc9d124136621_d.txt\n",
      "===============================================================================================================\n",
      "Starting job_prep.py script\n",
      "Starting job preparation. Current time:2020-04-29T19:10:49.214666\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: a3194df6-05bc-4a12-b5f0-e39b2d93f70e\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 79\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "Download from datastores if requested.\n",
      "Acquired lockfile /tmp/7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30-datastore.lock to downloading input data references\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 136\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ dataprep.py ] with arguments: ['--output_path', '/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/mounts/workspaceblobstore/azureml/7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/titanic_train']\n",
      "After variable expansion, calling script [ dataprep.py ] with arguments: ['--output_path', '/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/mounts/workspaceblobstore/azureml/7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/titanic_train']\n",
      "\n",
      "Wrote test to /mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/mounts/workspaceblobstore/azureml/7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/titanic_train and train to /mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/mounts/workspaceblobstore/azureml/7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/titanic_train\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.17726993560791016 seconds\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 136\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_e500d72f3653bd93798b2ddbb4794a8c9a5413486dd0711ca01fc9d124136621_d.txt\n",
      "===============================================================================================================\n",
      "Starting job release. Current time:2020-04-29T19:11:26.121331\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 344\n",
      "Job release is complete. Current time:2020-04-29T19:11:28.562320\n",
      "\n",
      "StepRun(dataprep) Execution Summary\n",
      "====================================\n",
      "StepRun( dataprep ) Status: Finished\n",
      "\n",
      "Warnings:\n",
      "This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\n",
      "Please enable Docker in the environment section of your run configuration to stop seeing this warning message.\n",
      "{'runId': '7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30', 'target': 'cpu-compute', 'status': 'Completed', 'startTimeUtc': '2020-04-29T19:07:59.01076Z', 'endTimeUtc': '2020-04-29T19:11:32.719659Z', 'warnings': [{'message': \"This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\\nPlease enable Docker in the environment section of your run configuration to stop seeing this warning message.\"}], 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'a3194df6-05bc-4a12-b5f0-e39b2d93f70e', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': 'ebeab107-cd1b-4c4a-8fb4-f397fbdc52be', '_azureml.ComputeTargetType': 'amlcompute', 'AzureML.DerivedImageName': 'azureml/azureml_ba78bf0538a0fee350254eccdf8e0109', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '922fca9c-13b0-443b-88f6-5926c26822ef'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'titanic_ds', 'mechanism': 'Direct'}}], 'runDefinition': {'script': 'dataprep.py', 'useAbsolutePath': False, 'arguments': ['--output_path', '$AZUREML_DATAREFERENCE_titanic_train'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cpu-compute', 'dataReferences': {'titanic_train': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/titanic_train', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'titanic_ds': {'dataLocation': {'dataset': {'id': '922fca9c-13b0-443b-88f6-5926c26822ef'}, 'dataPath': None}, 'createOutputDirectories': False, 'mechanism': 'Direct', 'environmentVariableName': 'titanic_ds', 'pathOnCompute': None, 'overwrite': False}}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment titanic_automl Environment', 'version': 'Autosave_2020-04-29T03:33:56Z_4a064cbc', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-sdk', 'azureml-dataprep[fuse,pandas]']}, 'pandas', 'scikit-learn'], 'name': 'azureml_1e70546db9ec9f93b20dca81d1020435'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_e500d72f3653bd93798b2ddbb4794a8c9a5413486dd0711ca01fc9d124136621_d.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/azureml-logs/55_azureml-execution-tvmps_e500d72f3653bd93798b2ddbb4794a8c9a5413486dd0711ca01fc9d124136621_d.txt?sv=2019-02-02&sr=b&sig=RqtPrP%2B9ybC98RG17DsaigGS39miaZHz4h6zSLLaIJo%3D&st=2020-04-29T19%3A01%3A40Z&se=2020-04-30T03%3A11%3A40Z&sp=r', 'azureml-logs/65_job_prep-tvmps_e500d72f3653bd93798b2ddbb4794a8c9a5413486dd0711ca01fc9d124136621_d.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/azureml-logs/65_job_prep-tvmps_e500d72f3653bd93798b2ddbb4794a8c9a5413486dd0711ca01fc9d124136621_d.txt?sv=2019-02-02&sr=b&sig=gPnPfkIYemi6uYyymbnZZC97tn7ob93KdQ5XIuQhPQA%3D&st=2020-04-29T19%3A01%3A40Z&se=2020-04-30T03%3A11%3A40Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=2ouZbD415%2BE5DnZgBzoAKkTxF7Ny8EbfTXRP3%2BadpI8%3D&st=2020-04-29T19%3A01%3A40Z&se=2020-04-30T03%3A11%3A40Z&sp=r', 'azureml-logs/75_job_post-tvmps_e500d72f3653bd93798b2ddbb4794a8c9a5413486dd0711ca01fc9d124136621_d.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/azureml-logs/75_job_post-tvmps_e500d72f3653bd93798b2ddbb4794a8c9a5413486dd0711ca01fc9d124136621_d.txt?sv=2019-02-02&sr=b&sig=Q2EEV%2F4uKFbXgBthaF1CW07lRy5owWn40Fi7hDk%2B5Zg%3D&st=2020-04-29T19%3A01%3A40Z&se=2020-04-30T03%3A11%3A40Z&sp=r', 'azureml-logs/process_info.json': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=Jrpd0NILky5cqZqh7Db0YLU8M5OUsUGMX6UwLLzv51M%3D&st=2020-04-29T19%3A01%3A40Z&se=2020-04-30T03%3A11%3A40Z&sp=r', 'azureml-logs/process_status.json': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=SbhrovfLVB3eyvIUemSoTQGWa5yElMfDZC9P2viO5rU%3D&st=2020-04-29T19%3A01%3A40Z&se=2020-04-30T03%3A11%3A40Z&sp=r', 'logs/azureml/136_azureml.log': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/logs/azureml/136_azureml.log?sv=2019-02-02&sr=b&sig=Edd049SVcujQLdeDNKRvyHqWcbFxpjJVlpVNhaC%2FQJM%3D&st=2020-04-29T19%3A01%3A40Z&se=2020-04-30T03%3A11%3A40Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=gbsegbq9ZMW6vWW7B8esmYX8qolWKV1DC8WF08nLtPo%3D&st=2020-04-29T19%3A01%3A40Z&se=2020-04-30T03%3A11%3A40Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=jNCjwhg%2BvRLft%2BxUOb8RXr%2BdtOARf5n5WLF7EkTNjw0%3D&st=2020-04-29T19%3A01%3A40Z&se=2020-04-30T03%3A11%3A40Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=dEyKPNyGQVSJJCWHY6c5nD0lmIldiXXIOwKFnOnOCYI%3D&st=2020-04-29T19%3A01%3A40Z&se=2020-04-30T03%3A11%3A40Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=stTjZuj7F6lYGxraGA16r%2F1poP0Ww0g0em%2FsKMm9Fyc%3D&st=2020-04-29T19%3A01%3A40Z&se=2020-04-30T03%3A11%3A40Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://cesardlautomln9894098850.blob.core.windows.net/azureml/ExperimentRun/dcid.7c0b2ed0-5b5a-4c16-8f0b-887e20e14a30/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=nnsQYwe1vw3zHol86I%2BnKkyPLx1rmp7uN0W0KJpwvzg%3D&st=2020-04-29T19%3A01%3A40Z&se=2020-04-30T03%3A11%3A40Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 403702f5-cabd-4748-b4b0-4c8dfaa39100\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/403702f5-cabd-4748-b4b0-4c8dfaa39100?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "StepRun( AutoML_Classification ) Status: NotStarted\n",
      "StepRun( AutoML_Classification ) Status: Queued\n",
      "StepRun( AutoML_Classification ) Status: Running\n",
      "\n",
      "StepRun(AutoML_Classification) Execution Summary\n",
      "=================================================\n",
      "StepRun( AutoML_Classification ) Status: Failed\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with ImportError: cannot import name 'CHILD_RUNS_SUMMARY_PATH'\",\n        \"detailsUri\": \"https://aka.ms/azureml-known-errors\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"ImportError\",\n            \"message\": \"cannot import name 'CHILD_RUNS_SUMMARY_PATH'\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/403702f5-cabd-4748-b4b0-4c8dfaa39100_setup/mounts/workspaceblobstore/azureml/403702f5-cabd-4748-b4b0-4c8dfaa39100_setup/azureml-setup/context_manager_injector.py\\\", line 127, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"setup_403702f5-cabd-4748-b4b0-4c8dfaa39100.py\\\", line 26, in <module>\\n    from azureml.train.automl import automl\\n  File \\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/site-packages/azureml/train/automl/__init__.py\\\", line 28, in <module>\\n    from azureml.train.automl.automlconfig import AutoMLConfig\\n  File \\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/site-packages/azureml/train/automl/automlconfig.py\\\", line 25, in <module>\\n    from . import constants\\n  File \\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/site-packages/azureml/train/automl/constants.py\\\", line 22, in <module>\\n    from azureml.automl.core.shared.constants import (\\n\"\n        },\n        \"messageParameters\": {}\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with ImportError: cannot import name 'CHILD_RUNS_SUMMARY_PATH'\\\",\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"ImportError\\\",\\n            \\\"message\\\": \\\"cannot import name 'CHILD_RUNS_SUMMARY_PATH'\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/403702f5-cabd-4748-b4b0-4c8dfaa39100_setup/mounts/workspaceblobstore/azureml/403702f5-cabd-4748-b4b0-4c8dfaa39100_setup/azureml-setup/context_manager_injector.py\\\\\\\", line 127, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"setup_403702f5-cabd-4748-b4b0-4c8dfaa39100.py\\\\\\\", line 26, in <module>\\\\n    from azureml.train.automl import automl\\\\n  File \\\\\\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/site-packages/azureml/train/automl/__init__.py\\\\\\\", line 28, in <module>\\\\n    from azureml.train.automl.automlconfig import AutoMLConfig\\\\n  File \\\\\\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/site-packages/azureml/train/automl/automlconfig.py\\\\\\\", line 25, in <module>\\\\n    from . import constants\\\\n  File \\\\\\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/site-packages/azureml/train/automl/constants.py\\\\\\\", line 22, in <module>\\\\n    from azureml.automl.core.shared.constants import (\\\\n\\\"\\n        },\\n        \\\"messageParameters\\\": {}\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-6c87469ded16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mrun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    289\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                             step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[1;32m--> 291\u001b[1;33m                                                          raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m    292\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    714\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[1;32m--> 716\u001b[1;33m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                 \u001b[0merror_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"The output streaming for the run interrupted.\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[1;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with ImportError: cannot import name 'CHILD_RUNS_SUMMARY_PATH'\",\n        \"detailsUri\": \"https://aka.ms/azureml-known-errors\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"ImportError\",\n            \"message\": \"cannot import name 'CHILD_RUNS_SUMMARY_PATH'\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/403702f5-cabd-4748-b4b0-4c8dfaa39100_setup/mounts/workspaceblobstore/azureml/403702f5-cabd-4748-b4b0-4c8dfaa39100_setup/azureml-setup/context_manager_injector.py\\\", line 127, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"setup_403702f5-cabd-4748-b4b0-4c8dfaa39100.py\\\", line 26, in <module>\\n    from azureml.train.automl import automl\\n  File \\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/site-packages/azureml/train/automl/__init__.py\\\", line 28, in <module>\\n    from azureml.train.automl.automlconfig import AutoMLConfig\\n  File \\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/site-packages/azureml/train/automl/automlconfig.py\\\", line 25, in <module>\\n    from . import constants\\n  File \\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/site-packages/azureml/train/automl/constants.py\\\", line 22, in <module>\\n    from azureml.automl.core.shared.constants import (\\n\"\n        },\n        \"messageParameters\": {}\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with ImportError: cannot import name 'CHILD_RUNS_SUMMARY_PATH'\\\",\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"ImportError\\\",\\n            \\\"message\\\": \\\"cannot import name 'CHILD_RUNS_SUMMARY_PATH'\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/403702f5-cabd-4748-b4b0-4c8dfaa39100_setup/mounts/workspaceblobstore/azureml/403702f5-cabd-4748-b4b0-4c8dfaa39100_setup/azureml-setup/context_manager_injector.py\\\\\\\", line 127, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"setup_403702f5-cabd-4748-b4b0-4c8dfaa39100.py\\\\\\\", line 26, in <module>\\\\n    from azureml.train.automl import automl\\\\n  File \\\\\\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/site-packages/azureml/train/automl/__init__.py\\\\\\\", line 28, in <module>\\\\n    from azureml.train.automl.automlconfig import AutoMLConfig\\\\n  File \\\\\\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/site-packages/azureml/train/automl/automlconfig.py\\\\\\\", line 25, in <module>\\\\n    from . import constants\\\\n  File \\\\\\\"/azureml-envs/azureml_bb2553c4c8454b03df8cbb6c7c3bc444/lib/python3.6/site-packages/azureml/train/automl/constants.py\\\\\\\", line 22, in <module>\\\\n    from azureml.automl.core.shared.constants import (\\\\n\\\"\\n        },\\n        \\\"messageParameters\\\": {}\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(workspace=ws, \n",
    "                        name='titanic_automl')\n",
    "\n",
    "run = experiment.submit(pipeline, show_output=True)\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the results of an automated ML run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on local machine\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "experiment = ws.experiments['titanic_automl']\n",
    "run = next(run for run in ex.get_runs() if run.id == 'aaaaaaaa-bbbb-cccc-dddd-0123456789AB')\n",
    "automl_run = next(r for r in run.get_children() if r.name == 'AutoML_Classification')\n",
    "outputs = automl_run.get_outputs()\n",
    "metrics = outputs['default_metrics_AutoML_Classification']\n",
    "model = outputs['default_model_AutoML_Classification']\n",
    "\n",
    "metrics.get_port_data_reference().download('.')\n",
    "model.get_port_data_reference().download('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 (aml-conda-env)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
