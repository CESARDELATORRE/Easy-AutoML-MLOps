{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ComputeTarget, Dataset, Datastore, Experiment, Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.pipeline.steps import AutoMLStep, PythonScriptStep\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='cesardl-automl-ncentralus-demo-ws', subscription_id='381b38e9-9840-4719-a5a0-61d9585e1e91', resource_group='cesardl-automl-ncentralus-demo-ws-resgrp')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ws = Workspace.from_config(auth=InteractiveLoginAuthentication(tenant_id=os.environ[\"AML_TENANT_ID\"]))\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating a new compute target...\n",
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2020-04-29T18:43:29.045000+00:00', 'errors': None, 'creationTime': '2020-04-29T18:43:20.856719+00:00', 'modifiedTime': '2020-04-29T18:43:36.931537+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 1, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
     ]
    }
   ],
   "source": [
    "compute_name = \"cpu-compute3\"\n",
    "if not compute_name in ws.compute_targets :\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                                min_nodes=0,\n",
    "                                                                max_nodes=1)\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "    # Show the result\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmlCompute(workspace=Workspace.create(name='cesardl-automl-ncentralus-demo-ws', subscription_id='381b38e9-9840-4719-a5a0-61d9585e1e91', resource_group='cesardl-automl-ncentralus-demo-ws-resgrp'), name=cpu-compute3, id=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/cesardl-automl-ncentralus-demo-ws-resgrp/providers/Microsoft.MachineLearningServices/workspaces/cesardl-automl-ncentralus-demo-ws/computes/cpu-compute3, type=AmlCompute, provisioning_state=Succeeded, location=northcentralus, tags=None)\n"
     ]
    }
   ],
   "source": [
    "compute = AmlCompute(ws, compute_name)\n",
    "print(compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_run_config = RunConfiguration()\n",
    "aml_run_config.target = compute\n",
    "\n",
    "# Use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "aml_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Specify CondaDependencies obj, add necessary packages\n",
    "aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=['pandas','scikit-learn', 'pyarrow'], \n",
    "    pip_packages=['azureml-sdk', 'azureml-dataprep[fuse,pandas]'], \n",
    "    pin_sdk_version=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Grab an open dataset and register it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is baseline data. If the `Dataset` does not exist, create and register it. Not a part of the Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'titanic_ds' in ws.datasets.keys() :\n",
    "    # create a TabularDataset from Titanic training data\n",
    "    web_paths = ['https://dprepdata.blob.core.windows.net/demo/Titanic.csv',\n",
    "                 'https://dprepdata.blob.core.windows.net/demo/Titanic2.csv']\n",
    "    titanic_ds = Dataset.Tabular.from_delimited_files(path=web_paths)\n",
    "\n",
    "    titanic_ds.register(workspace = ws,\n",
    "                                     name = 'titanic_ds',\n",
    "                                     description = 'new titanic training data',\n",
    "                                     create_new_version = True)\n",
    "\n",
    "titanic_ds = Dataset.get_by_name(ws, 'titanic_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azureml.data.tabular_dataset.TabularDataset"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(titanic_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'titanic_files_ds' in ws.datasets.keys() :\n",
    "    # create a TabularDataset from Titanic training data\n",
    "    web_paths = ['https://dprepdata.blob.core.windows.net/demo/Titanic.csv',\n",
    "                 'https://dprepdata.blob.core.windows.net/demo/Titanic2.csv']\n",
    "    titanic_ds = Dataset.File.from_files(path=web_paths)\n",
    "\n",
    "    titanic_ds.register(workspace = ws,\n",
    "                                     name = 'titanic_files_ds',\n",
    "                                     description = 'File Dataset of titanic training data',\n",
    "                                     create_new_version = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataprep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataprep.py\n",
    "# dataprep.py\n",
    "from azureml.core import Run\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "RANDOM_SEED=42\n",
    "\n",
    "def prepare_age(df):\n",
    "    # Fill in missing Age values from distribution of present Age values \n",
    "    mean = df[\"Age\"].mean()\n",
    "    std = df[\"Age\"].std()\n",
    "    is_null = df[\"Age\"].isnull().sum()\n",
    "    # compute enough (== is_null().sum()) random numbers between the mean, std\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = df[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    df[\"Age\"] = age_slice\n",
    "    df[\"Age\"] = df[\"Age\"].astype(int)\n",
    "    \n",
    "    # Quantize age into 5 classes\n",
    "    df['Age_Group'] = pd.qcut(df['Age'],5, labels=False)\n",
    "    df.drop(['Age'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def prepare_fare(df):\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    df['Fare_Group'] = pd.qcut(df['Fare'],5,labels=False)\n",
    "    df.drop(['Fare'], axis=1, inplace=True)\n",
    "    return df \n",
    "\n",
    "def prepare_genders(df):\n",
    "    genders = {\"male\": 0, \"female\": 1, \"unknown\": 2}\n",
    "    df['Sex'] = df['Sex'].map(genders)\n",
    "    df['Sex'].fillna(2, inplace=True)\n",
    "    df['Sex'] = df['Sex'].astype(int)\n",
    "    return df\n",
    "\n",
    "def prepare_embarked(df):\n",
    "    df['Embarked'].replace('', 'U', inplace=True)\n",
    "    df['Embarked'].fillna('U', inplace=True)\n",
    "    ports = {\"S\": 0, \"C\": 1, \"Q\": 2, \"U\": 3}\n",
    "    df['Embarked'] = df['Embarked'].map(ports)\n",
    "    return df\n",
    "    \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_path', dest='output_path', required=True)\n",
    "args = parser.parse_args()\n",
    "    \n",
    "titanic_ds = Run.get_context().input_datasets['titanic_ds']\n",
    "df = titanic_ds.to_pandas_dataframe().drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "df = prepare_embarked(prepare_genders(prepare_fare(prepare_age(df))))\n",
    "\n",
    "os.makedirs(os.path.dirname(args.output_path), exist_ok=True)\n",
    "pq.write_table(pa.Table.from_pandas(df), args.output_path)\n",
    "\n",
    "print(f\"Wrote test to {args.output_path} and train to {args.output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepped_data_path = PipelineData(\"titanic_train\", datastore).as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep_step = PythonScriptStep(\n",
    "    name=\"dataprep\", \n",
    "    script_name=\"dataprep.py\", \n",
    "    compute_target=compute, \n",
    "    runconfig=aml_run_config,\n",
    "    arguments=[\"--output_path\", prepped_data_path],\n",
    "    inputs=[titanic_ds.as_named_input(\"titanic_ds\")],\n",
    "    outputs=[prepped_data_path],\n",
    "    allow_reuse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train with AutoMLStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - The AutoMLConfig inputs you have specified will soon be deprecated. Please use the AutoMLConfig shown in our documentation: https://aka.ms/AutoMLConfig\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML config created.\n"
     ]
    }
   ],
   "source": [
    "prepped_data_potds = prepped_data_path.parse_parquet_files(file_extension=None)\n",
    "\n",
    "X = prepped_data_potds.drop_columns('Survived')\n",
    "y = prepped_data_potds.keep_columns('Survived')\n",
    "\n",
    "\n",
    "# Change iterations to a reasonable number (50) to get better accuracy\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\" : 10,\n",
    "    \"iterations\" : 50,\n",
    "    \"experiment_timeout_hours\" : 1,\n",
    "    \"primary_metric\" : 'AUC_weighted',\n",
    "    \"n_cross_validations\" : 2\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             path = '.',\n",
    "                             debug_log = 'automated_ml_errors.log',\n",
    "                             compute_target = compute,\n",
    "                             run_configuration = aml_run_config,\n",
    "                             featurization = 'auto',\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             **automl_settings)\n",
    "                             \n",
    "print(\"AutoML config created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_step created.\n"
     ]
    }
   ],
   "source": [
    "dstor = Datastore.get_default(ws)\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                           datastore=dstor,\n",
    "                           pipeline_output_name='metrics_output',\n",
    "                           training_output=TrainingOutput(type='Metrics'))\n",
    "model_data = PipelineData(name='best_model_data',\n",
    "                           datastore=dstor,\n",
    "                           pipeline_output_name='model_output',\n",
    "                           training_output=TrainingOutput(type='Model'))\n",
    "\n",
    "\n",
    "train_step = AutoMLStep(name='AutoML_Classification',\n",
    "                                 automl_config=automl_config,\n",
    "                                 passthru_automl_config=False,\n",
    "                                 outputs=[metrics_data,model_data],\n",
    "                                 allow_reuse=True)\n",
    "print(\"train_step created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting register_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile register_model.py\n",
    "from azureml.core.model import Model, Dataset\n",
    "from azureml.core.run import Run, _OfflineRun\n",
    "from azureml.core import Workspace\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--model_name\", required=True)\n",
    "parser.add_argument(\"--model_path\", required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(f\"model_name : {args.model_name}\")\n",
    "print(f\"model_path: {args.model_path}\")\n",
    "\n",
    "run = Run.get_context()\n",
    "ws = Workspace.from_config() if type(run) == _OfflineRun else run.experiment.workspace\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_path=args.model_path,\n",
    "                       model_name=args.model_name)\n",
    "\n",
    "print(\"Registered version {0} of model {1}\".format(model.version, model.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model name with which to register the trained model in the workspace.\n",
    "model_name = PipelineParameter(\"model_name\", default_value=\"TitanicSurvival\")\n",
    "\n",
    "register_step = PythonScriptStep(script_name=\"register_model.py\",\n",
    "                                       name=\"register_model\",\n",
    "                                       allow_reuse=False,\n",
    "                                       arguments=[\"--model_name\", model_name, \"--model_path\", model_data],\n",
    "                                       inputs=[model_data],\n",
    "                                       compute_target=compute,\n",
    "                                       runconfig=aml_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'titanic_automl' in ws.experiments.keys() :\n",
    "    Experiment(ws, 'titanic_automl')\n",
    "experiment = ws.experiments['titanic_automl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(ws, [dataprep_step, train_step, register_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step dataprep [3e4ebdcb][dd4ac83b-8444-4c84-b536-2e6aafeab11a], (This step will run and generate new outputs)\n",
      "Created step AutoML_Classification [3460776d][ea57090e-b15a-4b04-81ac-1807bc7f5220], (This step will run and generate new outputs)\n",
      "Created step register_model [b522e10f][05bd3f97-f8cb-457c-a578-d88be5ee553b], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun dd4537ff-efb2-4d0f-bf1a-6f345e4e0327\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/dd4537ff-efb2-4d0f-bf1a-6f345e4e0327?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(pipeline, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: dd4537ff-efb2-4d0f-bf1a-6f345e4e0327\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/dd4537ff-efb2-4d0f-bf1a-6f345e4e0327?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/titanic_automl/runs/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/cesardl-automl-ncentralus-demo-ws-resgrp/workspaces/cesardl-automl-ncentralus-demo-ws\n",
      "StepRun( dataprep ) Status: NotStarted\n",
      "StepRun( dataprep ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2020/04/29 18:49:06 Downloading source code...\n",
      "2020/04/29 18:49:07 Finished downloading source code\n",
      "2020/04/29 18:49:08 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2020/04/29 18:49:08 Successfully set up Docker network: acb_default_network\n",
      "2020/04/29 18:49:08 Setting up Docker configuration...\n",
      "2020/04/29 18:49:09 Successfully set up Docker configuration\n",
      "2020/04/29 18:49:09 Logging in to registry: cesardlautoma5f87185.azurecr.io\n",
      "2020/04/29 18:49:10 Successfully logged into cesardlautoma5f87185.azurecr.io\n",
      "2020/04/29 18:49:10 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/04/29 18:49:10 Scanning for dependencies...\n",
      "2020/04/29 18:49:11 Successfully scanned dependencies\n",
      "2020/04/29 18:49:11 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  60.93kB\n",
      "\n",
      "Step 1/15 : FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05: Pulling from azureml/base\n",
      "Digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      " ---> 93a72e6bd1ce\n",
      "Step 2/15 : USER root\n",
      " ---> Running in 7beae86a9fdc\n",
      "Removing intermediate container 7beae86a9fdc\n",
      " ---> a5ff60ec906d\n",
      "Step 3/15 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 488b92595f6c\n",
      "Removing intermediate container 488b92595f6c\n",
      " ---> 7bdd9e697b89\n",
      "Step 4/15 : WORKDIR /\n",
      " ---> Running in 9910eccd688c\n",
      "Removing intermediate container 9910eccd688c\n",
      " ---> ddc30579e675\n",
      "Step 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 5df81295b22c\n",
      "Step 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 964af8515d6a\n",
      "Removing intermediate container 964af8515d6a\n",
      " ---> e7de9926cd26\n",
      "Step 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> e9675c55ac65\n",
      "Step 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 990a13b42d7c\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "libprotobuf-3.6.0    | 4.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libprotobuf-3.6.0    | 4.1 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "libprotobuf-3.6.0    | 4.1 MB    | #########7 |  97% \u001b[0m\u001b[91m\n",
      "libprotobuf-3.6.0    | 4.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-dateutil-2.8. | 224 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "python-dateutil-2.8. | 224 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl-service-2.3.0    | 208 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl-service-2.3.0    | 208 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "numpy-base-1.18.1    | 5.2 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "numpy-base-1.18.1    | 5.2 MB    | #######5   |  76% \u001b[0m\u001b[91m\n",
      "numpy-base-1.18.1    | 5.2 MB    | #########8 |  99% \u001b[0m\u001b[91m\n",
      "numpy-base-1.18.1    | 5.2 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pandas-1.0.3         | 11.1 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | ###5       |  35% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | #########1 |  91% \u001b[0m\u001b[91m\n",
      "pandas-1.0.3         | 11.1 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "joblib-0.14.1        | 202 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "joblib-0.14.1        | 202 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "arrow-cpp-0.13.0     | 3.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "arrow-cpp-0.13.0     | 3.5 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "arrow-cpp-0.13.0     | 3.5 MB    | ########8  |  88% \u001b[0m\u001b[91m\n",
      "arrow-cpp-0.13.0     | 3.5 MB    | #########7 |  97% \u001b[0m\u001b[91m\n",
      "arrow-cpp-0.13.0     | 3.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "scipy-1.4.1          | 18.9 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | #6         |  16% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | #####5     |  56% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | #########  |  91% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "zstd-1.3.7           | 887 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "zstd-1.3.7           | 887 KB    | ########4  |  84% \u001b[0m\u001b[91m\n",
      "zstd-1.3.7           | 887 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "certifi-2020.4.5.1   | 159 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "certifi-2020.4.5.1   | 159 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "numpy-1.18.1         | 5 KB      |            |   0% \u001b[0m\u001b[91m\n",
      "numpy-1.18.1         | 5 KB      | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "boost-cpp-1.67.0     | 11 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "boost-cpp-1.67.0     | 11 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | #########9 | 100% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "six-1.14.0           | 27 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "six-1.14.0           | 27 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | 2          |   2% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | 6          |   6% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | 9          |  10% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #3         |  13% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #6         |  17% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ##         |  20% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ##3        |  24% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ##6        |  27% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ###        |  30% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ###3       |  34% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ###7       |  38% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ####1      |  41% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ####5      |  45% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ####8      |  49% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #####2     |  52% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #####5     |  56% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #####9     |  60% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ######3    |  64% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ######7    |  67% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #######1   |  71% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #######5   |  75% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #######8   |  78% \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########   |  80% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########1  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########2  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########3  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  85% \u001b[0m\n",
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\n",
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.4           | 204.1 MB  | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #2         |  13% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ###5       |  36% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #####7     |  57% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########6  |  87% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #########5 |  95% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "wheel-0.34.2         | 49 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "wheel-0.34.2         | 49 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl_random-1.1.0     | 369 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl_random-1.1.0     | 369 KB    | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "scikit-learn-0.22.1  | 7.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | ######2    |  62% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | ########1  |  81% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | #########5 |  96% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "thrift-cpp-0.11.0    | 2.3 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "thrift-cpp-0.11.0    | 2.3 MB    |            |   1% \u001b[0m\u001b[91m\n",
      "thrift-cpp-0.11.0    | 2.3 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "thrift-cpp-0.11.0    | 2.3 MB    | #########7 |  97% \u001b[0m\u001b[91m\n",
      "thrift-cpp-0.11.0    | 2.3 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libboost-1.67.0      | 20.9 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "libboost-1.67.0      | 20.9 MB   | 1          |   2% \u001b[0m\u001b[91m\n",
      "libboost-1.67.0      | 20.9 MB   | ##5        |  26% \u001b[0m\u001b[91m\n",
      "libboost-1.67.0      | 20.9 MB   | ####6      |  47% \u001b[0m\u001b[91m\n",
      "libboost-1.67.0      | 20.9 MB   | ######2    |  63% \u001b[0m\u001b[91m\n",
      "libboost-1.67.0      | 20.9 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "libboost-1.67.0      | 20.9 MB   | ########5  |  86% \u001b[0m\u001b[91m\n",
      "libboost-1.67.0      | 20.9 MB   | #########2 |  93% \u001b[0m\u001b[91m\n",
      "libboost-1.67.0      | 20.9 MB   | #########8 |  98% \u001b[0m\u001b[91m\n",
      "libboost-1.67.0      | 20.9 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "libedit-3.1          | 171 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | #######8   |  79% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "glog-0.4.0           | 128 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "glog-0.4.0           | 128 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "intel-openmp-2020.0  | 916 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "intel-openmp-2020.0  | 916 KB    | ########4  |  84% \u001b[0m\u001b[91m\n",
      "intel-openmp-2020.0  | 916 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | ########9  |  90% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | #########9 |  99% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libevent-2.1.8       | 1.4 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libevent-2.1.8       | 1.4 MB    | #######7   |  78% \u001b[0m\u001b[91m\n",
      "libevent-2.1.8       | 1.4 MB    | #########7 |  97% \u001b[0m\u001b[91m\n",
      "libevent-2.1.8       | 1.4 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "double-conversion-3. | 233 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "double-conversion-3. | 233 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl_fft-1.0.15       | 173 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl_fft-1.0.15       | 173 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ca-certificates-2020 | 132 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ca-certificates-2020 | 132 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \u001b[0m\u001b[91m\n",
      "blas-1.0             | 6 KB      | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "re2-2019.08.01       | 613 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "re2-2019.08.01       | 613 KB    | ########7  |  87% \u001b[0m\u001b[91m\n",
      "re2-2019.08.01       | 613 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "gflags-2.2.2         | 160 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "gflags-2.2.2         | 160 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "xz-5.2.5             | 438 KB    | #########  |  90% \u001b[0m\u001b[91m\n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "tk-8.6.8             | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########7  |  88% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #########6 |  97% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libffi-3.2.1         | 43 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "libffi-3.2.1         | 43 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 387 KB    | ########8  |  89% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 387 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "brotli-1.0.7         | 1.0 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "brotli-1.0.7         | 1.0 MB    | ########4  |  85% \u001b[0m\u001b[91m\n",
      "brotli-1.0.7         | 1.0 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "setuptools-46.1.3    | 663 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "setuptools-46.1.3    | 663 KB    | ########4  |  85% \u001b[0m\u001b[91m\n",
      "setuptools-46.1.3    | 663 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "icu-58.2             | 22.5 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "icu-58.2             | 22.5 MB   | #9         |  20% \u001b[0m\u001b[91m\n",
      "icu-58.2             | 22.5 MB   | ####7      |  47% \u001b[0m\u001b[91m\n",
      "icu-58.2             | 22.5 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "icu-58.2             | 22.5 MB   | #########2 |  92% \u001b[0m\u001b[91m\n",
      "icu-58.2             | 22.5 MB   | ########## | 100% \u001b[0m\u001b[91m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lz4-c-1.8.1.2        | 158 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "lz4-c-1.8.1.2        | 158 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | #########1 |  91% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ####6      |  46% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #######5   |  76% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #########4 |  95% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "snappy-1.1.8         | 39 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "snappy-1.1.8         | 39 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pyarrow-0.13.0       | 2.2 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pyarrow-0.13.0       | 2.2 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "pyarrow-0.13.0       | 2.2 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "pyarrow-0.13.0       | 2.2 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "bzip2-1.0.8          | 105 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "bzip2-1.0.8          | 105 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pytz-2019.3          | 231 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "pytz-2019.3          | 231 KB    | #########  |  91% \u001b[0m\u001b[91m\n",
      "pytz-2019.3          | 231 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pip-20.0.2           | 1.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | #######8   |  78% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | #########1 |  91% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | ########## | 100% \u001b[0m\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... \n",
      "done\n",
      "Executing transaction: ...working... done\n",
      "Collecting azureml-sdk\n",
      "  Downloading azureml_sdk-1.4.0-py3-none-any.whl (4.6 kB)\n",
      "Collecting azureml-dataprep[fuse,pandas]\n",
      "  Downloading azureml_dataprep-1.4.6-py3-none-any.whl (26.7 MB)\n",
      "Collecting azureml-train~=1.4.0\n",
      "  Downloading azureml_train-1.4.0-py3-none-any.whl (3.2 kB)\n",
      "Collecting azureml-core~=1.4.0\n",
      "  Downloading azureml_core-1.4.0.post1-py3-none-any.whl (1.3 MB)\n",
      "Collecting azureml-train-automl-client~=1.4.0\n",
      "  Downloading azureml_train_automl_client-1.4.0-py3-none-any.whl (81 kB)\n",
      "Collecting azureml-pipeline~=1.4.0\n",
      "  Downloading azureml_pipeline-1.4.0-py3-none-any.whl (3.7 kB)\n",
      "Collecting cloudpickle>=1.1.0\n",
      "  Downloading cloudpickle-1.4.1-py3-none-any.whl (26 kB)\n",
      "Collecting azure-identity<1.3.0,>=1.2.0\n",
      "  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting dotnetcore2>=2.1.13\n",
      "  Downloading dotnetcore2-2.1.13-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
      "Collecting azureml-dataprep-native<15.0.0,>=14.1.0\n",
      "  Downloading azureml_dataprep_native-14.1.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting fusepy>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Requirement already satisfied: pandas>=0.23.4; extra == \"pandas\" in /azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/site-packages (from azureml-dataprep[fuse,pandas]->-r /azureml-environment-setup/condaenv.ibubta60.requirements.txt (line 2)) (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.14.0; extra == \"pandas\" in /azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/site-packages (from azureml-dataprep[fuse,pandas]->-r /azureml-environment-setup/condaenv.ibubta60.requirements.txt (line 2)) (1.18.1)\n",
      "Collecting pyarrow>=0.15.*; extra == \"pandas\"\n",
      "  Downloading pyarrow-0.17.0-cp36-cp36m-manylinux2014_x86_64.whl (63.8 MB)\n",
      "Collecting azureml-train-core~=1.4.0\n",
      "  Downloading azureml_train_core-1.4.0-py3-none-any.whl (8.6 MB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pytz in /azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/site-packages (from azureml-core~=1.4.0->azureml-sdk->-r /azureml-environment-setup/condaenv.ibubta60.requirements.txt (line 1)) (2019.3)\n",
      "Collecting docker\n",
      "  Downloading docker-4.2.0-py2.py3-none-any.whl (143 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\n",
      "Collecting pyopenssl\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting azure-mgmt-resource>=1.2.1\n",
      "  Downloading azure_mgmt_resource-9.0.0-py2.py3-none-any.whl (807 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting ruamel.yaml<=0.15.89,>=0.15.35\n",
      "  Downloading ruamel.yaml-0.15.89-cp36-cp36m-manylinux1_x86_64.whl (651 kB)\n",
      "Collecting azure-mgmt-keyvault>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting azure-mgmt-authorization>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/site-packages (from azureml-core~=1.4.0->azureml-sdk->-r /azureml-environment-setup/condaenv.ibubta60.requirements.txt (line 1)) (2.8.1)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting requests>=2.19.1\n",
      "  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
      "Collecting azure-mgmt-storage>=1.5.0\n",
      "  Downloading azure_mgmt_storage-9.0.0-py2.py3-none-any.whl (525 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting adal>=1.2.0\n",
      "  Downloading adal-1.2.2-py2.py3-none-any.whl (53 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.13-py2.py3-none-any.whl (83 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n",
      "  Downloading cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)\n",
      "Collecting azure-graphrbac>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting azureml-telemetry~=1.4.0\n",
      "  Downloading azureml_telemetry-1.4.0-py3-none-any.whl (29 kB)\n",
      "Collecting azureml-automl-core~=1.4.0\n",
      "  Downloading azureml_automl_core-1.4.0-py3-none-any.whl (111 kB)\n",
      "Collecting azureml-pipeline-steps~=1.4.0\n",
      "  Downloading azureml_pipeline_steps-1.4.0-py3-none-any.whl (49 kB)\n",
      "Collecting azureml-pipeline-core~=1.4.0\n",
      "  Downloading azureml_pipeline_core-1.4.0-py3-none-any.whl (272 kB)\n",
      "Collecting msal<2.0.0,>=1.0.0\n",
      "  Downloading msal-1.2.0-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: six>=1.6 in /azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/site-packages (from azure-identity<1.3.0,>=1.2.0->azureml-dataprep[fuse,pandas]->-r /azureml-environment-setup/condaenv.ibubta60.requirements.txt (line 2)) (1.14.0)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.4.0-py2.py3-none-any.whl (114 kB)\n",
      "Collecting msal-extensions~=0.1.3\n",
      "  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting flake8<=3.7.9,>=3.1.0; python_version >= \"3.6\"\n",
      "  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)\n",
      "Collecting azureml-train-restclients-hyperdrive~=1.4.0\n",
      "  Downloading azureml_train_restclients_hyperdrive-1.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/site-packages (from requests>=2.19.1->azureml-core~=1.4.0->azureml-sdk->-r /azureml-environment-setup/condaenv.ibubta60.requirements.txt (line 1)) (2020.4.5.1)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)\n",
      "Collecting applicationinsights\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting portalocker~=1.0\n",
      "  Downloading portalocker-1.7.0-py2.py3-none-any.whl (14 kB)\n",
      "Collecting mccabe<0.7.0,>=0.6.0\n",
      "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Collecting pyflakes<2.2.0,>=2.1.0\n",
      "  Downloading pyflakes-2.1.1-py2.py3-none-any.whl (59 kB)\n",
      "Collecting entrypoints<0.4.0,>=0.3.0\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pycodestyle<2.6.0,>=2.5.0\n",
      "  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Building wheels for collected packages: fusepy\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=81bffda4757a1ffbcf8dedaeb61b87d07293ca0cc1267c8d3297890f20a042bc\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "Successfully built fusepy\n",
      "Installing collected packages: mccabe, pyflakes, entrypoints, pycodestyle, flake8, chardet, idna, urllib3, requests, oauthlib, requests-oauthlib, isodate, msrest, pycparser, cffi, cryptography, PyJWT, adal, msrestazure, azureml-train-restclients-hyperdrive, azure-common, websocket-client, docker, jmespath, pyopenssl, azure-mgmt-resource, pyasn1, ndg-httpsclient, ruamel.yaml, azure-mgmt-keyvault, azure-mgmt-authorization, jeepney, SecretStorage, azure-mgmt-containerregistry, zipp, importlib-metadata, jsonpickle, azure-mgmt-storage, pathspec, contextlib2, backports.weakref, backports.tempfile, azure-graphrbac, azureml-core, applicationinsights, azureml-telemetry, azureml-train-core, azureml-train, cloudpickle, msal, azure-core, portalocker, msal-extensions, azure-identity, distro, dotnetcore2, azureml-dataprep-native, fusepy, pyarrow, azureml-dataprep, azureml-automl-core, azureml-train-automl-client, azureml-pipeline-core, azureml-pipeline-steps, azureml-pipeline, azureml-sdk\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 0.13.0\n",
      "    Uninstalling pyarrow-0.13.0:\n",
      "      Successfully uninstalled pyarrow-0.13.0\n",
      "Successfully installed PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.2 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.4.0 azure-graphrbac-0.61.1 azure-identity-1.2.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-9.0.0 azure-mgmt-storage-9.0.0 azureml-automl-core-1.4.0 azureml-core-1.4.0.post1 azureml-dataprep-1.4.6 azureml-dataprep-native-14.1.0 azureml-pipeline-1.4.0 azureml-pipeline-core-1.4.0 azureml-pipeline-steps-1.4.0 azureml-sdk-1.4.0 azureml-telemetry-1.4.0 azureml-train-1.4.0 azureml-train-automl-client-1.4.0 azureml-train-core-1.4.0 azureml-train-restclients-hyperdrive-1.4.0 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.0 chardet-3.0.4 cloudpickle-1.4.1 contextlib2-0.6.0.post1 cryptography-2.9.2 distro-1.5.0 docker-4.2.0 dotnetcore2-2.1.13 entrypoints-0.3 flake8-3.7.9 fusepy-3.0.1 idna-2.9 importlib-metadata-1.6.0 isodate-0.6.0 jeepney-0.4.3 jmespath-0.9.5 jsonpickle-1.4.1 mccabe-0.6.1 msal-1.2.0 msal-extensions-0.1.3 msrest-0.6.13 msrestazure-0.6.3 ndg-httpsclient-0.5.1 oauthlib-3.1.0 pathspec-0.8.0 portalocker-1.7.0 pyarrow-0.17.0 pyasn1-0.4.8 pycodestyle-2.5.0 pycparser-2.20 pyflakes-2.1.1 pyopenssl-19.1.0 requests-2.23.0 requests-oauthlib-1.3.0 ruamel.yaml-0.15.89 urllib3-1.25.9 websocket-client-0.57.0 zipp-3.1.0\n",
      "\u001b[91m\n",
      "\u001b[0m#\n",
      "# To activate this environment, use:\n",
      "# > source activate /azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d\n",
      "#\n",
      "# To deactivate an active environment, use:\n",
      "# > source deactivate\n",
      "#\n",
      "\n",
      "\n",
      "Removing intermediate container 990a13b42d7c\n",
      " ---> fc47eabc3153\n",
      "Step 9/15 : ENV PATH /azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/bin:$PATH\n",
      " ---> Running in 77eeb378e880\n",
      "Removing intermediate container 77eeb378e880\n",
      " ---> c60894fc243a\n",
      "Step 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d\n",
      " ---> Running in b2f4b96f37ca\n",
      "Removing intermediate container b2f4b96f37ca\n",
      " ---> 8830e5d78aec\n",
      "Step 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 2440dbdeac15\n",
      "Removing intermediate container 2440dbdeac15\n",
      " ---> 7496f9c329ab\n",
      "Step 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> f68c557d9d43\n",
      "Step 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit \"--repositories\" \"[]\" /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in cc8368ead7c7\n",
      "Removing intermediate container cc8368ead7c7\n",
      " ---> 3ba6578aa063\n",
      "Step 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 2c43b08dc2e0\n",
      "Removing intermediate container 2c43b08dc2e0\n",
      " ---> 384a35d297e0\n",
      "Step 15/15 : CMD [\"bash\"]\n",
      " ---> Running in 0c3e34c5d4d3\n",
      "Removing intermediate container 0c3e34c5d4d3\n",
      " ---> 8b275ad32e90\n",
      "Successfully built 8b275ad32e90\n",
      "Successfully tagged cesardlautoma5f87185.azurecr.io/azureml/azureml_b75709396e112eb3c528ff9421e54d7f:latest\n",
      "2020/04/29 18:54:07 Successfully executed container: acb_step_0\n",
      "2020/04/29 18:54:07 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/04/29 18:54:07 Pushing image: cesardlautoma5f87185.azurecr.io/azureml/azureml_b75709396e112eb3c528ff9421e54d7f:latest, attempt 1\n",
      "The push refers to repository [cesardlautoma5f87185.azurecr.io/azureml/azureml_b75709396e112eb3c528ff9421e54d7f]\n",
      "096d5f4935ca: Preparing\n",
      "4fae00ac92f6: Preparing\n",
      "2603aeef8c4f: Preparing\n",
      "c5e77b5fe1e6: Preparing\n",
      "fc09ea23df5b: Preparing\n",
      "680554a15d7b: Preparing\n",
      "e1171d4d60ca: Preparing\n",
      "6ef1a8ae63b7: Preparing\n",
      "85389f9ead9e: Preparing\n",
      "f2608f66a0e3: Preparing\n",
      "0e259b09e5f4: Preparing\n",
      "340dc32eb998: Preparing\n",
      "df18b66efaa6: Preparing\n",
      "ccdb13a20bf2: Preparing\n",
      "9513cdf4e497: Preparing\n",
      "7f083f9454c0: Preparing\n",
      "29f36b5893dc: Preparing\n",
      "f2608f66a0e3: Waiting\n",
      "0e259b09e5f4: Waiting\n",
      "340dc32eb998: Waiting\n",
      "df18b66efaa6: Waiting\n",
      "ccdb13a20bf2: Waiting\n",
      "9513cdf4e497: Waiting\n",
      "7f083f9454c0: Waiting\n",
      "29f36b5893dc: Waiting\n",
      "680554a15d7b: Waiting\n",
      "e1171d4d60ca: Waiting\n",
      "6ef1a8ae63b7: Waiting\n",
      "85389f9ead9e: Waiting\n",
      "fc09ea23df5b: Pushed\n",
      "2603aeef8c4f: Pushed\n",
      "c5e77b5fe1e6: Pushed\n",
      "096d5f4935ca: Pushed\n",
      "680554a15d7b: Pushed\n",
      "e1171d4d60ca: Pushed\n",
      "6ef1a8ae63b7: Pushed\n",
      "\n",
      "340dc32eb998: Pushed\n",
      "f2608f66a0e3: Pushed\n",
      "0e259b09e5f4: Pushed\n",
      "ccdb13a20bf2: Pushed\n",
      "85389f9ead9e: Pushed\n",
      "9513cdf4e497: Pushed\n",
      "7f083f9454c0: Pushed\n",
      "\n",
      "df18b66efaa6: Pushed\n",
      "29f36b5893dc: Pushed\n",
      "4fae00ac92f6: Pushed\n",
      "latest: digest: sha256:7bd670545e6f02976bcc589eab181c573d9b971f24e5b53d19e7bad625610064 size: 3883\n",
      "2020/04/29 18:57:00 Successfully pushed image: cesardlautoma5f87185.azurecr.io/azureml/azureml_b75709396e112eb3c528ff9421e54d7f:latest\n",
      "2020/04/29 18:57:00 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 296.896444)\n",
      "2020/04/29 18:57:00 Populating digests for step ID: acb_step_0...\n",
      "2020/04/29 18:57:02 Successfully populated digests for step ID: acb_step_0\n",
      "2020/04/29 18:57:02 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 172.868887)\n",
      "2020/04/29 18:57:02 The following dependencies were found:\n",
      "2020/04/29 18:57:02 \n",
      "- image:\n",
      "    registry: cesardlautoma5f87185.azurecr.io\n",
      "    repository: azureml/azureml_b75709396e112eb3c528ff9421e54d7f\n",
      "    tag: latest\n",
      "    digest: sha256:7bd670545e6f02976bcc589eab181c573d9b971f24e5b53d19e7bad625610064\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/base\n",
      "    tag: intelmpi2018.3-ubuntu16.04\n",
      "    digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cp11 was successful after 7m57s\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_18d6587efde1d8b73f740672f98381309a859eace68e4a64cf477ea89696ae63_d.txt\n",
      "========================================================================================================================\n",
      "2020-04-29T18:57:30Z Starting output-watcher...\n",
      "2020-04-29T18:57:30Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_b75709396e112eb3c528ff9421e54d7f\n",
      "a1298f4ce990: Pulling fs layer\n",
      "04a3282d9c4b: Pulling fs layer\n",
      "9b0d3db6dc03: Pulling fs layer\n",
      "8269c605f3f1: Pulling fs layer\n",
      "6504d449e70c: Pulling fs layer\n",
      "4e38f320d0d4: Pulling fs layer\n",
      "b0a763e8ee03: Pulling fs layer\n",
      "11917a028ca4: Pulling fs layer\n",
      "a6c378d11cbf: Pulling fs layer\n",
      "6cc007ad9140: Pulling fs layer\n",
      "6c1698a608f3: Pulling fs layer\n",
      "b42202f2f29b: Pulling fs layer\n",
      "0293ce4cde4b: Pulling fs layer\n",
      "faf4a144b597: Pulling fs layer\n",
      "9353f057e3d3: Pulling fs layer\n",
      "dd8bc8ef7897: Pulling fs layer\n",
      "6bb4f3f71377: Pulling fs layer\n",
      "6504d449e70c: Waiting\n",
      "4e38f320d0d4: Waiting\n",
      "b0a763e8ee03: Waiting\n",
      "11917a028ca4: Waiting\n",
      "a6c378d11cbf: Waiting\n",
      "6cc007ad9140: Waiting\n",
      "6c1698a608f3: Waiting\n",
      "b42202f2f29b: Waiting\n",
      "0293ce4cde4b: Waiting\n",
      "faf4a144b597: Waiting\n",
      "9353f057e3d3: Waiting\n",
      "dd8bc8ef7897: Waiting\n",
      "6bb4f3f71377: Waiting\n",
      "8269c605f3f1: Waiting\n",
      "04a3282d9c4b: Verifying Checksum\n",
      "04a3282d9c4b: Download complete\n",
      "9b0d3db6dc03: Verifying Checksum\n",
      "9b0d3db6dc03: Download complete\n",
      "8269c605f3f1: Verifying Checksum\n",
      "8269c605f3f1: Download complete\n",
      "a1298f4ce990: Verifying Checksum\n",
      "a1298f4ce990: Download complete\n",
      "4e38f320d0d4: Verifying Checksum\n",
      "4e38f320d0d4: Download complete\n",
      "b0a763e8ee03: Verifying Checksum\n",
      "b0a763e8ee03: Download complete\n",
      "6504d449e70c: Verifying Checksum\n",
      "6504d449e70c: Download complete\n",
      "11917a028ca4: Verifying Checksum\n",
      "11917a028ca4: Download complete\n",
      "6cc007ad9140: Verifying Checksum\n",
      "6cc007ad9140: Download complete\n",
      "6c1698a608f3: Verifying Checksum\n",
      "6c1698a608f3: Download complete\n",
      "b42202f2f29b: Verifying Checksum\n",
      "b42202f2f29b: Download complete\n",
      "0293ce4cde4b: Verifying Checksum\n",
      "0293ce4cde4b: Download complete\n",
      "faf4a144b597: Verifying Checksum\n",
      "faf4a144b597: Download complete\n",
      "9353f057e3d3: Verifying Checksum\n",
      "9353f057e3d3: Download complete\n",
      "6bb4f3f71377: Verifying Checksum\n",
      "6bb4f3f71377: Download complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a6c378d11cbf: Verifying Checksum\n",
      "a6c378d11cbf: Download complete\n",
      "a1298f4ce990: Pull complete\n",
      "04a3282d9c4b: Pull complete\n",
      "9b0d3db6dc03: Pull complete\n",
      "8269c605f3f1: Pull complete\n",
      "dd8bc8ef7897: Verifying Checksum\n",
      "dd8bc8ef7897: Download complete\n",
      "6504d449e70c: Pull complete\n",
      "4e38f320d0d4: Pull complete\n",
      "b0a763e8ee03: Pull complete\n",
      "11917a028ca4: Pull complete\n",
      "a6c378d11cbf: Pull complete\n",
      "6cc007ad9140: Pull complete\n",
      "6c1698a608f3: Pull complete\n",
      "b42202f2f29b: Pull complete\n",
      "0293ce4cde4b: Pull complete\n",
      "faf4a144b597: Pull complete\n",
      "9353f057e3d3: Pull complete\n",
      "dd8bc8ef7897: Pull complete\n",
      "6bb4f3f71377: Pull complete\n",
      "Digest: sha256:7bd670545e6f02976bcc589eab181c573d9b971f24e5b53d19e7bad625610064\n",
      "Status: Downloaded newer image for cesardlautoma5f87185.azurecr.io/azureml/azureml_b75709396e112eb3c528ff9421e54d7f:latest\n",
      "78e2cea629f571d8885f2e518b2a923fcff5b0bdfe9013c7f37f74621e81ed47\n",
      "2020/04/29 19:00:33 Version: 3.0.01196.0002 Branch: hotfix1 Commit: bc95bff5\n",
      "2020/04/29 19:00:33 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/04/29 19:00:33 sshd runtime has already been installed in the container\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_18d6587efde1d8b73f740672f98381309a859eace68e4a64cf477ea89696ae63_d.txt\n",
      "===============================================================================================================\n",
      "Starting job_prep.py script\n",
      "Starting job preparation. Current time:2020-04-29T19:00:35.370386\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: a06506c7-ca0a-498b-ab14-416f1efc391b\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 75\n",
      "Starting project file download.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 132\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ dataprep.py ] with arguments: ['--output_path', '/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0/mounts/workspaceblobstore/azureml/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0/titanic_train']\n",
      "After variable expansion, calling script [ dataprep.py ] with arguments: ['--output_path', '/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0/mounts/workspaceblobstore/azureml/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0/titanic_train']\n",
      "\n",
      "\n",
      "\n",
      "The experiment failed. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.5912580490112305 seconds\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 132\n",
      "Traceback (most recent call last):\n",
      "  File \"dataprep.py\", line 55, in <module>\n",
      "    df = titanic_ds.to_pandas_dataframe().drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
      "AttributeError: 'FileDataset' object has no attribute 'to_pandas_dataframe'\n",
      "\n",
      "2020/04/29 19:00:49 mpirun version string: {\n",
      "Intel(R) MPI Library for Linux* OS, Version 2018 Update 3 Build 20180411 (id: 18329)\n",
      "Copyright 2003-2018 Intel Corporation.\n",
      "}\n",
      "2020/04/29 19:00:49 MPI publisher: intel ; version: 2018\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_18d6587efde1d8b73f740672f98381309a859eace68e4a64cf477ea89696ae63_d.txt\n",
      "===============================================================================================================\n",
      "Starting job release. Current time:2020-04-29T19:00:53.577547\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 183\n",
      "Job release is complete. Current time:2020-04-29T19:00:56.818994\n",
      "\n",
      "StepRun(dataprep) Execution Summary\n",
      "====================================\n",
      "StepRun( dataprep ) Status: Failed\n",
      "\n",
      "Warnings:\n",
      "This compute target type doesn't support non-Docker runs; overriding run configuration to enable Docker.\n",
      "Please enable Docker in the environment section of your run configuration to stop seeing this warning message.\n",
      "{\n",
      "  \"error\": {\n",
      "    \"code\": \"UserError\",\n",
      "    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\",\n",
      "    \"messageFormat\": null,\n",
      "    \"messageParameters\": null,\n",
      "    \"referenceCode\": null,\n",
      "    \"detailsUri\": null,\n",
      "    \"target\": null,\n",
      "    \"details\": [],\n",
      "    \"innerError\": null,\n",
      "    \"debugInfo\": null\n",
      "  },\n",
      "  \"correlation\": {\n",
      "    \"operation\": null,\n",
      "    \"request\": \"ff087823dd805b1d\"\n",
      "  },\n",
      "  \"environment\": \"northcentralus\",\n",
      "  \"location\": \"northcentralus\",\n",
      "  \"time\": \"2020-04-29T19:00:58.5365857+00:00\"\n",
      "}\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with AttributeError: 'FileDataset' object has no attribute 'to_pandas_dataframe'\",\n        \"detailsUri\": \"https://aka.ms/azureml-known-errors\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"AttributeError\",\n            \"message\": \"'FileDataset' object has no attribute 'to_pandas_dataframe'\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0/mounts/workspaceblobstore/azureml/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0/azureml-setup/context_manager_injector.py\\\", line 127, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"dataprep.py\\\", line 55, in <module>\\n    df = titanic_ds.to_pandas_dataframe().drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\\n\"\n        },\n        \"messageParameters\": {}\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with AttributeError: 'FileDataset' object has no attribute 'to_pandas_dataframe'\\\",\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"AttributeError\\\",\\n            \\\"message\\\": \\\"'FileDataset' object has no attribute 'to_pandas_dataframe'\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0/mounts/workspaceblobstore/azureml/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0/azureml-setup/context_manager_injector.py\\\\\\\", line 127, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"dataprep.py\\\\\\\", line 55, in <module>\\\\n    df = titanic_ds.to_pandas_dataframe().drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\\\\n\\\"\\n        },\\n        \\\"messageParameters\\\": {}\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3817306bf75a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    289\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                             step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[1;32m--> 291\u001b[1;33m                                                          raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m    292\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mtimeout_seconds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    714\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[1;32m--> 716\u001b[1;33m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                 \u001b[0merror_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"The output streaming for the run interrupted.\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\azureml\\pipeline\\core\\run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[1;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with AttributeError: 'FileDataset' object has no attribute 'to_pandas_dataframe'\",\n        \"detailsUri\": \"https://aka.ms/azureml-known-errors\",\n        \"details\": [],\n        \"debugInfo\": {\n            \"type\": \"AttributeError\",\n            \"message\": \"'FileDataset' object has no attribute 'to_pandas_dataframe'\",\n            \"stackTrace\": \"  File \\\"/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0/mounts/workspaceblobstore/azureml/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0/azureml-setup/context_manager_injector.py\\\", line 127, in execute_with_context\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\"__main__\\\")\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\", line 263, in run_path\\n    pkg_name=pkg_name, script_name=fname)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\", line 96, in _run_module_code\\n    mod_name, mod_spec, pkg_name, script_name)\\n  File \\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\", line 85, in _run_code\\n    exec(code, run_globals)\\n  File \\\"dataprep.py\\\", line 55, in <module>\\n    df = titanic_ds.to_pandas_dataframe().drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\\n\"\n        },\n        \"messageParameters\": {}\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with AttributeError: 'FileDataset' object has no attribute 'to_pandas_dataframe'\\\",\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-known-errors\\\",\\n        \\\"details\\\": [],\\n        \\\"debugInfo\\\": {\\n            \\\"type\\\": \\\"AttributeError\\\",\\n            \\\"message\\\": \\\"'FileDataset' object has no attribute 'to_pandas_dataframe'\\\",\\n            \\\"stackTrace\\\": \\\"  File \\\\\\\"/mnt/batch/tasks/shared/LS_root/jobs/cesardl-automl-ncentralus-demo-ws/azureml/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0/mounts/workspaceblobstore/azureml/a9ad403d-ab3b-44bb-a5d0-5af9d887f0f0/azureml-setup/context_manager_injector.py\\\\\\\", line 127, in execute_with_context\\\\n    runpy.run_path(sys.argv[0], globals(), run_name=\\\\\\\"__main__\\\\\\\")\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\\\\\", line 263, in run_path\\\\n    pkg_name=pkg_name, script_name=fname)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\\\\\", line 96, in _run_module_code\\\\n    mod_name, mod_spec, pkg_name, script_name)\\\\n  File \\\\\\\"/azureml-envs/azureml_0bdf841bedfca5de2e4cf97ccc64431d/lib/python3.6/runpy.py\\\\\\\", line 85, in _run_code\\\\n    exec(code, run_globals)\\\\n  File \\\\\\\"dataprep.py\\\\\\\", line 55, in <module>\\\\n    df = titanic_ds.to_pandas_dataframe().drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\\\\n\\\"\\n        },\\n        \\\"messageParameters\\\": {}\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automl_run = next(r for r in run.get_children() if r.name == 'AutoML_Classification')\n",
    "# outputs = automl_run.get_outputs()\n",
    "# metrics = outputs['default_metrics_AutoML_Classification']\n",
    "# model = outputs['default_model_AutoML_Classification']\n",
    "\n",
    "# metrics.get_port_data_reference().download('.')\n",
    "# model.get_port_data_reference().download('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
