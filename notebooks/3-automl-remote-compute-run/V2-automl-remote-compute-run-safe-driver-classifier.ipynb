{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML on remote AML Compute (Porto Seguro's Safe Driving Prediction)\n",
    "\n",
    "This notebook is refactored (from the original AutoML local training notebook) to use AutoML on remote AML compute, in a cluster.\n",
    "It also uses AML Datasets for training instead of Pandas Dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilitity methods\n",
    "\n",
    "Some methods to keep track of the job, download logs etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility methods\n",
    "\n",
    "# Currently, there's no SDK v2 equivalent of v1's 'show_output' or 'wait_for_completion' functionality, \n",
    "# that prints the AutoML iteration info\n",
    "\n",
    "def show_output(client, job) -> None:    \n",
    "    # This doesn't appear to stream anything at the moment\n",
    "    client.jobs.stream(created_job.name)\n",
    "\n",
    "\n",
    "def wait_for_completion(client, job, poll_duration: int = 30) -> None:    \n",
    "    \"\"\"Poll for job status every `poll_duration` seconds, until it is terminated\"\"\"\n",
    "    import time\n",
    "    from azure.ml._operations.run_history_constants import RunHistoryConstants\n",
    "\n",
    "    cur_status = client.jobs.get(job.name).status\n",
    "    print(\"Current job status: \", cur_status)\n",
    "    while cur_status not in RunHistoryConstants.TERMINAL_STATUSES:\n",
    "        time.sleep(poll_duration)\n",
    "        cur_status = client.jobs.get(job.name).status\n",
    "        print(\"Current job status: \", cur_status)\n",
    "\n",
    "\n",
    "def download_outputs(client, job) -> None:\n",
    "    # This does not download any logs (no models as well, since this is at the parent run level)\n",
    "    client.jobs.download(job.name, download_path=\"./outputs\")\n",
    "\n",
    "    # For the child run level, currently this throws an exception saying it's not supported for the job type\n",
    "    try:\n",
    "        first_child_run = \"{}_0\".format(job.name)\n",
    "        client.jobs.download(first_child_run, download_path=\"./outputs/\")\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "\n",
    "        print(str(e))\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "def print_studio_url(job, open_in_new_tab: bool = False) -> None:\n",
    "    # TODO: Any easier way to get the URL?\n",
    "    \n",
    "    print(\"Studio URL: \", job.interaction_endpoints['Studio'].endpoint)\n",
    "    if open_in_new_tab:\n",
    "        import webbrowser\n",
    "        webbrowser.open(job.interaction_endpoints['Studio'].endpoint)\n",
    "        \n",
    "\n",
    "def download_outputs_via_mlflow_client(mlflow_client, run_id, path) -> str:\n",
    "    \"\"\"Download the `path` (file or dir) from the run artifacts, returns the local path download\"\"\"\n",
    "    local_path = os.path.join(\"/tmp/artifact_downloads/{}\".format(run_id), path)\n",
    "    if os.path.exists(local_path):\n",
    "        print(\"Directory {} already exists. Skipping download.\".format(os.path.join(local_dir, path)))\n",
    "    else:\n",
    "        # download outputs\n",
    "        if not os.path.exists(local_dir):\n",
    "            os.mkdir(local_dir)\n",
    "\n",
    "        local_path = mlflow_client.download_artifacts(run_id, path, local_dir)\n",
    "        print(\"Artifacts downloaded to: {}\".format(local_path))\n",
    "        print(\"Artifacts: {}\".format(os.listdir(local_path)))\n",
    "    return local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Needed Packages\n",
    "\n",
    "Import the general packages needed for this notebook. These are SDK V2 packages needed to create compute, upload dataset, submit jobs etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1616704851120
    }
   },
   "outputs": [],
   "source": [
    "# Global imports\n",
    "from azure.ml import MLClient\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "\n",
    "from azure.ml.entities.workspace.workspace import Workspace\n",
    "from azure.ml.entities.compute.compute import Compute\n",
    "from azure.ml.entities.assets import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Azure ML SDK version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1616704851360
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using version <module 'azure.ml' from '/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/__init__.py'> of the Azure ML SDK\n"
     ]
    }
   ],
   "source": [
    "import azure.ml\n",
    "print(\"You are currently using version\", azure.ml, \"of the Azure ML SDK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Initiliaze MLClient\n",
    "\n",
    "The MLClient is used to interface with AzureML services, to submit job, create compute, upload data etc.\n",
    "The resource group must be existing at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1616704977544
    }
   },
   "outputs": [],
   "source": [
    "subscription_id = '381b38e9-9840-4719-a5a0-61d9585e1e91'\n",
    "resource_group_name = 'gasi_rg_neu'\n",
    "\n",
    "client = MLClient(subscription_id, resource_group_name) # default_workspace_name=workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "\n",
    "Also set this as the default workspace for submitting ML Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace with name gasi_ws_neu already exists.\n"
     ]
    }
   ],
   "source": [
    "workspace_name = 'gasi_ws_neu'\n",
    "workspace = Workspace(name=workspace_name)\n",
    "\n",
    "try:\n",
    "    client.workspaces.create(workspace)\n",
    "except ResourceExistsError as re:\n",
    "    print(re)\n",
    "    \n",
    "client.default_workspace_name = workspace_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azureml-train-restclients-hyperdrive 0.1.0.0 (/home/schrodinger/automl/AzureMlCli/src/azureml-train-restclients-hyperdrive), Requirement.parse('azureml-train-restclients-hyperdrive~=1.27.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azureml-dataset-runtime 0.1.0.0 (/home/schrodinger/automl/AzureMlCli/src/azureml-dataset-runtime), Requirement.parse('azureml-dataset-runtime~=1.27.0')).\n",
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registry URI:         azureml://northeurope.experiments.azureml.net/mlflow/v1.0/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_neu/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_neu?\n",
      "\n",
      "Current tracking uri: azureml://northeurope.experiments.azureml.net/mlflow/v1.0/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_neu/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_neu?\n"
     ]
    }
   ],
   "source": [
    "# Set the tracking URI to AzureML, and changing the active experiment\n",
    "\n",
    "import mlflow\n",
    "\n",
    "##### NOTE: This is SDK v1 API #####\n",
    "# TODO: How do we get this from MLClient? Tracking URI can't be obtained from v2 Workspace object\n",
    "from azureml.core import Workspace as WorkspaceV1\n",
    "ws = WorkspaceV1(workspace_name=workspace_name, resource_group=resource_group_name, subscription_id=subscription_id)\n",
    "####################################\n",
    "\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "\n",
    "# Set the active experiment, creating one if it doesn't exist\n",
    "# mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Get Experiment Details\n",
    "# experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "# print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "# print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "# print(\"Tags: {}\".format(experiment.tags))\n",
    "# print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "\n",
    "print(\"\\nRegistry URI:         {}\".format(mlflow.get_registry_uri()))\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Submit dataset file into DataStore (Azure Blob under the covers)\n",
    "\n",
    "If there's a CSV file locally, upload it to the datastore.\n",
    "\n",
    "Note that this is currently going to upload the dataset as a File Dataset, which is incompatible with AutoML. As such, ensure that a TabularDataset is registered with this name outside of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1616704980161
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not create dataset.  (UserError) A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's Path cannot be changed. Only tags and description can be updated.\n",
      "Additional Information:Type: ComponentName\n",
      "Info: \"managementfrontend\"Type: Correlation\n",
      "Info: {\n",
      "    \"operation\": \"5cf159221529b446b761ce5f9408ca51\",\n",
      "    \"request\": \"e60f0ca38ac11f41\"\n",
      "}Type: Environment\n",
      "Info: \"northeurope\"Type: Location\n",
      "Info: \"northeurope\"Type: Time\n",
      "Info: \"2021-05-18T00:25:40.7241096+00:00\"Type: DebugInfo\n",
      "Info: {\n",
      "    \"type\": \"Microsoft.MachineLearning.Common.Core.Exceptions.BaseException\",\n",
      "    \"message\": \"A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's Path cannot be changed. Only tags and description can be updated.\",\n",
      "    \"stackTrace\": \"   at Microsoft.MachineLearning.ManagementFrontEnd.Services.Validators.DataVersionValidator.ValidUpdateRequest(DataVersion dataVersion1, DataVersion dataVersion2) in /home/vsts/work/1/s/src/azureml-api/src/ManagementFrontEnd/Services/Validators/DataVersionValidator.cs:line 49\\n   at Microsoft.MachineLearning.ManagementFrontEnd.Services.DataVersionService.Update(WorkspaceContext2 workspaceContext, DataVersion dataversion, String name, String version) in /home/vsts/work/1/s/src/azureml-api/src/ManagementFrontEnd/Services/Services/DataVersionService.cs:line 279\\n   at Microsoft.MachineLearning.ManagementFrontEnd.Services.DataVersionService.CreateOrUpdate(WorkspaceContext2 workspace, String name, String version, Resource`1 versionEntity) in /home/vsts/work/1/s/src/azureml-api/src/ManagementFrontEnd/Services/Services/DataVersionService.cs:line 78\\n   at Microsoft.MachineLearning.ManagementFrontEnd.EntryPoints.Api.V20210301Preview.Controllers.ResourceVersionControllerBase`2.CreateOrUpdate(WorkspaceContext2 workspaceContext, String name, String version, Resource`1 request, String apiVersion) in /home/vsts/work/1/s/src/azureml-api/src/ManagementFrontEnd/EntryPoints/Api/V20210301Preview/Controllers/ResourceVersionControllerBase.cs:line 70\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.TaskOfIActionResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeActionMethodAsync>g__Logged|12_1(ControllerActionInvoker invoker)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeNextActionFilterAsync>g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeInnerFilterAsync>g__Awaited|13_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeNextExceptionFilterAsync>g__Awaited|25_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\",\n",
      "    \"innerException\": null,\n",
      "    \"data\": {\n",
      "        \"BaseError\": {\n",
      "            \"Definition\": {\n",
      "                \"MessageFormat\": \"A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's {property} cannot be changed. Only tags and description can be updated.\",\n",
      "                \"DetailsUri\": null,\n",
      "                \"IsTransient\": null,\n",
      "                \"CodesHierarchy\": [\n",
      "                    \"UserError\",\n",
      "                    \"Immutable\",\n",
      "                    \"DataVersionPropertyImmutable\"\n",
      "                ],\n",
      "                \"Code\": \"DataVersionPropertyImmutable\"\n",
      "            },\n",
      "            \"Message\": \"A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's Path cannot be changed. Only tags and description can be updated.\",\n",
      "            \"MessageParameters\": {\n",
      "                \"property\": \"Path\"\n",
      "            },\n",
      "            \"Target\": null,\n",
      "            \"RetryAfterSeconds\": null\n",
      "        }\n",
      "    },\n",
      "    \"errorResponse\": null\n",
      "}Type: DetailsUri\n",
      "Info: nullType: InnerError\n",
      "Info: {\n",
      "    \"code\": \"Immutable\",\n",
      "    \"innerError\": {\n",
      "        \"code\": \"DataVersionPropertyImmutable\",\n",
      "        \"innerError\": null\n",
      "    }\n",
      "}Type: MessageFormat\n",
      "Info: \"A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's {property} cannot be changed. Only tags and description can be updated.\"Type: MessageParameters\n",
      "Info: {\n",
      "    \"property\": \"Path\"\n",
      "}Type: ReferenceCode\n",
      "Info: nullType: Severity\n",
      "Info: null\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data({'is_anonymous': False, 'name': 'porto_seguro_safe_driver_prediction_trimmed', 'id': None, 'description': None, 'tags': {}, 'properties': {}, 'base_path': './', 'creation_context': None, 'version': 1, 'datastore': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_neu/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_neu/datastores/workspaceblobstore', 'path': 'az-ml-artifacts/176b8ab41ee91bbc7c2efbfe86483578/porto_data', 'local_path': PosixPath('/home/schrodinger/automl/Easy-AutoML-MLOps/notebooks/3-automl-remote-compute-run/porto_data')})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload dataset\n",
    "\n",
    "dataset_name = \"porto_seguro_safe_driver_prediction_trimmed\"\n",
    "dataset_version = 1\n",
    "\n",
    "training_data = Data(name=dataset_name, version=dataset_version, local_path=\"./porto_data\")\n",
    "\n",
    "try:\n",
    "    data = client.data.create_or_update(training_data)\n",
    "    print(\"Uploaded to path  : \", data.path)\n",
    "    print(\"Datastore location: \", data.datastore)\n",
    "except Exception as e:\n",
    "    print(\"Could not create dataset. \", str(e))\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"{}:{}\".format(dataset_name, dataset_version) == \"{}:{}\".format(training_data.name, training_data.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into Azure ML Dataset and Register into Workspace\n",
    "\n",
    "Tabular Datasets are currently not supported with SDK v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1616704981055
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data({'is_anonymous': False, 'name': 'porto_seguro_safe_driver_prediction_trimmed', 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_neu/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_neu/data/porto_seguro_safe_driver_prediction_trimmed/versions/1', 'description': None, 'tags': {}, 'properties': {}, 'base_path': './', 'creation_context': <azure.ml._restclient._2021_03_01_preview.machinelearningservices.models._models_py3.SystemData object at 0x7f1400f22b10>, 'version': 1, 'datastore': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_neu/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_neu/datastores/workspaceblobstore', 'path': 'UI/05-13-2021_081406_UTC/porto_seguro_safe_driver_prediction_trimmed.csv', 'local_path': None})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to load the dataset from the Workspace\n",
    "\n",
    "dataset = client.data.get(name=dataset_name, version=dataset_version)\n",
    "\n",
    "\n",
    "# found = False\n",
    "# aml_dataset_name = \"porto_seguro_safe_driver_prediction_train\"\n",
    "\n",
    "# if aml_dataset_name in ws.datasets.keys(): \n",
    "#        found = True\n",
    "#        aml_dataset = ws.datasets[aml_dataset_name] \n",
    "#        print(\"Dataset loaded from the Workspace\")\n",
    "       \n",
    "# if not found:\n",
    "#         # Create AML Dataset and register it into Workspace\n",
    "#         print(\"Dataset does not exist in the current Workspace. It will be imported and registered.\")\n",
    "        \n",
    "#         # Option A: Create AML Dataset from file in AML DataStore\n",
    "#         # datastore = ws.get_default_datastore()\n",
    "#         # aml_dataset = Dataset.Tabular.from_delimited_files(path=datastore.path('Datasets/porto_seguro_safe_driver_prediction/porto_seguro_safe_driver_prediction_train.csv'))\n",
    "#         # data_origin_type = 'AMLDataStore'\n",
    "        \n",
    "#         # Option B: Create AML Dataset from file in HTTP URL\n",
    "#         data_url = 'https://azmlworkshopdata.blob.core.windows.net/safedriverdata/porto_seguro_safe_driver_prediction_train.csv'\n",
    "#         aml_dataset = Dataset.Tabular.from_delimited_files(data_url)  \n",
    "#         data_origin_type = 'HttpUrl'\n",
    "        \n",
    "#         print(aml_dataset)\n",
    "                \n",
    "#         #Register Dataset in Workspace\n",
    "#         registration_method = 'SDK'  # or 'UI'\n",
    "#         aml_dataset = aml_dataset.register(workspace=ws,\n",
    "#                                            name=aml_dataset_name,\n",
    "#                                            description='Porto Seguro Safe Driver Prediction Train dataset file',\n",
    "#                                            tags={'Registration-Method': registration_method, 'Data-Origin-Type': data_origin_type},\n",
    "#                                            create_new_version=True)\n",
    "        \n",
    "#         print(\"Dataset created from file and registered in the Workspace\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1616704986719
    }
   },
   "outputs": [],
   "source": [
    "# # Use Pandas DataFrame just to sneak peak some data and schema\n",
    "# data_df = aml_dataset.to_pandas_dataframe()\n",
    "# print(data_df.shape)\n",
    "# print(data_df.describe())\n",
    "# data_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Test AML Tabular Datasets\n",
    "\n",
    "Remote AML Training you need to use AML Datasets, you cannot submit Pandas Dataframes to remote runs of AutoMLConfig.\n",
    "\n",
    "Note that AutoMLConfig below is not using the Test dataset (you only provide a single dataset that will internally be split in validation/train datasets or use cross-validation depending on the size of the dataset. The boundary for that is 20k rows, using cross-validation if less than 20k. This can also be decided by the user.). \n",
    "\n",
    "The Test dataset will be used at the end of the notebook to manually calculate the quality metrics with a dataset not seen by AutoML training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1616705002541
    }
   },
   "outputs": [],
   "source": [
    "# # Split in train/test datasets (Test=10%, Train=90%)\n",
    "\n",
    "# train_dataset, test_dataset = aml_dataset.random_split(0.9, seed=0)\n",
    "\n",
    "# # Use Pandas DF only to check the data\n",
    "# train_df = train_dataset.to_pandas_dataframe()\n",
    "# test_df = test_dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1616705003514
    }
   },
   "outputs": [],
   "source": [
    "# print(train_df.shape)\n",
    "# print(test_df.shape)\n",
    "\n",
    "# train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1616705003793
    }
   },
   "outputs": [],
   "source": [
    "# train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Remote AML Compute (Existing AML cluster)\n",
    "\n",
    "Note that this step currently fails due to some deserialization error from SDK. Ensure that a compute cluster exists by creating it outside of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1616705019346
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not create compute. Cannot deserialize duration object., ISO8601Error: Unable to parse duration string ''\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1872, in deserialize_duration\n",
      "    duration = isodate.parse_duration(attr)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/isodate/isoduration.py\", line 104, in parse_duration\n",
      "    raise ISO8601Error(\"Unable to parse duration string %r\" % datestring)\n",
      "isodate.isoerror.ISO8601Error: Unable to parse duration string ''\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-14-5f5576546e55>\", line 14, in <module>\n",
      "    client.compute.create(compute)\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_operations/compute_operations.py\", line 98, in create\n",
      "    polling=not no_wait,\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_restclient/_2021_03_01_preview/machinelearningservices/operations/_machine_learning_compute_operations.py\", line 304, in begin_create_or_update\n",
      "    **kwargs\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_restclient/_2021_03_01_preview/machinelearningservices/operations/_machine_learning_compute_operations.py\", line 251, in _create_or_update_initial\n",
      "    deserialized = self._deserialize('ComputeResource', pipeline_response)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1368, in __call__\n",
      "    return self._deserialize(target_obj, data)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1442, in _deserialize\n",
      "    value = self.deserialize_data(raw_value, attr_desc['type'])\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1631, in deserialize_data\n",
      "    return self._deserialize(obj_type, data)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1442, in _deserialize\n",
      "    value = self.deserialize_data(raw_value, attr_desc['type'])\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1631, in deserialize_data\n",
      "    return self._deserialize(obj_type, data)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1442, in _deserialize\n",
      "    value = self.deserialize_data(raw_value, attr_desc['type'])\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1631, in deserialize_data\n",
      "    return self._deserialize(obj_type, data)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1442, in _deserialize\n",
      "    value = self.deserialize_data(raw_value, attr_desc['type'])\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1613, in deserialize_data\n",
      "    data_val = self.deserialize_type[data_type](data)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1875, in deserialize_duration\n",
      "    raise_with_traceback(DeserializationError, msg, err)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/exceptions.py\", line 51, in raise_with_traceback\n",
      "    raise error.with_traceback(exc_traceback)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1872, in deserialize_duration\n",
      "    duration = isodate.parse_duration(attr)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/isodate/isoduration.py\", line 104, in parse_duration\n",
      "    raise ISO8601Error(\"Unable to parse duration string %r\" % datestring)\n",
      "msrest.exceptions.DeserializationError: Cannot deserialize duration object., ISO8601Error: Unable to parse duration string ''\n"
     ]
    }
   ],
   "source": [
    "# Set or create compute\n",
    "\n",
    "cpu_cluster_name = \"cpucluster\"\n",
    "compute = Compute(\"amlcompute\",\n",
    "                  name=cpu_cluster_name, size=\"STANDARD_D13_V2\",\n",
    "                  min_instances=0, max_instances=3,\n",
    "                  idle_time_before_scale_down=120)\n",
    "\n",
    "# Load directly from YAML file\n",
    "# compute = Compute.load(\"./compute.yaml\")\n",
    "\n",
    "try:\n",
    "    # TODO: This currently results in an exception in Azure ML, please create compute manually.\n",
    "    client.compute.create(compute)\n",
    "except ResourceExistsError as re:\n",
    "    print(re)\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    \n",
    "    print(\"Could not create compute.\", str(e))\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1616705020057
    }
   },
   "outputs": [],
   "source": [
    "# For additional details of current AmlCompute status:\n",
    "# aml_remote_compute.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Azure AutoML automatically searching for the 'best model' (Best algorithms and best hyper-parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List and select primary metric to drive the AutoML classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1616705020282
    }
   },
   "outputs": [],
   "source": [
    "# from azureml.train import automl\n",
    "\n",
    "# # List of possible primary metrics is here:\n",
    "# # https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train#primary-metric\n",
    "    \n",
    "# # Get a list of valid metrics for your given task\n",
    "# automl.utilities.get_primary_metrics('classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AutoML Experiment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoMLJob({'name': '05bb01e9-a479-48ba-a0e3-3bcd868dbcd7', 'id': None, 'description': None, 'tags': {}, 'properties': {'save_mlflow': True}, 'base_path': './', 'type': 'automl_job', 'creation_context': None, 'experiment_name': '3-automl-remote-compute-run', 'status': None, 'interaction_endpoints': None, 'log_files': None, 'output': None, 'general_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.GeneralSettings object at 0x7f1400f39310>, 'data_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.DataSettings object at 0x7f140b575e90>, 'limit_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.LimitSettings object at 0x7f140b592dd0>, 'forecasting_settings': None, 'training_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.TrainingSettings object at 0x7f140b575fd0>, 'featurization_settings': <azure.ml.entities.job.automl.featurization.FeaturizationSettings object at 0x7f140b575bd0>, 'compute': <azure.ml._schema.compute_binding.InternalComputeConfiguration object at 0x7f1400ee7910>})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ml._restclient._2020_09_01_preview.machinelearningservices.models import GeneralSettings, LimitSettings, DataSettings, TrainingDataSettings, ValidationDataSettings, TrainingSettings\n",
    "from azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._azure_machine_learning_workspaces_enums import TaskType, OptimizationMetric\n",
    "from azure.ml._schema.compute_binding import InternalComputeConfiguration\n",
    "from azure.ml.entities import AutoMLJob\n",
    "from azure.ml.entities.job.automl.featurization import FeaturizationSettings\n",
    "\n",
    "# TODO: Add the following\n",
    "# blocked_models = ['LogisticRegression', 'ExtremeRandomTrees', 'RandomForest'], \n",
    "# allowed_models = ['LightGBM'],\n",
    "# enable_voting_ensemble = True,\n",
    "# enable_stack_ensemble = False,\n",
    "# enable_early_stopping= True,\n",
    "# experiment_timeout_hours=3,                           \n",
    "# debug_log='automated_ml_errors.log',\n",
    "# verbosity= logging.DEBUG,\n",
    "# enable_onnx_compatible_models=True,\n",
    "\n",
    "compute = InternalComputeConfiguration(target=cpu_cluster_name)\n",
    "\n",
    "general_settings = GeneralSettings(task_type=TaskType.CLASSIFICATION,\n",
    "                                   primary_metric= OptimizationMetric.AUC_WEIGHTED,\n",
    "                                   enable_model_explainability=True)\n",
    "\n",
    "# TODO: Seems like a bug here, max_trials=3 + max_concurrent_trials=4 seems to only trigger one child run\n",
    "limit_settings = LimitSettings(job_timeout=60,\n",
    "                               max_trials=4,\n",
    "                               max_concurrent_trials=4,\n",
    "                               enable_early_termination=False)\n",
    "\n",
    "training_data_settings = TrainingDataSettings(dataset_arm_id=\"{}:{}\".format(training_data.name, training_data.version),\n",
    "                                              target_column_name=\"target\")\n",
    "validation_data_settings = ValidationDataSettings(validation_size=0.1)\n",
    "data_settings = DataSettings(training_data=training_data_settings, validation_data=validation_data_settings)\n",
    "\n",
    "featurization_settings = FeaturizationSettings(featurization_config=\"auto\")\n",
    "\n",
    "training_settings = TrainingSettings(enable_dnn_training=False)\n",
    "\n",
    "extra_automl_settings = {\"save_mlflow\": True}\n",
    "\n",
    "automl_job = AutoMLJob(\n",
    "#     name=job_name,\n",
    "    compute=compute,\n",
    "    general_settings=general_settings,\n",
    "    limit_settings=limit_settings,\n",
    "    data_settings=data_settings,\n",
    "    training_settings=training_settings,\n",
    "    featurization_settings=featurization_settings,\n",
    "    properties=extra_automl_settings,\n",
    ")\n",
    "\n",
    "automl_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiment (on remote AML Compute) with multiple child runs under the covers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoMLJob({'name': '05bb01e9-a479-48ba-a0e3-3bcd868dbcd7', 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_neu/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_neu/jobs/05bb01e9-a479-48ba-a0e3-3bcd868dbcd7', 'description': None, 'tags': {}, 'properties': {'save_mlflow': 'True'}, 'base_path': './', 'type': 'automl_job', 'creation_context': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.SystemData object at 0x7f140ce3d3d0>, 'experiment_name': '3-automl-remote-compute-run', 'status': 'NotStarted', 'interaction_endpoints': {'Tracking': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.JobEndpoint object at 0x7f140ce3d290>, 'Studio': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.JobEndpoint object at 0x7f140ce3d2d0>}, 'log_files': None, 'output': None, 'general_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.GeneralSettings object at 0x7f140ce3d0d0>, 'data_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.DataSettings object at 0x7f140ce3d1d0>, 'limit_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.LimitSettings object at 0x7f140ce3d190>, 'forecasting_settings': <azure.ml.entities.job.automl.forecasting.ForecastingSettings object at 0x7f1400f10e10>, 'training_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.TrainingSettings object at 0x7f140ce3d110>, 'featurization_settings': <azure.ml.entities.job.automl.featurization.FeaturizationSettings object at 0x7f1400f10cd0>, 'compute': <azure.ml._schema.compute_binding.InternalComputeConfiguration object at 0x7f1400f5ef10>})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit job\n",
    "# TODO: There appears to be a bug here (repro: try executing this cell twice)\n",
    "created_job = client.jobs.create_or_update(automl_job)\n",
    "created_job\n",
    "\n",
    "# Dump _all_ info we have about the job \n",
    "# created_job._dump_yaml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore results with Widget\n",
    "\n",
    "> Note: This doesn't have any equivalent SDK v2 API right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1616705036791
    }
   },
   "outputs": [],
   "source": [
    "# # Explore the results of automatic training with a Jupyter widget: https://docs.microsoft.com/en-us/python/api/azureml-widgets/azureml.widgets?view=azure-ml-py\n",
    "# from azureml.widgets import RunDetails\n",
    "# RunDetails(parent_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studio URL:  https://ml.azure.com/runs/05bb01e9-a479-48ba-a0e3-3bcd868dbcd7?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/gasi_rg_neu/workspaces/gasi_ws_neu&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "Current job status:  NotStarted\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading the job logs ExperimentRun/dcid.05bb01e9-a479-48ba-a0e3-3bcd868dbcd7/ at ./outputs/05bb01e9-a479-48ba-a0e3-3bcd868dbcd7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation returned an invalid status 'A job was found, but it is not supported in this API version and cannot be accessed.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-1-4fa2dbf6b888>\", line 31, in download_outputs\n",
      "    client.jobs.download(first_child_run, download_path=\"./outputs/\")\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_operations/job_operations.py\", line 255, in download\n",
      "    job_details = self.get(name)\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_operations/job_operations.py\", line 110, in get\n",
      "    job_object = self._get_job(name)\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_operations/job_operations.py\", line 294, in _get_job\n",
      "    **self._kwargs,\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_restclient/_2020_09_01_preview/machinelearningservices/operations/_jobs_operations.py\", line 196, in get\n",
      "    raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)\n",
      "azure.core.exceptions.HttpResponseError: Operation returned an invalid status 'A job was found, but it is not supported in this API version and cannot be accessed.'\n"
     ]
    }
   ],
   "source": [
    "# Wait for the remote parent run to complete\n",
    "\n",
    "# Get Studio URL, open in new tab\n",
    "print_studio_url(created_job)\n",
    "\n",
    "# Wait until the job is finished\n",
    "wait_for_completion(client, created_job)\n",
    "\n",
    "# Download logs + outputs locally\n",
    "download_outputs(client, created_job)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Parent Run Time needed for the whole AutoML process \n",
    "\n",
    "> Note: Todo -  Start time /  End time is available on run.info[start_time, end_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gather": {
     "logged": 1616706272935
    }
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# from datetime import datetime\n",
    "\n",
    "# run_details = parent_run.get_details()\n",
    "\n",
    "# # Like: 2020-01-12T23:11:56.292703Z\n",
    "# end_time_utc_str = run_details['endTimeUtc'].split(\".\")[0]\n",
    "# start_time_utc_str = run_details['startTimeUtc'].split(\".\")[0]\n",
    "# timestamp_end = time.mktime(datetime.strptime(end_time_utc_str, \"%Y-%m-%dT%H:%M:%S\").timetuple())\n",
    "# timestamp_start = time.mktime(datetime.strptime(start_time_utc_str, \"%Y-%m-%dT%H:%M:%S\").timetuple())\n",
    "\n",
    "# parent_run_time = timestamp_end - timestamp_start\n",
    "# print('Run Timing: --- %s minutes needed for running the whole Remote AutoML Experiment ---' % (parent_run_time/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating ModelProxy for submitting prediction runs to the training environment.\n",
    "We will create a ModelProxy for the best child run, which will allow us to submit a run that does the prediction in the training environment. Unlike the local client, which can have different versions of some libraries, the training environment will have all the compatible libraries for the model already.\n",
    "\n",
    "\n",
    "> **Note:**<br/>\n",
    "  This is currently not possible on SDK V2, the ModelProxy object expects a SDK v1 Run object. \n",
    "<br/>**Gaps**: <br/> 1. Make ModelProxy v1 concept independent (e.g. Run, Environment etc.), accepting individual properties that are needed for a Model Proxy job. OR, create ModelProxyJob? Or...? <br/> 2. Child runs are currently not submitted via. MFE, hence there's no way today to load the underlying child runs as v2 a 'Job', and access related information (like get it's environment, outputs etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################### Prepare Data ############################\n",
    "# y_test = test_dataset.keep_columns('target')\n",
    "# test_data_no_label = test_dataset.drop_columns('target')\n",
    "\n",
    "# test_data_no_label_df = test_data_no_label.to_pandas_dataframe()\n",
    "# print(test_data_no_label_df.shape)\n",
    "# ####################################################################\n",
    "\n",
    "\n",
    "# ################## Model Proxy Run ########################\n",
    "# from azureml.train.automl.model_proxy import ModelProxy\n",
    "# best_run = parent_run.get_best_child()\n",
    "# # best_run = parent_run.get_best_child(metric = \"accuracy\")\n",
    "\n",
    "# best_model_proxy = ModelProxy(best_run, aml_remote_compute)\n",
    "# y_pred_test = best_model_proxy.predict(test_data_no_label)\n",
    "\n",
    "# y_pred_test\n",
    "# ############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show hyperparameters\n",
    "Show the model pipeline used for the best run with its hyperparameters.\n",
    "\n",
    "> **Note:** <br/>This isn't possible with SDK V2, much of the Run DTO stuff gets lost in the v2 equivalent (Job).  <br/>**Gaps:** <br/> 1. Child runs are currently not submitted via. MFE, hence there's no way today to load the underlying child runs as v2 a 'Job', and access related information (like get it's environment, outputs etc.) <br/> 2. Decide if these methods need to be on the Run object, or should be ported to the model object, and be accessed from there (e.g. `best_automl_job.load_model().print_pipeline()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the 'Best' Model\n",
    "\n",
    "Using MLFlowClient to get the best child run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best child run id:  05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={'AUC_macro': 0.617244424629982,\n",
       " 'AUC_micro': 0.9716681799999999,\n",
       " 'AUC_weighted': 0.6172446874741211,\n",
       " 'accuracy': 0.9634,\n",
       " 'average_precision_score_macro': 0.5141399710497053,\n",
       " 'average_precision_score_micro': 0.9667662768482096,\n",
       " 'average_precision_score_weighted': 0.9419044919340782,\n",
       " 'balanced_accuracy': 0.5,\n",
       " 'f1_score_macro': 0.49067943363553024,\n",
       " 'f1_score_micro': 0.9634,\n",
       " 'f1_score_weighted': 0.9454411327289397,\n",
       " 'log_loss': 0.15478797349812543,\n",
       " 'matthews_correlation': 0.0,\n",
       " 'norm_macro_recall': 0.0,\n",
       " 'precision_score_macro': 0.4817,\n",
       " 'precision_score_micro': 0.9634,\n",
       " 'precision_score_weighted': 0.92813956,\n",
       " 'recall_score_macro': 0.5,\n",
       " 'recall_score_micro': 0.9634,\n",
       " 'recall_score_weighted': 0.9634,\n",
       " 'weighted_accuracy': 0.99855880571045}, params={}, tags={'_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":1,\"CurrentNodeCount\":1}',\n",
       " '_aml_system_automl_is_child_run_end_telemetry_event_logged': 'True',\n",
       " '_aml_system_azureml.automlComponent': 'AutoML',\n",
       " 'mlflow.parentRunId': '05bb01e9-a479-48ba-a0e3-3bcd868dbcd7',\n",
       " 'mlflow.source.name': 'automl_driver.py',\n",
       " 'mlflow.source.type': 'JOB',\n",
       " 'model_explain_run_id': '05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_ModelExplain',\n",
       " 'model_explanation': 'True'}>, info=<RunInfo: artifact_uri='azureml://experiments/3-automl-remote-compute-run/runs/05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_1/artifacts', end_time=1621298098843, experiment_id='71434ea8-978c-473a-a449-88f3bfd5bbc4', lifecycle_stage='active', run_id='05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_1', run_uuid='05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_1', start_time=1621298052775, status='FINISHED', user_id='d0b038bb-162b-4d49-b8fe-5786e199f6fb'>>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# TODO: Use this run, as it has MLFlow model stored on the run - AutoML_3454b06e-2e3e-4e3e-a8e0-f52f50f9f358\n",
    "\n",
    "mlflow_client = MlflowClient()\n",
    "mlflow_parent_run = mlflow_client.get_run(created_job.name)\n",
    "\n",
    "best_child_run_id = mlflow_parent_run.data.tags[\"automl_best_child_run_id\"]\n",
    "print(\"Found best child run id: \", best_child_run_id)\n",
    "\n",
    "mlflow_best_child_run = mlflow_client.get_run(best_child_run_id)\n",
    "mlflow_best_child_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show hyperparameters\n",
    "Show the model pipeline used for the best run with its hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost==0.90\n",
      "  Downloading xgboost-0.90-py2.py3-none-manylinux1_x86_64.whl (142.8 MB)\n",
      "\u001b[K     || 142.8 MB 91 kB/s s eta 0:00:01    |            | 86.7 MB 10.7 MB/s eta 0:00:06     |      | 112.2 MB 12.0 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages (from xgboost==0.90) (1.5.2)\n",
      "Requirement already satisfied: numpy in /home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages (from xgboost==0.90) (1.18.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost==0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/tmp/tmp1zc5q0_i/outputs/MLmodel'\n",
      "Failed to load MLFlow model, downloading artifacts manually and loading the model.\n",
      "Artifacts downloaded in: /tmp/artifact_downloads/05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_1/outputs\n",
      "Artifacts: ['pipeline_graph.json', 'env_dependencies.json', 'scoring_file_v_1_0_0.py', 'model.pkl', 'conda_env_v_1_0_0.yml']\n",
      "Pipeline(memory=None,\n",
      "         steps=[('datatransformer',\n",
      "                 DataTransformer(enable_dnn=False, enable_feature_sweeping=False, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=False, is_onnx_compatible=False, observer=None, task='classification', working_dir='/home/schrodinger/automl/Easy-AutoML-MLOps/notebooks/3-automl-remote-compute-run')),\n",
      "                ('MaxAbsScaler', MaxAbsScaler(copy=True)),\n",
      "                ('XGBoostClassifier',\n",
      "                 XGBoostClassifier(n_jobs=-1, problem_info=None, random_state=0))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Local predictions using python function flavor\n",
    "\n",
    "import mlflow.pyfunc\n",
    "\n",
    "try:\n",
    "    fitted_model = mlflow.pyfunc.load_model(\"runs:/{}/outputs\".format(mlflow_best_child_run.info.run_id))\n",
    "except Exception as e:\n",
    "    # TODO: This is probably due to a bug, where MLFlow models are not being generated despite 'save_mlflow'\n",
    "    print(str(e))\n",
    "    print(\"Failed to load MLFlow model, downloading artifacts manually and loading the model.\")\n",
    "    \n",
    "    import os, pickle\n",
    "\n",
    "    local_dir = \"/tmp/artifact_downloads/{}\".format(mlflow_best_child_run.info.run_id)\n",
    "    if not os.path.exists(local_dir):\n",
    "        os.mkdir(local_dir)\n",
    "\n",
    "    local_path = mlflow_client.download_artifacts(mlflow_best_child_run.info.run_id, \"outputs\", local_dir)\n",
    "    print(\"Artifacts downloaded in: {}\".format(local_path))\n",
    "    print(\"Artifacts: {}\".format(os.listdir(local_path)))\n",
    "    \n",
    "    pickled_model_path = \"{}/model.pkl\".format(local_path)\n",
    "    with open(pickled_model_path, \"rb\") as model_file:\n",
    "        fitted_model = pickle.load(model_file)\n",
    "\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor: \n",
      "('MaxAbsScaler', MaxAbsScaler(copy=True))\n",
      "\n",
      "Estimator: \n",
      " ('XGBoostClassifier', XGBoostClassifier(\n",
      "    random_state=0,\n",
      "    n_jobs=-1,\n",
      "    problem_info=None\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "# Print more information about the winning model\n",
    "print(\"Preprocessor: \\n{}\\n\".format(fitted_model.steps[1]))\n",
    "print(\"Estimator: \\n\", fitted_model.steps[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve METRICS for All Child Runs\n",
    "You can also use SDK methods to fetch all the child runs and see individual metrics that we log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "gather": {
     "logged": 1616706367305
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_score_micro</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_macro_recall</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_weighted</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_weighted</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_micro</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_macro</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_weighted</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matthews_correlation</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_micro</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_macro</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_macro</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_weighted</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_weighted</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_macro</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_micro</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_accuracy</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_micro</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_macro</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0    1    2    3\n",
       "f1_score_micro                   0.96 0.96 0.96 0.96\n",
       "norm_macro_recall                0.00 0.00 0.00 0.00\n",
       "AUC_weighted                     0.57 0.62 0.62 0.62\n",
       "precision_score_weighted         0.93 0.93 0.93 0.93\n",
       "accuracy                         0.96 0.96 0.96 0.96\n",
       "AUC_micro                        0.97 0.97 0.97 0.97\n",
       "AUC_macro                        0.57 0.62 0.62 0.62\n",
       "recall_score_weighted            0.96 0.96 0.96 0.96\n",
       "matthews_correlation             0.00 0.00 0.00 0.00\n",
       "recall_score_micro               0.96 0.96 0.96 0.96\n",
       "average_precision_score_macro    0.51 0.51 0.51 0.51\n",
       "log_loss                         0.16 0.15 0.15 0.16\n",
       "precision_score_macro            0.48 0.48 0.48 0.48\n",
       "f1_score_weighted                0.95 0.95 0.95 0.95\n",
       "average_precision_score_weighted 0.94 0.94 0.94 0.94\n",
       "f1_score_macro                   0.49 0.49 0.49 0.49\n",
       "precision_score_micro            0.96 0.96 0.96 0.96\n",
       "balanced_accuracy                0.50 0.50 0.50 0.50\n",
       "weighted_accuracy                1.00 1.00 1.00 1.00\n",
       "average_precision_score_micro    0.96 0.97 0.97 0.97\n",
       "recall_score_macro               0.50 0.50 0.50 0.50"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_iter_metrics = dict()\n",
    "\n",
    "# max_trials is = 4, so gather metrics for the 4 child iterations\n",
    "for i in range(4):\n",
    "    # Construct child run id\n",
    "    child_run_id = mlflow_parent_run.info.run_id + \"_{}\".format(i)\n",
    "    \n",
    "    # parse metrics for this iteration\n",
    "    metrics = mlflow_client.get_run(child_run_id).data.metrics\n",
    "    \n",
    "    # index by iteration\n",
    "    all_iter_metrics[i] = metrics\n",
    "\n",
    "rundata = pd.DataFrame(all_iter_metrics).sort_index(1)\n",
    "rundata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Best Model's explanation\n",
    "Retrieve the explanation from the best_run which includes explanations for engineered features and raw features. Make sure that the run for generating explanations for the best model is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "gather": {
     "logged": 1616706385527
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status:  FINISHED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={}, params={}, tags={'_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":1,\"CurrentNodeCount\":1}',\n",
       " 'mlflow.parentRunId': '05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_1',\n",
       " 'mlflow.source.name': 'model_explain.py',\n",
       " 'mlflow.source.type': 'JOB'}>, info=<RunInfo: artifact_uri='azureml://experiments/3-automl-remote-compute-run/runs/05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_ModelExplain/artifacts', end_time=1621298404352, experiment_id='71434ea8-978c-473a-a449-88f3bfd5bbc4', lifecycle_stage='active', run_id='05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_ModelExplain', run_uuid='05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_ModelExplain', start_time=1621298301196, status='FINISHED', user_id='d0b038bb-162b-4d49-b8fe-5786e199f6fb'>>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_explain_run_id = mlflow_best_child_run.data.tags[\"model_explain_run_id\"]\n",
    "\n",
    "# Wait for the best model explanation run to complete\n",
    "status = \"\"\n",
    "while True:\n",
    "    mlflow_model_explain_run = mlflow_client.get_run(model_explain_run_id)\n",
    "    status = mlflow_model_explain_run.info.status\n",
    "    print(\"Current Status: \", status)\n",
    "    if status == \"FINISHED\":\n",
    "        break\n",
    "    time.sleep(10)\n",
    "\n",
    "mlflow_model_explain_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Print engineered feature importance from artifact store\n",
    "You can use ExplanationClient to download the engineered feature explanations from the artifact store of the best_run.\n",
    "> **Note**: \\\n",
    "  This wouldn't work. It would likely require changes in ExplanationClient to accept non-v1 structures in its initialization, similar to ModelProxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616706396159
    }
   },
   "outputs": [],
   "source": [
    "# from azureml.interpret import ExplanationClient\n",
    "\n",
    "# client = ExplanationClient.from_run(best_run)\n",
    "# engineered_explanations = client.download_model_explanation(raw=False)\n",
    "# exp_data = engineered_explanations.get_feature_importance_dict()\n",
    "# exp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download raw feature importance from artifact store\n",
    "You can use ExplanationClient to download the raw feature explanations from the artifact store of the best_run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616706409898
    }
   },
   "outputs": [],
   "source": [
    "# client = ExplanationClient.from_run(best_run)\n",
    "# engineered_explanations = client.download_model_explanation(raw=True)\n",
    "# exp_data = engineered_explanations.get_feature_importance_dict()\n",
    "# exp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model in Workspace model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616706422992
    }
   },
   "outputs": [],
   "source": [
    "# Ensure that the model exists locally\n",
    "output_path = download_outputs_via_mlflow_client(mlflow_client, mlflow_best_child_run.info.run_id, \"outputs\")\n",
    "\n",
    "# Create (register?) the model\n",
    "azure_model = Model(name=\"porto-seg-automl-remote-compute\", version=1, local_path=os.path.join(output_path, \"model.pkl\"))\n",
    "azure_model = client.models.create_or_update(azure_model)\n",
    "\n",
    "\n",
    "registered_model = parent_run.register_model(model_name='porto-seg-automl-remote-compute', \n",
    "                                           description='Porto Seguro Model from plain AutoML in remote AML compute')\n",
    "\n",
    "print(parent_run.model_id)\n",
    "registered_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference File:  /tmp/artifact_downloads/05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_1/outputs/scoring_file_v_1_0_0.py\n",
      "Conda Environment File:  /tmp/artifact_downloads/05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_1/outputs/conda.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading scoring_file_v_1_0_0.py: 100%|| 1/1 [00:00<00:00,  7.19it/s]\n",
      "\n",
      "The deployment request gasi_ws_neu-endpoint-05bb01e9-5759945 was accepted,  status can be found in the link below: \n",
      "https://ms.portal.azure.com/#blade/HubsExtension/DeploymentDetailsBlade/overview/id/%2Fsubscriptions%2F381b38e9-9840-4719-a5a0-61d9585e1e91%2FresourceGroups%2Fgasi_rg_neu%2Fproviders%2FMicrosoft.Resources%2Fdeployments%2Fgasi_ws_neu-endpoint-05bb01e9-5759945\n",
      "\n",
      "Registering environment version (environment-05bb01e9:1)  Done (4s)\n",
      "Creating endpoint endpoint-05bb01e9 ..  Done (30s)\n",
      "Polling hit the exception (DeploymentFailed) At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment failed:  (DeploymentFailed) At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/azure/core/polling/base_polling.py\", line 482, in run\n",
      "    self._poll()\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/azure/core/polling/base_polling.py\", line 521, in _poll\n",
      "    raise OperationFailed(\"Operation failed or canceled\")\n",
      "azure.core.polling.base_polling.OperationFailed: Operation failed or canceled\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-233-6864668628da>\", line 57, in <module>\n",
      "    client.endpoints.create(online_endpoint)\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_operations/endpoint_operations.py\", line 211, in create\n",
      "    return self._create_online_endpoint(internal_endpoint=endpoint, no_wait=no_wait)\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_operations/endpoint_operations.py\", line 608, in _create_online_endpoint\n",
      "    template=template, resources_being_deployed=resources_being_deployed, wait=not no_wait\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_arm_deployments/arm_deployment_executor.py\", line 85, in deploy_resource\n",
      "    raise ex\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_arm_deployments/arm_deployment_executor.py\", line 81, in deploy_resource\n",
      "    total_duration = poller.result().properties.duration\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/azure/core/polling/_poller.py\", line 255, in result\n",
      "    self.wait(timeout)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/azure/core/tracing/decorator.py\", line 83, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/azure/core/polling/_poller.py\", line 275, in wait\n",
      "    raise self._exception # type: ignore\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/azure/core/polling/_poller.py\", line 192, in _start\n",
      "    self._polling_method.run()\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/azure/core/polling/base_polling.py\", line 502, in run\n",
      "    error=err\n",
      "azure.core.exceptions.HttpResponseError: (DeploymentFailed) At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.\n"
     ]
    }
   ],
   "source": [
    "from azure.ml.entities import Endpoint, ManagedOnlineEndpoint, Environment, \\\n",
    "CodeConfiguration, ManagedOnlineDeployment, ManualScaleSettings, Code\n",
    "\n",
    "inference_script_file_name = os.path.join(output_path, \"scoring_file_v_1_0_0.py\")\n",
    "conda_environment_yaml = os.path.join(output_path, \"conda.yaml\")\n",
    "\n",
    "print(\"Inference File: \", inference_script_file_name)\n",
    "print(\"Conda Environment File: \", conda_environment_yaml)\n",
    "\n",
    "assert os.path.exists(inference_script_file_name)\n",
    "assert os.path.exists(conda_environment_yaml)\n",
    "\n",
    "\n",
    "# Prepare the deployment configuration\n",
    "environment = Environment(\n",
    "    name=\"environment-{}\".format(mlflow_best_child_run.info.run_id[:8]),\n",
    "    version=1,\n",
    "    path=\".\",\n",
    "    conda_file=conda_environment_yaml,\n",
    "    docker_image=\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1\",\n",
    ")\n",
    "\n",
    "code = Code(\n",
    "    name=\"environment-{}\".format(mlflow_best_child_run.info.run_id[:8]),\n",
    "    version=1,\n",
    "    local_path=inference_script_file_name,\n",
    ")\n",
    "code_configuration = CodeConfiguration(\n",
    "    code=code,\n",
    "    scoring_script=inference_script_file_name\n",
    ")\n",
    "\n",
    "scale_settings = ManualScaleSettings(\n",
    "    scale_type=\"Manual\",\n",
    "    min_instances=1,\n",
    "    max_instances=2,\n",
    "    instance_count=1\n",
    ")\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"deployment-{}\".format(mlflow_best_child_run.info.run_id[:8]),\n",
    "    model=registered_model,\n",
    "    environment=environment,\n",
    "    code_configuration=code_configuration,\n",
    "    instance_type=\"Standard_F2s_v2\",\n",
    "    scale_settings=scale_settings,\n",
    "                                    )\n",
    "online_endpoint = ManagedOnlineEndpoint(\n",
    "    name=\"endpoint-{}\".format(mlflow_best_child_run.info.run_id[:8]),\n",
    "    deployments=[deployment],\n",
    "    description=\"Demo model deployment\",\n",
    "    tags={\"deployed_using\": \"sdkv2\"}\n",
    ")\n",
    "##### Loading from YAML\n",
    "# endpoint = Endpoint.load(\"/home/schrodinger/automl/Easy-AutoML-MLOps/notebooks/3-automl-remote-compute-run/endpoint.yml\")\n",
    "\n",
    "try:\n",
    "    client.endpoints.create(online_endpoint)\n",
    "except Exception as e:\n",
    "    print(\"Deployment failed: \", str(e))\n",
    "    traceback.print_exc()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See files associated with the 'Best run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories:  {'azureml-logs', 'logs', 'explanation', 'outputs'}\n",
      "Files:  {'confusion_matrix', 'automl_driver.py', 'accuracy_table'}\n"
     ]
    }
   ],
   "source": [
    "artifacts = mlflow_client.list_artifacts(mlflow_best_child_run.info.run_id)\n",
    "\n",
    "directories = []\n",
    "files = []\n",
    "for artifact in artifacts:\n",
    "    if artifact.is_dir:\n",
    "        directories.append(artifact)\n",
    "    else:\n",
    "        # File\n",
    "        files.append(artifact)\n",
    "\n",
    "print(\"Directories: \", set([d.path for d in directories]))\n",
    "print(\"Files: \", set([f.path for f in files]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions and calculate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Test Data: \n",
    "Generating data in-line (can also load a local test file as pandas dataframe). Tabular Datasets are missing, so can't capture a pandas dataframe object for local predictions, nor there is test run support on SDKv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "gather": {
     "logged": 1616706439070
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test shape:  (2,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "0 20.00       2.00           1.00       3.00           1.00           0.00   \n",
       "1 20.00       2.00           1.00       3.00           1.00           0.00   \n",
       "\n",
       "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ...  \\\n",
       "0           0.00           1.00           0.00           0.00  ...   \n",
       "1           0.00           1.00           0.00           0.00  ...   \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0        3.00        0.00        0.00       10.00            0.00   \n",
       "1        3.00        0.00        0.00       10.00            0.00   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0            1.00            0.00            0.00            1.00   \n",
       "1            1.00            0.00            0.00            1.00   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0            0.00  \n",
       "1            0.00  \n",
       "\n",
       "[2 rows x 58 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Duplicating the same row twice\n",
    "raw_data = json.dumps({\n",
    "     'data': [\n",
    "         [20,2,1,3,1,0,0,1,0,0,0,0,0,0,0,8,1,0,0,0.6,0.1,0.61745445,6,1,-1,0,1,11,1,1,0,1,99,2,0.31622777,0.6396829,0.36878178,3.16227766,0.2,0.6,0.5,2,2,8,1,8,3,10,3,0,0,10,0,1,0,0,1,0, 0],\n",
    "         [20,2,1,3,1,0,0,1,0,0,0,0,0,0,0,8,1,0,0,0.6,0.1,0.61745445,6,1,-1,0,1,11,1,1,0,1,99,2,0.31622777,0.6396829,0.36878178,3.16227766,0.2,0.6,0.5,2,2,8,1,8,3,10,3,0,0,10,0,1,0,0,1,0, 1]\n",
    "     ],\n",
    "     'method': 'predict'  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    " })\n",
    "\n",
    "numpy_data = np.array(json.loads(raw_data)['data'])\n",
    "\n",
    "df_data = pd.DataFrame(data=numpy_data, columns=['id', 'ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n",
    "                                               'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n",
    "                                               'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin',\n",
    "                                               'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n",
    "                                               'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n",
    "                                               'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n",
    "                                               'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n",
    "                                               'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n",
    "                                               'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n",
    "                                               'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n",
    "                                               'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n",
    "                                               'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n",
    "                                               'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n",
    "                                               'ps_calc_20_bin', 'target'])\n",
    "y_test = df_data.pop('target')\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions in bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "gather": {
     "logged": 1616706457554
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# Try the best model making predictions with the test dataset\n",
    "y_predictions = fitted_model.predict(df_data)\n",
    "\n",
    "print(y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the predictions' probabilities needed to calculate ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some class probabilities...: \n",
      "[[0.9700505  0.02994949]\n",
      " [0.9700505  0.02994949]]\n"
     ]
    }
   ],
   "source": [
    "class_probabilities = fitted_model.predict_proba(df_data)\n",
    "\n",
    "print('Some class probabilities...: ')\n",
    "print(class_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "Evaluating performance is an essential task in machine learning. In this case, because this is a classification problem, the data scientist elected to use an AUC - ROC Curve. When we need to check or visualize the performance of the multi - class classification problem, we use AUC (Area Under The Curve) ROC (Receiver Operating Characteristics) curve. It is one of the most important evaluation metrics for checking any classification models performance.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Oxana_Trifonova/publication/276079439/figure/fig2/AS:614187332034565@1523445079168/An-example-of-ROC-curves-with-good-AUC-09-and-satisfactory-AUC-065-parameters.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 12px; width: 320px; height: 239px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the ROC AUC with probabilities vs. the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC *method 1*:\n",
      "0.5\n",
      "ROC AUC Weighted:\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Not enough test data, but no changes here\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#roc_auc_score(y, clf.predict_proba(X)[:, 1])\n",
    "#roc_auc_score(y, clf.decision_function(X))\n",
    "\n",
    "print('ROC AUC *method 1*:')\n",
    "print(roc_auc_score(y_test, class_probabilities[:,1]))\n",
    "\n",
    "print('ROC AUC Weighted:')\n",
    "print(roc_auc_score(y_test, class_probabilities[:,1], average='weighted'))\n",
    "# AUC with plain LightGBM was: 0.6374553321494826 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Accuracy with predictions vs. the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 58)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "print(df_data.shape)\n",
    "print(y_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, y_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Option A: Load from model .pkl file)\n",
    "\n",
    "This is demonstrated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Option B: Load from model registry in Workspace)\n",
    "\n",
    "#### Using SDK v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /tmp/artifact_downloads/05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_1/outputs already exists. Skipping download.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model({'is_anonymous': False, 'name': 'porto-seg-automl-remote-compute', 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_neu/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_neu/models/porto-seg-automl-remote-compute/versions/1', 'description': None, 'tags': {}, 'properties': {}, 'base_path': './', 'creation_context': <azure.ml._restclient._2021_03_01_preview.machinelearningservices.models._models_py3.SystemData object at 0x7f13c5bcd250>, 'version': 1, 'datastore': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_neu/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_neu/datastores/workspaceblobstore', 'path': 'az-ml-artifacts/2f589510f11c75fc407a9f68ca9408cd/model.pkl', 'local_path': None, 'utc_time_created': None, 'flavors': {}})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ml.entities.assets import Model\n",
    "\n",
    "# Retrieve the registered model by name.\n",
    "registered_model = client.models.get(azure_model.name, azure_model.version)\n",
    "registered_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RegisteredModel: creation_timestamp=1621384876543, description='', last_updated_timestamp=1621384876543, latest_versions=[], name='porto-seg-mlflow_05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_1', tags={}>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the registered model by name using MLFlow client\n",
    "registered_model = next(filter(lambda model: model.name == model_name, mlflow_client.list_registered_models()))\n",
    "# print(\"name={}; run_id={}; version={}\".format(registered_model.name, registered_model.run_id, registered_model.version))\n",
    "registered_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml-models/porto-seg-automl-remote-compute/1/model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load model from model registry in Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "model_path = Model.get_model_path('porto-seg-automl-remote-compute', _workspace=ws)\n",
    "print(model_path)\n",
    "# fitted_model = joblib.load(model_path)\n",
    "# print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try model inference with hardcoded input data for the model to predict\n",
    "\n",
    "This is demonstrated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Best ONNX Model\n",
    "Below we select the best pipeline from our iterations. The get_output method returns the best run and the fitted model. The Model includes the pipeline and any pre-processing. Overloads on get_output allow you to retrieve the best run and fitted model for any logged metric or for a particular iteration.\n",
    "\n",
    "Set the parameter return_onnx_model=True to retrieve the best ONNX model, instead of the Python model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This should be similar to above, although not sure why ONNX models are not being generated at the moment.\n",
    "#       (Same class of bug as MLflow models not being saved?)\n",
    "\n",
    "best_run, onnx_mdl = parent_run.get_output(return_onnx_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best ONNX model to local path\n",
    "#### Predict with the ONNX model, using onnxruntime package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /tmp/artifact_downloads/05bb01e9-a479-48ba-a0e3-3bcd868dbcd7_1/outputs already exists. Skipping download.\n",
      "[0 0]\n",
      "[[0.9730727  0.02692736]\n",
      " [0.9730727  0.02692736]]\n"
     ]
    }
   ],
   "source": [
    "def get_onnx_res(onnx_resource_json_path):\n",
    "    with open(onnx_resource_json_path) as f:\n",
    "        onnx_res = json.load(f)\n",
    "    return onnx_res\n",
    "\n",
    "\n",
    "output_path = download_outputs_via_mlflow_client(mlflow_client, mlflow_best_child_run.info.run_id, \"outputs\")\n",
    "\n",
    "onnx_model_path = os.path.join(local_dir, \"outputs\", \"model.onnx\")\n",
    "\n",
    "# Loading an ONNX model with MLFlow can be done via.the following, however, we currently don't save the flavor\n",
    "# information in the MLModel file.\n",
    "# mlflow.onnx.load_model(onnx_model_path)\n",
    "\n",
    "# Loading via. OnnxConverter\n",
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "from azureml.automl.runtime.onnx_convert import OnnxInferenceHelper\n",
    "\n",
    "onnx_resource_json_path = os.path.join(local_dir, \"outputs\", \"model_onnx.json\")\n",
    "fitted_onnx_model = OnnxConverter.load_onnx_model(onnx_model_path)\n",
    "\n",
    "mdl_bytes = fitted_onnx_model.SerializeToString()\n",
    "onnx_res = get_onnx_res(onnx_resource_json_path)\n",
    "\n",
    "onnxrt_helper = OnnxInferenceHelper(mdl_bytes, onnx_res)\n",
    "pred_onnx, pred_prob_onnx = onnxrt_helper.predict(df_data)\n",
    "\n",
    "print(pred_onnx)\n",
    "print(pred_prob_onnx)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python [conda env:devmar] *",
   "language": "python",
   "name": "conda-env-devmar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
