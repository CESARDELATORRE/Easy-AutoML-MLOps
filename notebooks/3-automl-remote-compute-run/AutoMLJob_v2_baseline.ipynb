{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Experiment using SDK V2\n",
    "\n",
    "Make sure SDK v2 is installed, via. the documentation in this [README.md](https://msdata.visualstudio.com/Vienna/_git/sdk-cli-v2?path=%2FREADME.md&_a=preview).\n",
    "\n",
    "Also ensure that the above installation is done in a conda environment where AutoML SDK v1 is already installed. You may also need to install MLFlow to do some operations. (e.g. via. `pip install azureml-mlflow`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility methods\n",
    "\n",
    "# Currently, there's no SDK v2 equivalent of v1's 'show_output' or 'wait_for_completion' functionality, \n",
    "# that prints the AutoML iteration info\n",
    "\n",
    "def show_output(client, job) -> None:    \n",
    "    # This doesn't appear to stream anything at the moment\n",
    "    client.jobs.stream(created_job.name)\n",
    "\n",
    "\n",
    "def wait_for_completion(client, job, poll_duration: int = 30) -> None:    \n",
    "    \"\"\"Poll for job status every `poll_duration` seconds, until it is terminated\"\"\"\n",
    "    import time\n",
    "    from azure.ml._operations.run_history_constants import RunHistoryConstants\n",
    "\n",
    "    cur_status = client.jobs.get(job.name).status\n",
    "    print(\"Current job status: \", cur_status)\n",
    "    while cur_status not in RunHistoryConstants.TERMINAL_STATUSES:\n",
    "        time.sleep(poll_duration)\n",
    "        cur_status = client.jobs.get(job.name).status\n",
    "        print(\"Current job status: \", cur_status)\n",
    "\n",
    "\n",
    "def download_outputs(client, job) -> None:\n",
    "    # This does not download any logs (no models as well, since this is at the parent run level)\n",
    "    client.jobs.download(job.name, download_path=\"./outputs\")\n",
    "\n",
    "    # For the child run level, currently this throws an exception saying it's not supported for the job type\n",
    "    try:\n",
    "        first_child_run = \"{}_0\".format(job.name)\n",
    "        client.jobs.download(first_child_run, download_path=\"./outputs/\")\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "\n",
    "        print(str(e))\n",
    "        traceback.print_exc()\n",
    "        \n",
    "\n",
    "def print_studio_url(job, open_in_new_tab: bool = False) -> None:\n",
    "    # TODO: Any easier way to get the URL?\n",
    "    \n",
    "    print(\"Studio URL: \", job.interaction_endpoints['Studio'].endpoint)\n",
    "    if open_in_new_tab:\n",
    "        import webbrowser\n",
    "        webbrowser.open(job.interaction_endpoints['Studio'].endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global imports\n",
    "from azure.ml import MLClient\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "\n",
    "from azure.ml.entities.workspace.workspace import Workspace\n",
    "from azure.ml.entities.compute.compute import Compute\n",
    "from azure.ml.entities.assets import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = '381b38e9-9840-4719-a5a0-61d9585e1e91'\n",
    "resource_group_name = 'gasi_rg_neu'\n",
    "workspace_name = 'gasi_ws_neu'\n",
    "\n",
    "experiment_name = \"3-automl-remote-compute-run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MLClient\n",
    "# A resource group must already be existing at this point\n",
    "\n",
    "client = MLClient(subscription_id, resource_group_name) # default_workspace_name=workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace with name gasi_ws_neu already exists.\n"
     ]
    }
   ],
   "source": [
    "# Set the default workspace for the Client, creating one if it doesn't exist.\n",
    "\n",
    "workspace = Workspace(name=workspace_name)\n",
    "\n",
    "try:\n",
    "    client.workspaces.create(workspace)\n",
    "except ResourceExistsError as re:\n",
    "    print(re)\n",
    "    \n",
    "client.default_workspace_name = workspace_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not create compute. Cannot deserialize duration object., ISO8601Error: Unable to parse duration string ''\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1872, in deserialize_duration\n",
      "    duration = isodate.parse_duration(attr)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/isodate/isoduration.py\", line 104, in parse_duration\n",
      "    raise ISO8601Error(\"Unable to parse duration string %r\" % datestring)\n",
      "isodate.isoerror.ISO8601Error: Unable to parse duration string ''\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-6-5ddad0ec168a>\", line 14, in <module>\n",
      "    client.compute.create(compute)\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_operations/compute_operations.py\", line 98, in create\n",
      "    polling=not no_wait,\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_restclient/_2021_03_01_preview/machinelearningservices/operations/_machine_learning_compute_operations.py\", line 304, in begin_create_or_update\n",
      "    **kwargs\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_restclient/_2021_03_01_preview/machinelearningservices/operations/_machine_learning_compute_operations.py\", line 251, in _create_or_update_initial\n",
      "    deserialized = self._deserialize('ComputeResource', pipeline_response)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1368, in __call__\n",
      "    return self._deserialize(target_obj, data)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1442, in _deserialize\n",
      "    value = self.deserialize_data(raw_value, attr_desc['type'])\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1631, in deserialize_data\n",
      "    return self._deserialize(obj_type, data)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1442, in _deserialize\n",
      "    value = self.deserialize_data(raw_value, attr_desc['type'])\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1631, in deserialize_data\n",
      "    return self._deserialize(obj_type, data)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1442, in _deserialize\n",
      "    value = self.deserialize_data(raw_value, attr_desc['type'])\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1631, in deserialize_data\n",
      "    return self._deserialize(obj_type, data)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1442, in _deserialize\n",
      "    value = self.deserialize_data(raw_value, attr_desc['type'])\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1613, in deserialize_data\n",
      "    data_val = self.deserialize_type[data_type](data)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1875, in deserialize_duration\n",
      "    raise_with_traceback(DeserializationError, msg, err)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/exceptions.py\", line 51, in raise_with_traceback\n",
      "    raise error.with_traceback(exc_traceback)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/msrest/serialization.py\", line 1872, in deserialize_duration\n",
      "    duration = isodate.parse_duration(attr)\n",
      "  File \"/home/schrodinger/anaconda3/envs/devmar/lib/python3.7/site-packages/isodate/isoduration.py\", line 104, in parse_duration\n",
      "    raise ISO8601Error(\"Unable to parse duration string %r\" % datestring)\n",
      "msrest.exceptions.DeserializationError: Cannot deserialize duration object., ISO8601Error: Unable to parse duration string ''\n"
     ]
    }
   ],
   "source": [
    "# Set or create compute\n",
    "\n",
    "cpu_cluster_name = \"cpucluster\"\n",
    "compute = Compute(\"amlcompute\",\n",
    "                  name=cpu_cluster_name, size=\"STANDARD_D2_V2\",\n",
    "                  min_instances=0, max_instances=3,\n",
    "                  idle_time_before_scale_down=120)\n",
    "\n",
    "# Load directly from YAML file\n",
    "# compute = Compute.load(\"./compute.yaml\")\n",
    "\n",
    "try:\n",
    "    # TODO: This currently results in an exception in Azure ML, please create compute manually.\n",
    "    client.compute.create(compute)\n",
    "except ResourceExistsError as re:\n",
    "    print(re)\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    \n",
    "    print(\"Could not create compute.\", str(e))\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not create dataset.  (UserError) A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's Path, Properties cannot be changed. Only tags and description can be updated.\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset\n",
    "\n",
    "dataset_name = \"train_dataset_beer\"\n",
    "training_data = Data(name=dataset_name, version=1, local_path=\"./data\")\n",
    "\n",
    "# Load directly from YAML file\n",
    "# training_data = Data.load(\"./data.yaml\")\n",
    "\n",
    "try:\n",
    "    data = client.data.create_or_update(training_data)\n",
    "    print(\"Uploaded to path  : \", data.path)\n",
    "    print(\"Datastore location: \", data.datastore)\n",
    "except Exception as e:\n",
    "    print(\"Could not create dataset. \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment_id: e76232b5-3215-43ad-8c33-54089e072777\n",
      "Artifact Location: \n",
      "Tags: {}\n",
      "Lifecycle_stage: active\n",
      "\n",
      "Registry URI:         azureml://northeurope.experiments.azureml.net/mlflow/v1.0/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_neu/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_neu?\n",
      "\n",
      "Current tracking uri: azureml://northeurope.experiments.azureml.net/mlflow/v1.0/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_neu/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_neu?\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLFlow, setting the tracking URI to AzureML, and changing the active experiment\n",
    "\n",
    "import mlflow\n",
    "\n",
    "##### NOTE: This is SDK v1 API #####\n",
    "# TODO: How do we get this from MLClient? Tracking URI can't be obtained from v2 Workspace object\n",
    "from azureml.core import Workspace as WorkspaceV1\n",
    "ws = WorkspaceV1(workspace_name=workspace_name, resource_group=resource_group_name, subscription_id=subscription_id)\n",
    "####################################\n",
    "\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "\n",
    "# Set the active experiment, creating one if it doesn't exist\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Get Experiment Details\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "\n",
    "print(\"\\nRegistry URI:         {}\".format(mlflow.get_registry_uri()))\n",
    "print(\"\\nCurrent tracking uri: {}\".format(mlflow.get_tracking_uri()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoMLJob({'name': '598fcd86-f7e8-4379-ae7b-4e7f1a1a566e', 'id': None, 'description': None, 'tags': {}, 'properties': {'save_mlflow': True}, 'base_path': './', 'type': 'automl_job', 'creation_context': None, 'experiment_name': '3-automl-remote-compute-run', 'status': None, 'interaction_endpoints': None, 'log_files': None, 'output': None, 'general_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.GeneralSettings object at 0x7fbef25178d0>, 'data_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.DataSettings object at 0x7fbef25179d0>, 'limit_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.LimitSettings object at 0x7fbef2517a50>, 'forecasting_settings': <azure.ml.entities.job.automl.forecasting.ForecastingSettings object at 0x7fbef2517b10>, 'training_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.TrainingSettings object at 0x7fbef2517a90>, 'featurization_settings': <azure.ml.entities.job.automl.featurization.FeaturizationSettings object at 0x7fbef2517ad0>, 'compute': <azure.ml._schema.compute_binding.InternalComputeConfiguration object at 0x7fbef2517910>})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ml._restclient._2020_09_01_preview.machinelearningservices.models import GeneralSettings, LimitSettings, DataSettings, TrainingDataSettings, ValidationDataSettings, TrainingSettings\n",
    "from azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._azure_machine_learning_workspaces_enums import TaskType, OptimizationMetric\n",
    "from azure.ml._schema.compute_binding import InternalComputeConfiguration\n",
    "from azure.ml.entities import AutoMLJob\n",
    "from azure.ml.entities.job.automl.forecasting import ForecastingSettings\n",
    "from azure.ml.entities.job.automl.featurization import FeaturizationSettings\n",
    "\n",
    "compute = InternalComputeConfiguration(target=cpu_cluster_name)\n",
    "\n",
    "general_settings = GeneralSettings(task_type=TaskType.FORECASTING,\n",
    "                                   primary_metric= OptimizationMetric.NORMALIZED_ROOT_MEAN_SQUARED_ERROR,\n",
    "                                   enable_model_explainability=True)\n",
    "\n",
    "# TODO: Seems like a bug here, max_trials=3 + max_concurrent_trials=4 seems to only trigger one child run\n",
    "limit_settings = LimitSettings(job_timeout=60,\n",
    "                               max_trials=4,\n",
    "                               max_concurrent_trials=4,\n",
    "                               enable_early_termination=False)\n",
    "\n",
    "# TODO: How can we reuse the 'data' object created above?\n",
    "training_data_settings = TrainingDataSettings(dataset_arm_id=\"train_dataset_beer:1\",\n",
    "                                              target_column_name=\"BeerProduction\")\n",
    "validation_data_settings = ValidationDataSettings(n_cross_validations=5)\n",
    "data_settings = DataSettings(training_data=training_data_settings, validation_data=validation_data_settings)\n",
    "\n",
    "featurization_settings = FeaturizationSettings(featurization_config=\"auto\")\n",
    "\n",
    "training_settings = TrainingSettings(enable_dnn_training=False)\n",
    "\n",
    "forecasting_settings = ForecastingSettings(country_or_region_for_holidays=\"US\",\n",
    "                                           forecast_horizon=12,\n",
    "                                           target_rolling_window_size=0,\n",
    "                                           time_column_name=\"DATE\")\n",
    "\n",
    "### get unique job name for repeated trials ###\n",
    "### This can be skipped, in which case a random guid is generated for the job name\n",
    "import time\n",
    "job_name = \"simplebeerjob{}\".format(str(int(time.time())))\n",
    "################################################\n",
    "\n",
    "extra_automl_settings = {\"save_mlflow\": True}\n",
    "\n",
    "automl_job = AutoMLJob(\n",
    "#     name=job_name,\n",
    "    compute=compute,\n",
    "    general_settings=general_settings,\n",
    "    limit_settings=limit_settings,\n",
    "    data_settings=data_settings,\n",
    "    forecasting_settings=forecasting_settings,\n",
    "    training_settings=training_settings,\n",
    "    featurization_settings=featurization_settings,\n",
    "    properties=extra_automl_settings,\n",
    ")\n",
    "\n",
    "######## For loading directly from YAML ########\n",
    "# from pathlib import Path\n",
    "# from azure.ml.entities import Job, AutoMLJob\n",
    "\n",
    "# job_path_yaml = Path(\"./automl_beer_job.yml\") \n",
    "# automl_job = Job.load(job_path_yaml)\n",
    "\n",
    "automl_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoMLJob({'name': '598fcd86-f7e8-4379-ae7b-4e7f1a1a566e', 'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/gasi_rg_neu/providers/Microsoft.MachineLearningServices/workspaces/gasi_ws_neu/jobs/598fcd86-f7e8-4379-ae7b-4e7f1a1a566e', 'description': None, 'tags': {}, 'properties': {'save_mlflow': 'True'}, 'base_path': './', 'type': 'automl_job', 'creation_context': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.SystemData object at 0x7fbef25a3b90>, 'experiment_name': '3-automl-remote-compute-run', 'status': 'NotStarted', 'interaction_endpoints': {'Tracking': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.JobEndpoint object at 0x7fbef25a3150>, 'Studio': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.JobEndpoint object at 0x7fbef25a3b10>}, 'log_files': None, 'output': None, 'general_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.GeneralSettings object at 0x7fbef25a3c90>, 'data_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.DataSettings object at 0x7fbef25a3710>, 'limit_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.LimitSettings object at 0x7fbef25a3f50>, 'forecasting_settings': <azure.ml.entities.job.automl.forecasting.ForecastingSettings object at 0x7fbf36599510>, 'training_settings': <azure.ml._restclient._2020_09_01_preview.machinelearningservices.models._models_py3.TrainingSettings object at 0x7fbef25a3450>, 'featurization_settings': <azure.ml.entities.job.automl.featurization.FeaturizationSettings object at 0x7fbf18fae490>, 'compute': <azure.ml._schema.compute_binding.InternalComputeConfiguration object at 0x7fbef53d3d90>})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit job\n",
    "# TODO: There appears to be a bug here (repro: try executing this cell twice)\n",
    "created_job = client.jobs.create_or_update(automl_job)\n",
    "created_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studio URL:  https://ml.azure.com/runs/598fcd86-f7e8-4379-ae7b-4e7f1a1a566e?wsid=/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/gasi_rg_neu/workspaces/gasi_ws_neu&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "Current job status:  NotStarted\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Running\n",
      "Current job status:  Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading the job logs ExperimentRun/dcid.598fcd86-f7e8-4379-ae7b-4e7f1a1a566e/ at ./outputs/598fcd86-f7e8-4379-ae7b-4e7f1a1a566e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(UserError) A job was found, but it is not supported in this API version and cannot be accessed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-19-4fa2dbf6b888>\", line 31, in download_outputs\n",
      "    client.jobs.download(first_child_run, download_path=\"./outputs/\")\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_operations/job_operations.py\", line 246, in download\n",
      "    job_details = self.get(name)\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_operations/job_operations.py\", line 101, in get\n",
      "    job_object = self._get_job(name)\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_operations/job_operations.py\", line 285, in _get_job\n",
      "    **self._kwargs,\n",
      "  File \"/home/schrodinger/automl/sdk-cli-v2/src/azure-ml/azure/ml/_restclient/_2020_09_01_preview/machinelearningservices/operations/_jobs_operations.py\", line 196, in get\n",
      "    raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)\n",
      "azure.core.exceptions.HttpResponseError: (UserError) A job was found, but it is not supported in this API version and cannot be accessed.\n"
     ]
    }
   ],
   "source": [
    "# Get Studio URL, open in new tab\n",
    "print_studio_url(created_job)\n",
    "\n",
    "# Wait until the job is finished\n",
    "wait_for_completion(client, created_job)\n",
    "\n",
    "# Download logs + outputs locally\n",
    "download_outputs(client, created_job)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code below currently doens't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Experiment: artifact_location='', experiment_id='e76232b5-3215-43ad-8c33-54089e072777', lifecycle_stage='active', name='beerproduction', tags={}>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<RegisteredModel: creation_timestamp=1616452676112, description='', last_updated_timestamp=1616452676112, latest_versions=[], name='AutoMLfe4299a1632', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1616452682701, description='', last_updated_timestamp=1616452682701, latest_versions=[], name='AutoML8342bc81c2', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1616452683282, description='', last_updated_timestamp=1616452683282, latest_versions=[], name='tf-dnn-mnist', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1616452683304, description='', last_updated_timestamp=1616452683304, latest_versions=[], name='tf-dnn-mnist-warm-start', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1616452683324, description='', last_updated_timestamp=1616452683324, latest_versions=[], name='tf-dnn-mnist-resumed', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1616452694989, description='', last_updated_timestamp=1616452694989, latest_versions=[], name='AutoML988d71b280', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1616452703873, description='', last_updated_timestamp=1616452703873, latest_versions=[], name='AutoMLea14f02962', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1616452708134, description='', last_updated_timestamp=1616452708134, latest_versions=[], name='emailclassifier', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1618273503578, description='', last_updated_timestamp=1618273503578, latest_versions=[<ModelVersion: creation_timestamp=1618273503608, current_stage='None', description='', last_updated_timestamp=1618273503608, name='noaaweatherds', run_id='', run_link='', source='', status='READY', status_message='', tags={}, user_id='', version='1'>], name='noaaweatherds', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1620687148196, description='', last_updated_timestamp=1620687148196, latest_versions=[<ModelVersion: creation_timestamp=1620687148220, current_stage='None', description='', last_updated_timestamp=1620687148220, name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_3', run_id='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_3', run_link='', source='', status='READY', status_message='', tags={}, user_id='', version='1'>], name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_3', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1620687240137, description='', last_updated_timestamp=1620687240137, latest_versions=[<ModelVersion: creation_timestamp=1620687240163, current_stage='None', description='', last_updated_timestamp=1620687240163, name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_1', run_id='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_1', run_link='', source='', status='READY', status_message='', tags={}, user_id='', version='1'>], name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_1', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1620687346224, description='', last_updated_timestamp=1620687346224, latest_versions=[<ModelVersion: creation_timestamp=1620687346259, current_stage='None', description='', last_updated_timestamp=1620687346259, name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_4', run_id='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_4', run_link='', source='', status='READY', status_message='', tags={}, user_id='', version='1'>], name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_4', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1620687360564, description='', last_updated_timestamp=1620687360564, latest_versions=[<ModelVersion: creation_timestamp=1620687360598, current_stage='None', description='', last_updated_timestamp=1620687360598, name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_0', run_id='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_0', run_link='', source='', status='READY', status_message='', tags={}, user_id='', version='1'>], name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_0', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1620687414976, description='', last_updated_timestamp=1620687414976, latest_versions=[<ModelVersion: creation_timestamp=1620687415001, current_stage='None', description='', last_updated_timestamp=1620687415001, name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_2', run_id='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_2', run_link='', source='', status='READY', status_message='', tags={}, user_id='', version='1'>], name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_2', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1620687429977, description='', last_updated_timestamp=1620687429977, latest_versions=[<ModelVersion: creation_timestamp=1620687429998, current_stage='None', description='', last_updated_timestamp=1620687429998, name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_5', run_id='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_5', run_link='', source='', status='READY', status_message='', tags={}, user_id='', version='1'>], name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_5', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1620687485955, description='', last_updated_timestamp=1620687485955, latest_versions=[<ModelVersion: creation_timestamp=1620687485980, current_stage='None', description='', last_updated_timestamp=1620687485980, name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_6', run_id='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_6', run_link='', source='', status='READY', status_message='', tags={}, user_id='', version='1'>], name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_6', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1620687500910, description='', last_updated_timestamp=1620687500910, latest_versions=[<ModelVersion: creation_timestamp=1620687500932, current_stage='None', description='', last_updated_timestamp=1620687500932, name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_7', run_id='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_7', run_link='', source='', status='READY', status_message='', tags={}, user_id='', version='1'>], name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_7', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1620687583583, description='', last_updated_timestamp=1620687583583, latest_versions=[<ModelVersion: creation_timestamp=1620687583607, current_stage='None', description='', last_updated_timestamp=1620687583607, name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_8', run_id='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_8', run_link='', source='', status='READY', status_message='', tags={}, user_id='', version='1'>], name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_8', tags={}>,\n",
       " <RegisteredModel: creation_timestamp=1620687658070, description='', last_updated_timestamp=1620687658070, latest_versions=[<ModelVersion: creation_timestamp=1620687658094, current_stage='None', description='', last_updated_timestamp=1620687658094, name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_9', run_id='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_9', run_link='', source='', status='READY', status_message='', tags={}, user_id='', version='1'>], name='AutoML_e141d59a-e69a-4842-afb9-c19b4aeb6ab9_9', tags={}>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "def print_model_info(models):\n",
    "    import datetime\n",
    "    import time\n",
    "    \n",
    "    for m in models:\n",
    "        print(\"--\")\n",
    "        print(\"Name: {}\".format(m.name))\n",
    "        print(\"Time Created: {}\".format(m.creation_timestamp))\n",
    "#         print(\"description: {}\".format(m.description))\n",
    "\n",
    "\n",
    "mlflow_client = MlflowClient()\n",
    "\n",
    "\n",
    "experiment = mlflow_client.get_experiment_by_name(experiment_name)\n",
    "print(experiment)\n",
    "mlflow_client.list_run_infos(experiment.experiment_id, run_view_type=ViewType.ACTIVE_ONLY)\n",
    "\n",
    "dir(mlflow_client)\n",
    "mlflow_client.list_registered_models()\n",
    "# best_run = client.search_runs(experiment_ids=[experiment.id], filter_string=\"\", run_vew_type=ViewType.ACTIVE_ONLY, max_results=1, order_by=[f\"metrics.{primary_metric} DESC\"])[0]\n",
    "# best_models = client.search_model_versions(f\"name='{best_run.id}'\")\n",
    "\n",
    "# for rm in client.list_registered_models():\n",
    "#     pprint(dict(rm), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: What's the API to get Experiment / id via SDK v2.0?\n",
    "from azureml.core.experiment import Experiment, ViewType\n",
    "experiment = Experiment(workspace=ws, name=\"3-automl-remote-compute-run\")\n",
    "\n",
    "client = MlflowClient()\n",
    "print(client.list_registered_models())\n",
    "print(dir(client))\n",
    "\n",
    "best_run = client.search_runs(\n",
    "    experiment_ids=[experiment.id],\n",
    "    filter_string=\"\", max_results=1, order_by=[f\"metrics.{OptimizationMetric.NORMALIZED_ROOT_MEAN_SQUARED_ERROR} DESC\"])[0]\n",
    "best_models = client.search_model_versions(f\"name='simplebeerjob1620684744'\")\n",
    "best_model = best_models[0]\n",
    "# we may store 1 or 2 models depending on how our API proposal goes. \n",
    "# If sklearn and onnx are flavors of the same model, this would only contain one,\n",
    "# if they are stored separately, we'll have 2 and we'll need to specify an aditional filter\n",
    "\n",
    "# the above is requiring us to name the model after the child run id, it should be achievable without that,\n",
    "# need to sync with some folks, but if getting that run's model isn't really supported, something like\n",
    "# the below would be convenient:\n",
    "model_filter = f\"parent_run_id='simplebeerjob1620684744';sort_by_metric=\\'{OptimizationMetric.NORMALIZED_ROOT_MEAN_SQUARED_ERROR}\\'\"  \n",
    "models = client.list_registered_models(model_filter)\n",
    "best_model = models[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:devmar] *",
   "language": "python",
   "name": "conda-env-devmar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
